[model]
model = unet       # Model: unet, dilated-unet or dilated-densenet
features = 32      # Number of features maps after first convolutional layer
depth = 3	   # Number of downsampled convolutional blocks
padding = same	   # Padding in convolutional layers. Either `same' or `valid'
batchnorm = False  # Whether to apply batch normalization before activation layers
dropout = 0.0      # Rate for dropout of activation units (set to zero to omit)
classes = inner    # One of `inner', `outer', or `both' for endocardium, epicardium, or both


[training]
epochs = 100		# Number of epochs to train
BATCH_SIZE = 32         # Mini-batch size for training
validation_split = 0.33  # Fraction of training data to hold out for validation
optimizer = adam        # Optimizer: sgd, rmsprop, adagrad, adadelta, adam, adamax, or nadam
learning_rate =         # Optimizer learning rate
momentum =              # Momentum for SGD optimizer
decay =                 # Learning rate decay (for all optimizers except nadam)
shuffle_train_val = True
shuffle = True
seed = 0

[files]
load_weights =                # Name of file to load previously-saved model weights
datadir = .                   # Directory containing list of patientXX/ subdirectories
outdir = .                    # Where to write weight files
outfile = weights-final.hdf5  # File to write final model weights
checkpoint = True             # Whether to output model weight checkpoint files

[dataset]
SEQ_LENGTH = 30               #The length of the sequences to feed into RNN
RANDOM_STATE = 1              #The random seed used to shuffle the dataset
MIRROR = 1                    #Whether the training data was augmented by mirroring choice and reward
SHUFFLE = 1                   #Whether data should be shuffled after every epoch
train_size = 0.5              #Proportion of data in training set
validate_size = 0.25          #Proportion of data in validation set
test_size = 0.25              #Proportion of data in test set
