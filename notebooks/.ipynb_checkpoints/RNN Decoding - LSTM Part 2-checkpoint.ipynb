{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs on GPU\n",
    "After 2 full days of Linux hell I got our Nvidia Tesla K40c to run with keras, and this will speed up computations significantly. Furthermore, I met with Jake Varley who works at Google Brain and knows his shit and he gave me a few tips. I will implement those here, and they are:  \n",
    "\n",
    "1) one-hot encoding over categorical variables  \n",
    "2) augment data by \"mirroring\" it, e.g. double the dataset by switching East and West labels since task is symmetrical  \n",
    "3) create 2 artificial datasets: one shuffled version where models should not be able to learn anything, and one \"hard-coded\" one where they should achieve perfect decoding score. This will be a sanity check   \n",
    "4) give more data to validation and test sets  \n",
    "5) only include last trial -- this point i'm less sure that I understand. from my understanding including a whole sequence is what gives the memory of the RNN the ability to learn chunks but we'll see. i'm going to try both 'last trial' and a sequence of length n.  \n",
    "6) switch dropout to 50%  \n",
    "7) increase batch size to 512  \n",
    "\n",
    "1-5 are about how we prepare the sequences. The last 2 are about the networks themeselves. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded...\n",
      "\n",
      "DSR_TbyT_FirstTraining.p\n",
      "DSR_TbyT_Naive_mPFC.p\n",
      "DSR_TbyT_Naive_OFC.p\n",
      "DSR_TbyT_MidTraining.p\n",
      "DSR_TbyT_Saline.p\n",
      "DSR_TbyT_MPFC.p\n",
      "DSR_TbyT_OFC.p\n",
      "DSR_TbyT_Ipsi.p\n",
      "DSR_TbyT_Contra.p\n",
      "PSR_TbyT_FirstTraining.p\n",
      "PSR_TbyT_MidTraining.p\n",
      "PSR_TbyT_Saline.p\n",
      "PSR_TbyT_MPFC.p\n",
      "PSR_TbyT_OFC.p\n",
      "PSR_TbyT_Ipsi.p\n",
      "PSR_TbyT_Contra.p\n",
      "PSR_TbyT_Saline_Rigged.p\n",
      "DSR_TbyT_Saline_Shuffled.p\n",
      "PSR_TbyT_Saline_Shuffled.p\n"
     ]
    }
   ],
   "source": [
    "#BOILERPLATE _______________________\n",
    "#MODULES ______________________\n",
    "ROOT = '/Users/pablomartin/python/'\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import operator\n",
    "import pysftp\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "from RNNmodule.SequenceClass import Sequences\n",
    "from behavioral_performance.utils import fileNames, fileNameLabels\n",
    "from Visualize.decoding import *\n",
    "idx = pd.IndexSlice\n",
    "datatype = ['Full', 'Last', 'Med']\n",
    "RANDOM_STATE = 6\n",
    "print 'modules loaded...\\n'\n",
    "\n",
    "artificial_datasets = ['PSR_TbyT_Saline_Rigged.p',\n",
    "                       'DSR_TbyT_Saline_Shuffled.p',\n",
    "                       'PSR_TbyT_Saline_Shuffled.p']\n",
    "for ad in artificial_datasets:\n",
    "    try:\n",
    "        fileNames.index(ad)\n",
    "    except ValueError:\n",
    "        fileNames.append(ad)\n",
    "try:\n",
    "    fileNames.index('DSR_TbyT_Naive_Saline.p')\n",
    "    fileNames.pop(fileNames.index('DSR_TbyT_Naive_Saline.p'))\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "for fileName in fileNames:\n",
    "    print fileName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Artificial Datasets\n",
    "First, let's create a shuffled dataset that no network could learn, so we have a baseline. We will make one for DSR_Saline and PSR_Saline, which are the 2 datasets with most data. We will keep all the trial information the same, but shuffle the labels.  \n",
    "Also, let's create a 'rigged' dataset that the network should be able to learn to perfection. We're gonna pick an XOR gate, where input A = last choice, input B = reward from penultimate trial. The prediction of this XOR model is highly counterintuitive and there is no chance that that is what rats do. Nonetheless, if we are implementing these models correctly, the network should disregard all the other data, find this pattern, and achieve perfect decoding. Otherwise, we are implementing everything wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created shuffled datasets\n",
      "created rigged dataset\n"
     ]
    }
   ],
   "source": [
    "#load saline datasets\n",
    "DSR_Saline = pickle.load(open(ROOT + 'DATA_structures/TbyT/DSR_TbyT_Saline.p', 'rb'))\n",
    "PSR_Saline = pickle.load(open(ROOT + 'DATA_structures/TbyT/PSR_TbyT_Saline.p', 'rb'))\n",
    "#shuffle current choice - these are the eventual labels\n",
    "np.random.shuffle(DSR_Saline['choice',0].values)\n",
    "np.random.shuffle(PSR_Saline['choice',0].values)\n",
    "#save result\n",
    "pickle.dump(DSR_Saline, open(ROOT + 'DATA_structures/TbyT/DSR_TbyT_Saline_Shuffled.p', 'wb'))\n",
    "pickle.dump(PSR_Saline, open(ROOT + 'DATA_structures/TbyT/PSR_TbyT_Saline_Shuffled.p', 'wb'))\n",
    "print 'created shuffled datasets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rigged dataset - base will be PSR_Saline\n",
    "PSR_Saline = pickle.load(open(ROOT + \\\n",
    "                            'DATA_structures/TbyT/PSR_TbyT_Saline.p', 'rb'))\n",
    "fresh_copy = pickle.load(open(ROOT + \\\n",
    "                            'DATA_structures/TbyT/PSR_TbyT_Saline.p', 'rb'))\n",
    "choice_ch = np.sum(PSR_Saline['choice',0] == fresh_copy['choice', 0])\n",
    "reward_ch = np.sum(PSR_Saline['reward',0] == fresh_copy['reward', 0])\n",
    "print 'matching values choice: %i/%i' %(choice_ch, len(PSR_Saline))\n",
    "print 'matching values reward: %i/%i' %(reward_ch, len(PSR_Saline))\n",
    "for label, session in PSR_Saline.groupby(axis = 0, level = 'session'):\n",
    "\n",
    "    A = copy.deepcopy(session['reward', 0])\n",
    "    B = copy.deepcopy(session['choice', 0])\n",
    "    C = A + 2 * B\n",
    "    for trial in range(2, len(session)):\n",
    "        C.iloc[trial] = (C.iloc[trial - 1] + C.iloc[trial - 2]) % 4\n",
    "    A = C % 2\n",
    "    B = C > 1\n",
    "    print 'before assigning rigged list to original'\n",
    "    print 'A: %i/%i' %(np.sum(A == session['reward', 0]), len(session))\n",
    "    print 'B: %i/%i' %(np.sum(B == session['choice', 0]), len(session))\n",
    "\n",
    "    session['reward',0] = A\n",
    "    session['choice',0] = B\n",
    "    print 'after assigning rigged list to original'\n",
    "    print 'A: %i/%i' %(np.sum(A == session['reward', 0]), len(session))\n",
    "    print 'B: %i/%i' %(np.sum(B == session['choice', 0]), len(session))\n",
    "\n",
    "\n",
    "    PSR_Saline.loc[idx[label,:,:],idx['choice',0]] = session['choice',0]\n",
    "    PSR_Saline.loc[idx[label,:,:],idx['reward',0]] = session['reward',0]\n",
    "\n",
    "\n",
    "\n",
    "choice_ch = np.sum(PSR_Saline['choice',0] == fresh_copy['choice', 0])\n",
    "reward_ch = np.sum(PSR_Saline['reward',0] == fresh_copy['reward', 0])\n",
    "\n",
    "print 'matching values choice: %i/%i' %(choice_ch, len(PSR_Saline))\n",
    "print 'matching values reward: %i/%i' %(reward_ch, len(PSR_Saline))\n",
    "\n",
    "pickle.dump(PSR_Saline, open(ROOT + \\\n",
    "                        'DATA_structures/TbyT/PSR_TbyT_Saline_Rigged.p', 'wb'))\n",
    "print 'created rigged dataset'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sequences\n",
    "Most of the fixes are in the preprocessing stage: preparing sequences. The data augmentation should be done *only* on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset DSR_TbyT_Saline_Shuffled.p\n",
      "finished: DSR_TbyT_Saline_Shuffled.p - 1 - OneHotBinaryMinimal\n",
      "finished: DSR_TbyT_Saline_Shuffled.p - 30 - OneHotBinaryMinimal\n",
      "finished: DSR_TbyT_Saline_Shuffled.p - 200 - OneHotBinaryMinimal\n",
      "dataset PSR_TbyT_Saline_Shuffled.p\n",
      "finished: PSR_TbyT_Saline_Shuffled.p - 1 - OneHotBinaryMinimal\n",
      "finished: PSR_TbyT_Saline_Shuffled.p - 30 - OneHotBinaryMinimal\n",
      "finished: PSR_TbyT_Saline_Shuffled.p - 200 - OneHotBinaryMinimal\n",
      "dataset PSR_TbyT_Saline_Rigged.p\n",
      "finished: PSR_TbyT_Saline_Rigged.p - 1 - OneHotBinaryMinimal\n",
      "finished: PSR_TbyT_Saline_Rigged.p - 30 - OneHotBinaryMinimal\n",
      "finished: PSR_TbyT_Saline_Rigged.p - 200 - OneHotBinaryMinimal\n"
     ]
    }
   ],
   "source": [
    "seq_lengths = [1, 30, 200]\n",
    "seq_length_labels = ['Last', 'Med', 'Full']\n",
    "seq_types = ['OneHotBinaryMinimal']\n",
    "\n",
    "dataset_filenames = [w for w in os.listdir(ROOT + 'DATA_structures/TbyT/')\\\n",
    "                     if not w.startswith('.') and w!='DSR_TbyT_Naive_Saline.p']\n",
    "dataset_filenames = ['DSR_TbyT_Saline_Shuffled.p', 'PSR_TbyT_Saline_Shuffled.p', 'PSR_TbyT_Saline_Rigged.p']\n",
    "\n",
    "dataset_paths = [ROOT + 'DATA_structures/TbyT/' + w for w in dataset_filenames]\n",
    "\n",
    "mirrorFlag = True\n",
    "for dataset_file, dataset_path in zip(dataset_filenames, dataset_paths):\n",
    "    if not dataset_file.find('Rigged') < 0:\n",
    "        mirrorFlag = False\n",
    "    if not dataset_file.find('Shuffled') < 0:\n",
    "        mirrorFlag = False\n",
    "        \n",
    "    print 'dataset %s' %dataset_file\n",
    "    df = pickle.load(open(dataset_path, 'rb'))\n",
    "    for seq_length, seq_type in itertools.product(seq_lengths, seq_types):\n",
    "        seqObject = Sequences(seq_length, seq_type, RANDOM_STATE = RANDOM_STATE)\n",
    "        seqObject.create_sequences(df,\n",
    "                                   timesteps = seq_length,\n",
    "                                   feature_dim = seq_type,\n",
    "                                   validate_size = 0.25,\n",
    "                                   test_size = 0.25,\n",
    "                                   mirrorFlag = mirrorFlag)\n",
    "        seq_length_label =  seq_length_labels[seq_lengths.index(seq_length)]\n",
    "        pickle.dump(seqObject, open(ROOT + 'DATA_structures/RNN_sequences/' + \\\n",
    "                                            seq_type + '/' + \\\n",
    "                                            seq_length_label + '/' + \\\n",
    "                                            dataset_file, 'wb'))\n",
    "        print 'finished: %s - %s - %s' %(dataset_file, seq_length, seq_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Useful Tools\n",
    "Let's define some tools that would be nice to have. Let's use pysftp systematically for all this stuff.\n",
    "\n",
    "1) function that finds highest validation accuracy given a folder  \n",
    "2) plot training vs. validation accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def retrieve_val_acc(connection, model_dir):\n",
    "    if not connection.isdir(model_dir):\n",
    "        print 'model does not exist... exiting'\n",
    "        return None\n",
    "    model_files = connection.listdir(model_dir)\n",
    "    finished_training = sum([w=='loss_acc_history.p' for w in model_files])\n",
    "    if finished_training:\n",
    "        scores = dict([(index, float(w[w.find('-') + 1: -5]))\n",
    "                       for index, w in enumerate(model_files) if w.startswith('w')])\n",
    "        best_model = model_files[max(scores, key=scores.get)]\n",
    "        val_score = max(scores.values())\n",
    "        return val_score, best_model\n",
    "    else:\n",
    "        print 'training did not finish or has not begun...'\n",
    "        return None\n",
    "        \n",
    "        \n",
    "def retrieve_history(connection, model_dir, path_to_save_to = '.'):\n",
    "    if not connection.isdir(model_dir):\n",
    "        print 'model does not exist... exiting'\n",
    "        return \n",
    "    model_files = connection.listdir(model_dir)\n",
    "    finished_training = sum([w=='loss_acc_history.p' for w in model_files])\n",
    "    if finished_training:\n",
    "        connection.get(model_dir + 'loss_acc_history.p', path_to_save_to)\n",
    "        return \n",
    "    else:\n",
    "        print 'training did not finish or has not begun...'\n",
    "        return \n",
    "    \n",
    "    \n",
    "#this will plot standard training/validation progress thru epochs\n",
    "def plot_training_history(hist, title):\n",
    "    for field in hist.keys():\n",
    "        plt.plot(hist[field], label=field)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('Accuracy / Loss')\n",
    "    plt.title(title, FontSize = 20)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#downloads file, plots it, and then deletes file\n",
    "def plot_training_hist(connection, model_dir):\n",
    "    retrieve_history(connection, model_dir, path_to_save_to = '/Users/pablomartin/python/loss_acc_history.p')\n",
    "    hist = pickle.load(open('/Users/pablomartin/python/loss_acc_history.p', 'rb'))\n",
    "    plot_training_history(hist, model_dir)\n",
    "    os.remove('/Users/pablomartin/python/loss_acc_history.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Best Networks\n",
    "The following code uses a secure file transfer protocol (SFTP) connection into epsilon, finds out which models are done training, and evaluates which are the top ten performing models on the validation set. It saves this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define parameters to iterate over\n",
    "epsilon_ROOT = '/home/pablo/python/'\n",
    "\n",
    "#CREATING NETWORK DIMENSIONS__________\n",
    "hidden_dimensions = [5, 20, 50, 100]\n",
    "hidden_dimensions_red = [5, 50]\n",
    "no_models = len(hidden_dimensions) + len(hidden_dimensions) ** 2 \\\n",
    "          + len(hidden_dimensions_red) ** 3\n",
    "HDS = np.zeros([no_models, 3], dtype = int)\n",
    "HDS[:len(hidden_dimensions), 0] = hidden_dimensions\n",
    "for index, (hd1, hd2) in enumerate(itertools.product(hidden_dimensions,\n",
    "                                                     hidden_dimensions)):\n",
    "    HDS[len(hidden_dimensions) + index, 0] = hd1\n",
    "    HDS[len(hidden_dimensions) + index, 1] = hd2\n",
    "\n",
    "counter = np.argmin(np.sum(HDS, axis = 1) != 0)\n",
    "for index, (hd1, hd2, hd3) in enumerate(itertools.product(hidden_dimensions_red,\n",
    "                                                          hidden_dimensions_red,\n",
    "                                                          hidden_dimensions_red)):\n",
    "    HDS[counter + index, 0] = hd1\n",
    "    HDS[counter + index, 1] = hd2\n",
    "    HDS[counter + index, 2] = hd3\n",
    "\n",
    "\n",
    "cellType_folders = {'RNN' : 'Models/RNN/OneHotBinaryMinimal/',\n",
    "                    'LSTM' : 'Models/LSTM/Pablo/OneHotBinaryMinimal/'}\n",
    "\n",
    "rows = pd.MultiIndex.from_product([datatype, [w[:-2] for w in fileNames]],\n",
    "                                  names =['Seq_Length', 'Dataset'])\n",
    "cols = pd.MultiIndex.from_product([['val_score', 'cell', 'network', 'dir_path', 'file_path'], range(1,11)],\n",
    "                                  names = ['Network Info', 'Rank'])\n",
    "MODEL_RESULTS = pd.DataFrame(np.zeros([len(rows), len(cols)]), index=rows, columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 19 datasets\n",
      "finished:  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  done\n",
      "Network Info                        val_score                        \n",
      "Rank                                        1     2     3     4     5\n",
      "Seq_Length Dataset                                                   \n",
      "Med        DSR_TbyT_Contra               0.73  0.72  0.72  0.72  0.72\n",
      "           DSR_TbyT_FirstTraining        0.70  0.70  0.70  0.69  0.69\n",
      "           DSR_TbyT_Ipsi                 0.75  0.74  0.74  0.74  0.74\n",
      "           DSR_TbyT_MPFC                 0.77  0.76  0.75  0.75  0.75\n",
      "           DSR_TbyT_MidTraining          0.74  0.71  0.70  0.70  0.70\n",
      "           DSR_TbyT_Naive_OFC            0.77  0.77  0.77  0.75  0.75\n",
      "           DSR_TbyT_Naive_mPFC           0.80  0.77  0.77  0.77  0.77\n",
      "           DSR_TbyT_OFC                  0.76  0.76  0.76  0.76  0.75\n",
      "           DSR_TbyT_Saline               0.74  0.74  0.74  0.74  0.74\n",
      "           DSR_TbyT_Saline_Shuffled      0.41  0.41  0.41  0.41  0.41\n",
      "           PSR_TbyT_Contra               0.60  0.60  0.59  0.59  0.59\n",
      "           PSR_TbyT_FirstTraining        0.64  0.62  0.62  0.61  0.61\n",
      "           PSR_TbyT_Ipsi                 0.56  0.55  0.55  0.55  0.54\n",
      "           PSR_TbyT_MPFC                 0.56  0.56  0.56  0.56  0.55\n",
      "           PSR_TbyT_MidTraining          0.60  0.59  0.59  0.59  0.58\n",
      "           PSR_TbyT_OFC                  0.58  0.58  0.57  0.57  0.56\n",
      "           PSR_TbyT_Saline               0.57  0.57  0.57  0.57  0.57\n",
      "           PSR_TbyT_Saline_Rigged        1.00  0.99  0.99  0.99  0.99\n",
      "           PSR_TbyT_Saline_Shuffled      0.34  0.34  0.33  0.33  0.33\n"
     ]
    }
   ],
   "source": [
    "verbose = 0\n",
    "epsilon_connection = pysftp.Connection('10.81.104.156', username='pablo', password='pablo2014')\n",
    "epsilon2_connection = pysftp.Connection('10.81.104.143', username='pablo', password='pablo2015')\n",
    "remote_desktops = [epsilon2_connection]\n",
    "model_iterator = itertools.product(remote_desktops, fileNames, ['Med'])\n",
    "\n",
    "print 'working on %i datasets' %(len(fileNames))\n",
    "print 'finished: ',\n",
    "for iterator_index, (connection, fileName, dataPrep) in enumerate(model_iterator):\n",
    "\n",
    "    d = {}\n",
    "    print '%i, ' %(iterator_index),\n",
    "    for cell_type, hd in itertools.product(['RNN', 'LSTM'], HDS):\n",
    "        model_dir = epsilon_ROOT + cellType_folders[cell_type] + dataPrep + '/'\n",
    "        network_name = '_D_'.join([fileName[:-2]] + [str(w) for w in hd if w > 0])\n",
    "        model_dir += network_name\n",
    "        start = time.time()\n",
    "        if connection.isdir(model_dir):\n",
    "            tmp_val = retrieve_val_acc(connection, model_dir)\n",
    "        else:\n",
    "            tmp_val = None\n",
    "        if verbose > 1: print 'retrieval time: %.3f sec' %(time.time() - start)\n",
    "        if tmp_val:\n",
    "            val_score, best_model = tmp_val\n",
    "            d[best_model] = (val_score, cell_type, network_name)\n",
    "        \n",
    "    top_ten = sorted(d, key=lambda x:d[x][0])[-10:]\n",
    "    for index, key in enumerate(top_ten[::-1]):\n",
    "        dir_path = epsilon_ROOT \\\n",
    "                    + cellType_folders[d[key][1]] \\\n",
    "                    + dataPrep + '/' \\\n",
    "                    + d[key][2] + '/' \n",
    "        file_path = dir_path + key\n",
    "        if verbose: print 'model directory exists:%s' %connection.isdir(dir_path)\n",
    "        if verbose: print 'model exists:%s' %connection.isfile(file_path)\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['val_score', 1 + index]] = d[key][0]\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['cell', 1 + index]] = d[key][1]\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['network', 1 + index]] = \\\n",
    "                                                            d[key][2][len(fileName[:-2]) + 1:]\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['dir_path', 1 + index]] = dir_path\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['file_path', 1 + index]] = file_path\n",
    "                                        \n",
    "                      \n",
    "MODEL_RESULTS.sort_index(axis = 0, inplace = True)\n",
    "MODEL_RESULTS.sort_index(axis = 1, inplace = True)\n",
    "print 'done'\n",
    "pickle.dump(MODEL_RESULTS, open('/Users/pablomartin/python/tmp/MODEL_RESULTS.p' ,'wb'))\n",
    "print MODEL_RESULTS.loc[idx['Med',:], idx['val_score',1:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Info                         cell  \\\n",
      "Rank                                    1   \n",
      "Seq_Length Dataset                          \n",
      "Med        DSR_TbyT_Contra            RNN   \n",
      "           DSR_TbyT_FirstTraining     RNN   \n",
      "           DSR_TbyT_Ipsi             LSTM   \n",
      "           DSR_TbyT_MPFC             LSTM   \n",
      "           DSR_TbyT_MidTraining       RNN   \n",
      "           DSR_TbyT_Naive_OFC         RNN   \n",
      "           DSR_TbyT_Naive_mPFC        RNN   \n",
      "           DSR_TbyT_OFC               RNN   \n",
      "           DSR_TbyT_Saline            RNN   \n",
      "           DSR_TbyT_Saline_Shuffled  LSTM   \n",
      "           PSR_TbyT_Contra            RNN   \n",
      "           PSR_TbyT_FirstTraining    LSTM   \n",
      "           PSR_TbyT_Ipsi              RNN   \n",
      "           PSR_TbyT_MPFC             LSTM   \n",
      "           PSR_TbyT_MidTraining       RNN   \n",
      "           PSR_TbyT_OFC               RNN   \n",
      "           PSR_TbyT_Saline           LSTM   \n",
      "           PSR_TbyT_Saline_Rigged     RNN   \n",
      "           PSR_TbyT_Saline_Shuffled   RNN   \n",
      "\n",
      "Network Info                                                                 file_path  \\\n",
      "Rank                                                                                 1   \n",
      "Seq_Length Dataset                                                                       \n",
      "Med        DSR_TbyT_Contra           /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           DSR_TbyT_FirstTraining    /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           DSR_TbyT_Ipsi             /home/pablo/python/Models/LSTM/Pablo/OneHotBin...   \n",
      "           DSR_TbyT_MPFC             /home/pablo/python/Models/LSTM/Pablo/OneHotBin...   \n",
      "           DSR_TbyT_MidTraining      /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           DSR_TbyT_Naive_OFC        /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           DSR_TbyT_Naive_mPFC       /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           DSR_TbyT_OFC              /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           DSR_TbyT_Saline           /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           DSR_TbyT_Saline_Shuffled  /home/pablo/python/Models/LSTM/Pablo/OneHotBin...   \n",
      "           PSR_TbyT_Contra           /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           PSR_TbyT_FirstTraining    /home/pablo/python/Models/LSTM/Pablo/OneHotBin...   \n",
      "           PSR_TbyT_Ipsi             /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           PSR_TbyT_MPFC             /home/pablo/python/Models/LSTM/Pablo/OneHotBin...   \n",
      "           PSR_TbyT_MidTraining      /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           PSR_TbyT_OFC              /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           PSR_TbyT_Saline           /home/pablo/python/Models/LSTM/Pablo/OneHotBin...   \n",
      "           PSR_TbyT_Saline_Rigged    /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "           PSR_TbyT_Saline_Shuffled  /home/pablo/python/Models/RNN/OneHotBinaryMini...   \n",
      "\n",
      "Network Info                                network val_score  \n",
      "Rank                                              1         1  \n",
      "Seq_Length Dataset                                             \n",
      "Med        DSR_TbyT_Contra                D_20_D_50      0.73  \n",
      "           DSR_TbyT_FirstTraining       D_100_D_100      0.70  \n",
      "           DSR_TbyT_Ipsi                 D_100_D_20      0.75  \n",
      "           DSR_TbyT_MPFC              D_5_D_50_D_50      0.77  \n",
      "           DSR_TbyT_MidTraining       D_5_D_50_D_50      0.74  \n",
      "           DSR_TbyT_Naive_OFC             D_20_D_50      0.77  \n",
      "           DSR_TbyT_Naive_mPFC                D_100      0.80  \n",
      "           DSR_TbyT_OFC                   D_5_D_100      0.76  \n",
      "           DSR_TbyT_Saline               D_20_D_100      0.74  \n",
      "           DSR_TbyT_Saline_Shuffled      D_50_D_100      0.41  \n",
      "           PSR_TbyT_Contra                 D_5_D_20      0.60  \n",
      "           PSR_TbyT_FirstTraining              D_50      0.64  \n",
      "           PSR_TbyT_Ipsi             D_50_D_50_D_50      0.56  \n",
      "           PSR_TbyT_MPFC                 D_20_D_100      0.56  \n",
      "           PSR_TbyT_MidTraining                D_50      0.60  \n",
      "           PSR_TbyT_OFC                        D_50      0.58  \n",
      "           PSR_TbyT_Saline                D_50_D_20      0.57  \n",
      "           PSR_TbyT_Saline_Rigged        D_50_D_100      1.00  \n",
      "           PSR_TbyT_Saline_Shuffled       D_20_D_50      0.34  \n"
     ]
    }
   ],
   "source": [
    "print MODEL_RESULTS.loc[idx['Med',:], idx[['cell','val_score','network', 'file_path'],1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Network Performance on Train, Validate, and Test\n",
    "Let's see how they generalize !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading DSR_TbyT_FirstTraining.p (1/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_Naive_mPFC.p (2/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_Naive_OFC.p (3/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_MidTraining.p (4/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_Saline.p (5/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_MPFC.p (6/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_OFC.p (7/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_Ipsi.p (8/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_Contra.p (9/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_FirstTraining.p (10/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_MidTraining.p (11/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_Saline.p (12/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_MPFC.p (13/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_OFC.p (14/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_Ipsi.p (15/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_Contra.p (16/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_Saline_Rigged.p (17/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading DSR_TbyT_Saline_Shuffled.p (18/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "downloading PSR_TbyT_Saline_Shuffled.p (19/19) ...  done\n",
      "loading model ...  done\n",
      "evaluating model ...  done\n",
      "                            train_choice  validate_choice  test_choice\n",
      "DSR_TbyT_FirstTraining.p        0.706573         0.717460     0.664360\n",
      "DSR_TbyT_Naive_mPFC.p           0.875339         0.817073     0.739726\n",
      "DSR_TbyT_Naive_OFC.p            0.732456         0.769231     0.589286\n",
      "DSR_TbyT_MidTraining.p          0.788927         0.755556     0.742222\n",
      "DSR_TbyT_Saline.p               0.751883         0.766581     0.764423\n",
      "DSR_TbyT_MPFC.p                 0.751412         0.782772     0.755245\n",
      "DSR_TbyT_OFC.p                  0.764115         0.785714     0.732323\n",
      "DSR_TbyT_Ipsi.p                 0.741516         0.771218     0.698980\n",
      "DSR_TbyT_Contra.p               0.705682         0.758958     0.662698\n",
      "PSR_TbyT_FirstTraining.p        0.757549         0.769697     0.744770\n",
      "PSR_TbyT_MidTraining.p          0.826657         0.688172     0.658436\n",
      "PSR_TbyT_Saline.p               0.682076         0.698097     0.667482\n",
      "PSR_TbyT_MPFC.p                 0.579291         0.666667     0.587413\n",
      "PSR_TbyT_OFC.p                  0.657068         0.699588     0.619835\n",
      "PSR_TbyT_Ipsi.p                 0.686761         0.708475     0.689362\n",
      "PSR_TbyT_Contra.p               0.657397         0.697674     0.573333\n",
      "PSR_TbyT_Saline_Rigged.p        0.997520         0.996540     0.995110\n",
      "DSR_TbyT_Saline_Shuffled.p      0.531073         0.541774     0.514423\n",
      "PSR_TbyT_Saline_Shuffled.p      0.505491         0.553633     0.507742\n"
     ]
    }
   ],
   "source": [
    "MODEL_RESULTS = pickle.load(open('/Users/pablomartin/python/tmp/MODEL_RESULTS.p','rb'))\n",
    "dataPrep = 'Med'\n",
    "remote = 'epsilon2'\n",
    "\n",
    "desktops = {'epsilon1': {'ip': '10.81.104.153', 'password' : 'pablo2014'},\n",
    "            'epsilon2': {'ip': '10.81.104.143', 'password' : 'pablo2015'}}\n",
    "\n",
    "scores = pd.DataFrame(np.zeros([len(fileNames),7]),\n",
    "                      index = fileNames,\n",
    "                      columns = ['train_choice','validate_choice','test_choice',\n",
    "                                 'train','validate','test', 'model'])   \n",
    "\n",
    "\n",
    "for index, fileName in enumerate(fileNames):\n",
    "    \n",
    "    sequence_path = '/Users/pablomartin/python/' + \\\n",
    "                    'DATA_structures/RNN_sequences/OneHotBinaryMinimal/' + \\\n",
    "                    dataPrep + '/' + fileName\n",
    "    seqs = pickle.load(open(sequence_path, 'rb'))       \n",
    "\n",
    "    file_path = MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['file_path',1]]\n",
    "    model_target = '/Users/pablomartin/python/Models/Winners/' + fileName[:-2] + '.hdf5'\n",
    "    scores.loc[fileName, 'model'] = file_path\n",
    "    file_weights = file_path[-file_path[::-1].find('/'):]\n",
    "    #downloading model if not available in local machine\n",
    "    with pysftp.Connection(desktops[remote]['ip'],\n",
    "                           username='pablo',\n",
    "                           password=desktops[remote]['password']) as connection:\n",
    "        if not os.path.isfile(model_target):\n",
    "            print 'downloading %s (%i/%i) ...' %(fileName, 1 + index, len(fileNames)),\n",
    "            connection.get(file_path, model_target)\n",
    "            print ' done'\n",
    "    print 'loading model ...',\n",
    "    model = load_model(model_target)\n",
    "    print ' done'\n",
    "    print 'evaluating model ...',\n",
    "    \n",
    "    loss, acc = model.evaluate(x = seqs.X_train, y = seqs.y_train, verbose = 0)\n",
    "    scores.loc[fileName, 'train'] = acc\n",
    "    loss, acc = model.evaluate(x = seqs.X_validate, y = seqs.y_validate, verbose = 0)\n",
    "    scores.loc[fileName, 'validate'] = acc\n",
    "    loss, acc = model.evaluate(x = seqs.X_test, y = seqs.y_test, verbose = 0)\n",
    "    scores.loc[fileName, 'test'] = acc\n",
    "    #choice accuracy\n",
    "    preds = np.argmax(model.predict(x = seqs.X_train), axis = 1) > 1\n",
    "    scores.loc[fileName, 'train_choice'] = \\\n",
    "        np.float(np.sum(preds == (np.argmax(seqs.y_train, axis=1) > 1))) / len(seqs.X_train)\n",
    "    preds = np.argmax(model.predict(x = seqs.X_validate), axis = 1) > 1\n",
    "    scores.loc[fileName, 'validate_choice'] = \\\n",
    "        np.float(np.sum(preds == (np.argmax(seqs.y_validate, axis=1) > 1))) / len(seqs.X_validate)\n",
    "    preds = np.argmax(model.predict(x = seqs.X_test), axis = 1) > 1\n",
    "    scores.loc[fileName, 'test_choice'] = \\\n",
    "        np.float(np.sum(preds == (np.argmax(seqs.y_test, axis=1) > 1))) / len(seqs.X_test)\n",
    "    assert scores.loc[fileName, 'train_choice'] >= scores.loc[fileName, 'train']\n",
    "    assert scores.loc[fileName, 'validate_choice'] >= scores.loc[fileName, 'validate']\n",
    "    assert scores.loc[fileName, 'test_choice'] >= scores.loc[fileName, 'test']\n",
    "    \n",
    "    print ' done'\n",
    "print scores.loc[:, ['train_choice','validate_choice','test_choice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
