{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks    \n",
    "\n",
    "First, we make a class definition with all appropriate functions that will be useful. \n",
    "\n",
    "Almost everything comes from here: http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/\n",
    "\n",
    "Changed very few things from implementation here. Mostly names to fit with what we're doing here, and so that I can understand it. Generalized some formulas so that I'm not tied down to input data being one-hot encoded vectors. I see why they did it, so you don't have to multiply the entire matrix, but I can see cases where I'm going to want to combine inputs, which doesn't make sense in the language model that they are using. But it does for me. I also defined RNN module with this class definition so in the future I can just import it like anything else.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class behaviorRNN:\n",
    "     \n",
    "    def __init__(self, noFeatures = 2, hidden_dim=100, bptt_truncate=4):\n",
    "        # Assign instance variables\n",
    "        self.noFeatures = noFeatures \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Randomly initialize network parameters between 1/sqrt()\n",
    "        f = lambda x,y: y * np.sqrt(1./x)\n",
    "        \n",
    "        self.Wxh = np.random.uniform(f(noFeatures, -1), f(noFeatures, 1), (hidden_dim, noFeatures))\n",
    "        self.Why = np.random.uniform(f(hidden_dim, -1), f(hidden_dim, 1), (noFeatures, hidden_dim))\n",
    "        self.Whh = np.random.uniform(f(hidden_dim, -1), f(hidden_dim, 1), (hidden_dim, hidden_dim))\n",
    "        \n",
    "    def softmax(self, x):  \n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)  \n",
    "    \n",
    "     \n",
    "    def predict(self, seq):\n",
    "        p, h  = self.forward_propagation(seq)\n",
    "        #max of last prediction\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    \n",
    "    def forward_propagation(self, seq):\n",
    "        #seq is 1-dimensional not one-hot vector\n",
    "        noTrials = len(seq)\n",
    "        #this is the hidden 'space'\n",
    "        h = np.zeros([1 + noTrials, self.hidden_dim])\n",
    "        #this is the output - probability of next element in sequence\n",
    "        p = np.zeros([noTrials, self.noFeatures])\n",
    "        \n",
    "        for trial in range(noTrials):\n",
    "            h[trial] = np.tanh(self.Wxh[:, seq[trial]] + self.Whh.dot(h[trial - 1]))\n",
    "            p[trial] = self.softmax(self.Why.dot(h[trial]))\n",
    "        return p, h\n",
    "\n",
    "    \n",
    "    def calculate_total_loss(self, x, y):\n",
    "        L = 0\n",
    "        # For each sequence of trials...\n",
    "        for i in np.arange(len(y)):\n",
    "            p, h = self.forward_propagation(x[i])\n",
    "            # We only care about our prediction of the \"correct\" words\n",
    "            correct_trial_predictions = p[np.arange(len(y[i])), y[i]]\n",
    "            # Add to the loss based on how off we were\n",
    "            L += -1 * np.sum(np.log(correct_trial_predictions))\n",
    "        return L\n",
    "\n",
    "    def calculate_loss(self, x, y):\n",
    "        # Divide the total loss by the number of training examples\n",
    "        N = np.sum((len(y_i) for y_i in y))\n",
    "        return self.calculate_total_loss(x, y) / N\n",
    "\n",
    "\n",
    "    def bptt(self, x, y, verbose = 0):\n",
    "        #x and y are NOT one-hot vectors, also they are a single example\n",
    "        \n",
    "        noTrials = len(y)\n",
    "        \n",
    "        # forward propagation\n",
    "        p, h = self.forward_propagation(x)\n",
    "        \n",
    "        # We accumulate the gradients in these variables\n",
    "        dLdWxh = np.zeros(self.Wxh.shape)\n",
    "        dLdWhh = np.zeros(self.Whh.shape)\n",
    "        dLdWhy = np.zeros(self.Why.shape)\n",
    "        \n",
    "        #difference between prediction and labels\n",
    "        delta_p = p\n",
    "        delta_p[np.arange(noTrials), y] -= 1.\n",
    "\n",
    "        # For each output backwards...\n",
    "        for trial in np.arange(noTrials)[::-1]:\n",
    "            \n",
    "            #easiest case\n",
    "            dLdWhy += np.outer(delta_p[trial], h[trial].T)\n",
    "            \n",
    "            # Initial delta calculation\n",
    "            delta_t = self.Why.T.dot(delta_p[trial]) * (1 - (h[trial] ** 2))\n",
    "            # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "            for bptt_step in np.arange(max(0, trial - self.bptt_truncate), trial + 1)[::-1]:\n",
    "                #for debugging\n",
    "                #if verbose: print \"Backpropagation step t=%d bptt step=%d \" %(trial, bptt_step)\n",
    "                dLdWhh += np.outer(delta_t, h[bptt_step - 1])         \n",
    "                dLdWxh[:, x[bptt_step]] += delta_t\n",
    "                # Update delta for next step\n",
    "                delta_t = self.Whh.T.dot(delta_t) * (1 - h[bptt_step - 1] ** 2)\n",
    "        return [dLdWxh, dLdWhh, dLdWhy]\n",
    "\n",
    "\n",
    "    \n",
    "    def gradient_check(self, x, y, delta = 0.001, error_threshold = 0.01):\n",
    "        \n",
    "        #i hope this fixes the issues, bro - it did!\n",
    "        self.bptt_truncate = 1000\n",
    "        \n",
    "        # Calculate the gradients using backpropagation. We want to checker if these are correct.\n",
    "        bptt_gradients = self.bptt(x, y)\n",
    "        # List of all parameters we want to check.\n",
    "        model_parameters = ['Wxh', 'Whh', 'Why']\n",
    "        # Gradient check for each parameter\n",
    "        for pidx, pname in enumerate(model_parameters):\n",
    "            # Get the actual parameter value from the mode, e.g. model.W\n",
    "            parameter = operator.attrgetter(pname)(self)\n",
    "            print \"Performing gradient check for parameter %s with size %d.\" % (pname, np.prod(parameter.shape))\n",
    "            # Iterate over each element of the parameter matrix, e.g. (0,0), (0,1), ...\n",
    "            it = np.nditer(parameter, flags=['multi_index'], op_flags=['readwrite'])\n",
    "            while not it.finished:\n",
    "                ix = it.multi_index\n",
    "                # Save the original value so we can reset it later\n",
    "                original_value = parameter[ix]\n",
    "                # Estimate the gradient using (f(x+delta) - f(x-delta))/(2*delta)\n",
    "                parameter[ix] = original_value + delta\n",
    "                gradplus = self.calculate_total_loss([x], [y])\n",
    "                parameter[ix] = original_value - delta\n",
    "                gradminus = self.calculate_total_loss([x], [y])\n",
    "                estimated_gradient = (gradplus - gradminus) / (2 * delta)\n",
    "                # Reset parameter to original value\n",
    "                parameter[ix] = original_value\n",
    "                # The gradient for this parameter calculated using backpropagation\n",
    "                backprop_gradient = bptt_gradients[pidx][ix] \n",
    "                # calculate The relative error: (|x - y|/(|x| + |y|))\n",
    "                relative_error = np.abs(backprop_gradient - estimated_gradient) \\\n",
    "                                / (np.abs(backprop_gradient) + np.abs(estimated_gradient))\n",
    "                # If the error is too large -> fail the gradient check\n",
    "                if relative_error > error_threshold:\n",
    "                    print \"Gradient Check ERROR: parameter=%s ix=%s\" % (pname, ix)\n",
    "                    print \"+h Loss: %f\" % gradplus\n",
    "                    print \"-h Loss: %f\" % gradminus\n",
    "                    print \"Estimated_gradient: %f\" % estimated_gradient\n",
    "                    print \"Backpropagation gradient: %f\" % backprop_gradient\n",
    "                    print \"Relative Error: %f\" % relative_error\n",
    "                    return \n",
    "                it.iternext()\n",
    "            print \"Gradient check for parameter %s passed.\" % (pname)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def numpy_sdg_step(self, x, y, learning_rate):\n",
    "        # Calculate the gradients\n",
    "        dLdWxh, dLdWhh, dLdWhy = self.bptt(x, y)\n",
    "        # Change parameters according to gradients and learning rate\n",
    "        self.Wxh -= learning_rate * dLdWxh\n",
    "        self.Why -= learning_rate * dLdWhy\n",
    "        self.Whh -= learning_rate * dLdWhh\n",
    "        \n",
    "    def train_with_sgd(model, X_train, y_train, learning_rate=0.005, nepoch=100, evaluate_loss_after=5):\n",
    "        # We keep track of the losses so we can plot them later\n",
    "        losses = []\n",
    "        num_examples_seen = 0\n",
    "        for epoch in range(nepoch):\n",
    "            # Optionally evaluate the loss\n",
    "            if (epoch % evaluate_loss_after == 0):\n",
    "                loss = model.calculate_loss(X_train, y_train)\n",
    "                losses.append((num_examples_seen, loss))\n",
    "                time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print \"%s: Loss after num_examples_seen=%d epoch=%d: %f\" \\\n",
    "                                    %(time, num_examples_seen, epoch, loss)\n",
    "                # Adjust the learning rate if loss increases\n",
    "                if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                    learning_rate = learning_rate * 0.5 \n",
    "                    print \"Setting learning rate to %f\" % learning_rate\n",
    "                sys.stdout.flush()\n",
    "            # For each training example...\n",
    "            for i in range(len(y_train)):\n",
    "                # One SGD step\n",
    "                model.numpy_sdg_step(X_train[i], y_train[i], learning_rate)\n",
    "                num_examples_seen += 1\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Our data consists of sequences of 0's and 1's, which mean EAST or WEST responses made by the rats. The aim, ultimately, is to decode these choices. However, there are a few choices to make as to how to prepare the data. For example, we can:  \n",
    "\n",
    "1) define sequences of 0's and 1's to denote EAST and WEST choices, or  \n",
    "2) define sequences of [0,1,2,3], where 0 = EAST and NO REWARD, 1 = EAST AND REWARD, 2 = WEST AND NO REWARD, 3 = WEST AND REWARD  \n",
    "\n",
    "Furthermore, how to define sequence length ? We can keep each session as a different sequence, in which case the RNN will only have 10 - 40 really long training examples. From what I can understand, RNNs struggle to learn long sequences and need lots of data to do so, so perhaps having fery vew really long sequences will mean the RNN is not able to learn properly. Alternatively, we could \"cut up\" each session into chunks of ~20 trials and feed them as individual training examples. We also need to add a 'token' that denotes the start of the session. This section will prepare all these options. We will probably try all of them.  \n",
    "\n",
    "Below are shown the methods used to obtain the data, I did it elsewhere and saved it all to a target folder though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def fileName_label(fileName):\n",
    "    datasetFile = fileName[-fileName[::-1].find('/'):]\n",
    "    datasetFile = datasetFile[:datasetFile.find('.')]\n",
    "    a = datasetFile[:datasetFile.find('_')]\n",
    "    b = datasetFile[-datasetFile[::-1].find('_'):]\n",
    "    return a+b\n",
    "\n",
    "def separate_by_session(df):\n",
    "    sessions = df.groupby(axis=0, level = 'session')\n",
    "    x = []; y = []\n",
    "    for label, sess in sessions:\n",
    "        x_, y_ = sequence_to_xy(sess.values)\n",
    "        x.append(x_)\n",
    "        y.append(y_)\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x, y\n",
    "\n",
    "def split_sessions(x, y, mu = 20, sigma = 7, min_seq_length = 7):\n",
    "    new_x = []; new_y = []\n",
    "    for session_x, session_y in zip(x, y):\n",
    "        k_old = 0\n",
    "        finished = 0\n",
    "        noTrials = len(session_x)\n",
    "        while finished == 0:\n",
    "            #sample length of sequence from normal distribution\n",
    "            k_new = k_old + \\\n",
    "                max(min_seq_length, int(np.floor(np.random.normal(mu, sigma))))\n",
    "\n",
    "            new_x.append(session_x[k_old: k_old + k_new])\n",
    "            new_y.append(session_y[k_old: k_old + k_new])\n",
    "            #shifting index\n",
    "            k_old = k_new\n",
    "\n",
    "            if noTrials - k_old < mu:\n",
    "                finished = 1\n",
    "                #still want to keep min sequence legnth requirements\n",
    "                #otherwise little chunk of data gets thrown out :'(\n",
    "                if (noTrials - k_old) > min_seq_length:\n",
    "                    new_x.append(session_x[k_old:])\n",
    "                    new_y.append(session_y[k_old:])\n",
    "\n",
    "    return new_x, new_y\n",
    "\n",
    "\n",
    "def sequence_to_xy(seq):\n",
    "    return seq[:-1], seq[1:]\n",
    "\n",
    "def add_start_token(seq, start_token):\n",
    "    #adding start token to each session\n",
    "    sessions = seq.groupby(axis = 0, level = 'session')\n",
    "    mod = sessions.get_group('S0')\n",
    "    mod.loc[pd.IndexSlice['S0', 'B1', -1]] = start_token\n",
    "    for label, sess in sessions:\n",
    "        if label != 'S0':\n",
    "            sess.loc[pd.IndexSlice[label, 'B1', -1]] = start_token\n",
    "            mod = pd.concat([mod, sess], axis=0)\n",
    "    mod.sort_index(axis=0, inplace = True)\n",
    "    return mod\n",
    "\n",
    "\n",
    "\n",
    "def dataframe_to_sequences(fileName, target):\n",
    "    #loading data\n",
    "    df = pickle.load(open(fileName, 'rb'))\n",
    "\n",
    "    #changing var to int type\n",
    "    choice_only = df['choice', 0].astype('int64')\n",
    "    #appending start token\n",
    "    choice_only = add_start_token(choice_only, 2)\n",
    "\n",
    "    #including reward information\n",
    "    choice_reward = df['choice',0] * 2 + df['reward',0]\n",
    "    choice_reward = choice_reward.astype('int64')\n",
    "    choice_reward = add_start_token(choice_reward, 4)\n",
    "\n",
    "    seq_type = {'choice_only': choice_only, 'choice_reward': choice_reward}\n",
    "\n",
    "    for sequence_option in seq_type.keys():\n",
    "        input_sequence = seq_type[sequence_option]\n",
    "        #each sequence is a session\n",
    "        x, y = separate_by_session(input_sequence)\n",
    "        #each sequence is of length drawn from normal(mu = 20, sigma= 7)\n",
    "        x2, y2 = split_sessions(x, y, mu = 20, sigma = 7, min_seq_length = 7)\n",
    "\n",
    "        file = fileName_label(fileName)\n",
    "        pickle.dump([x,y],\n",
    "                    open(target + file + '_' + \\\n",
    "                    sequence_option + '_session_sequences.p', 'wb'))\n",
    "        pickle.dump([x2, y2],\n",
    "                    open(target + file + '_' + \\\n",
    "                    sequence_option + '_split_sequences.p', 'wb'))\n",
    "    return\n",
    "\n",
    "def split_sequences_train_test(x, y, test_size = 0.2, random_state = 17):\n",
    "    noSequences = len(x)\n",
    "    index = np.arange(noSequences)\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    cutoff = int(np.floor(noSequences * (1 - test_size)))\n",
    "    x_train = x[index[:cutoff]]\n",
    "    y_train = y[index[:cutoff]]\n",
    "    x_test = x[index[cutoff:]]\n",
    "    y_test = y[index[cutoff:]]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient and Entropy Checks\n",
    "\n",
    "Let's insantiate an RNN and make some checks. We will check if the cross-entropy is being calculated properly given the random initialization of the weight matrices Wxh, Whh, Why. We will also check if back propagation thru time was implemented properly by calculating all the gradients by shifting them by a small delta. We will also check whether all our datasets are compatible with the pipeline. This may take a while, but it's important ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checks_RNN(RNN, x, y):\n",
    "    print 'expected cross-entropy: %f' %np.log(1 + np.max(x[0]))\n",
    "    print 'actual cross-entropy: %f' %RNN.calculate_loss(x, y)    \n",
    "    #expensive, so only do one example\n",
    "    RNN.gradient_check(x[0], y[0])\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSROFC_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.155486\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.572173\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.607735\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSROFC_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.020388\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.102967\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.668069\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSROFC_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.665514\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.100121\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.705331\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.634723\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRContra_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.111488\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.634252\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.086316\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.159310\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.558210\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.143173\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.685759\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.171944\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.167647\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.631746\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.103260\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.623142\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSROFC_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 0.983551\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.083447\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.051940\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.687465\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.591893\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRContra_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.627990\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRContra_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.644779\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.145337\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.679335\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.655236\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRContra_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.078113\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.012084\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.624982\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.087886\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSROFC_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.608917\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.566161\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.261432\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.617253\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.653105\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.129730\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.121969\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.100258\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSROFC_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.647846\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRContra_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.154973\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRContra_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.641419\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSROFC_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.574749\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSROFC_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.010783\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.571053\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.113933\n",
      "Performing gradient check for parameter Wxh with size 300.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.112324\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_only_split_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.041522\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRContra_choice_reward_session_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.556335\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_reward_split_sequences.p\n",
      "expected cross-entropy: 1.609438\n",
      "actual cross-entropy: 1.621058\n",
      "Performing gradient check for parameter Wxh with size 500.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 500.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n",
      "PSRContra_choice_only_session_sequences.p\n",
      "expected cross-entropy: 1.098612\n",
      "actual cross-entropy: 1.170603\n",
      "Performing gradient check for parameter Wxh with size 300.\n",
      "Gradient check for parameter Wxh passed.\n",
      "Performing gradient check for parameter Whh with size 10000.\n",
      "Gradient check for parameter Whh passed.\n",
      "Performing gradient check for parameter Why with size 300.\n",
      "Gradient check for parameter Why passed.\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target = ROOT + '/DATA_structures/RNN_sequences/'\n",
    "\n",
    "for sequences in os.listdir(target):\n",
    "    print sequences\n",
    "    x, y = pickle.load(open(target + sequences, 'rb'))\n",
    "    elements_in_seq = np.max(x[0]) + 1\n",
    "    #initialize RNN\n",
    "    RNN = behaviorRNN(noFeatures = elements_in_seq, hidden_dim = 100, bptt_truncate = 4)\n",
    "    checks_RNN(RNN, x, y)\n",
    "    print '*' * 80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, 56 'datasets' and all gradient checks passed. That took a while. Now we are ready to train the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Network\n",
    "We will train network with 100 epochs. This means we push the dataset thru the network 100 times. We will truncate backpropagation thru time to 30 trials, which is expensive, because we want the network to learn some longer dependencies. We define some functions for saving and loading our RNNs and off we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model_parameters(outfile, model):\n",
    "    Wxh, Why, Whh = model.Wxh, model.Why, model.Whh\n",
    "    np.savez(outfile, Wxh = Wxh, Why = Why, Whh = Whh)\n",
    "    print \"Saved model parameters to %s.\" %outfile\n",
    "    return\n",
    "\n",
    "def load_model_parameters(path, model):\n",
    "    npzfile = np.load(path)\n",
    "    Wxh, Why, Whh = npzfile[\"Wxh\"], npzfile[\"Why\"], npzfile[\"Whh\"]\n",
    "    model.hidden_dim = Wxh.shape[0]\n",
    "    model.noFeatures = Wxh.shape[1]\n",
    "    model.Wxh = Wxh\n",
    "    model.Why = Why\n",
    "    model.Whh = Whh\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "DSROFC_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:03:52: Loss after num_examples_seen=0 epoch=0: 1.128256\n",
      "2018-06-26 00:04:00: Loss after num_examples_seen=40 epoch=5: 0.659024\n",
      "2018-06-26 00:04:07: Loss after num_examples_seen=80 epoch=10: 0.639959\n",
      "2018-06-26 00:04:15: Loss after num_examples_seen=120 epoch=15: 0.606577\n",
      "2018-06-26 00:04:23: Loss after num_examples_seen=160 epoch=20: 0.603817\n",
      "2018-06-26 00:04:31: Loss after num_examples_seen=200 epoch=25: 0.618549\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:04:38: Loss after num_examples_seen=240 epoch=30: 0.591685\n",
      "2018-06-26 00:04:46: Loss after num_examples_seen=280 epoch=35: 0.585868\n",
      "2018-06-26 00:04:54: Loss after num_examples_seen=320 epoch=40: 0.580041\n",
      "2018-06-26 00:05:01: Loss after num_examples_seen=360 epoch=45: 0.599485\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:05:09: Loss after num_examples_seen=400 epoch=50: 0.570332\n",
      "2018-06-26 00:05:17: Loss after num_examples_seen=440 epoch=55: 0.564594\n",
      "2018-06-26 00:05:25: Loss after num_examples_seen=480 epoch=60: 0.559398\n",
      "2018-06-26 00:05:32: Loss after num_examples_seen=520 epoch=65: 0.553865\n",
      "2018-06-26 00:05:40: Loss after num_examples_seen=560 epoch=70: 0.547834\n",
      "2018-06-26 00:05:48: Loss after num_examples_seen=600 epoch=75: 0.541260\n",
      "2018-06-26 00:05:56: Loss after num_examples_seen=640 epoch=80: 0.534511\n",
      "2018-06-26 00:06:04: Loss after num_examples_seen=680 epoch=85: 0.528392\n",
      "2018-06-26 00:06:11: Loss after num_examples_seen=720 epoch=90: 0.523106\n",
      "2018-06-26 00:06:19: Loss after num_examples_seen=760 epoch=95: 0.517277\n",
      "total training time: 2.58 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSROFC_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:06:27: Loss after num_examples_seen=0 epoch=0: 1.562101\n",
      "2018-06-26 00:07:07: Loss after num_examples_seen=895 epoch=5: 0.681852\n",
      "2018-06-26 00:07:46: Loss after num_examples_seen=1790 epoch=10: 0.660638\n",
      "2018-06-26 00:08:25: Loss after num_examples_seen=2685 epoch=15: 0.665350\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:09:05: Loss after num_examples_seen=3580 epoch=20: 0.619395\n",
      "2018-06-26 00:09:44: Loss after num_examples_seen=4475 epoch=25: 0.610911\n",
      "2018-06-26 00:10:23: Loss after num_examples_seen=5370 epoch=30: 0.592745\n",
      "2018-06-26 00:11:03: Loss after num_examples_seen=6265 epoch=35: 0.549483\n",
      "2018-06-26 00:11:42: Loss after num_examples_seen=7160 epoch=40: 0.510941\n",
      "2018-06-26 00:12:22: Loss after num_examples_seen=8055 epoch=45: 0.485638\n",
      "2018-06-26 00:13:01: Loss after num_examples_seen=8950 epoch=50: 0.470279\n",
      "2018-06-26 00:13:40: Loss after num_examples_seen=9845 epoch=55: 0.556406\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:14:20: Loss after num_examples_seen=10740 epoch=60: 0.368471\n",
      "2018-06-26 00:14:59: Loss after num_examples_seen=11635 epoch=65: 0.343888\n",
      "2018-06-26 00:15:39: Loss after num_examples_seen=12530 epoch=70: 0.347453\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 00:16:19: Loss after num_examples_seen=13425 epoch=75: 0.233281\n",
      "2018-06-26 00:16:58: Loss after num_examples_seen=14320 epoch=80: 0.212470\n",
      "2018-06-26 00:17:38: Loss after num_examples_seen=15215 epoch=85: 0.205838\n",
      "2018-06-26 00:18:17: Loss after num_examples_seen=16110 epoch=90: 0.199599\n",
      "2018-06-26 00:18:57: Loss after num_examples_seen=17005 epoch=95: 0.190379\n",
      "total training time: 13.15 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRSaline_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:19:36: Loss after num_examples_seen=0 epoch=0: 1.585556\n",
      "2018-06-26 00:19:45: Loss after num_examples_seen=40 epoch=5: 1.065691\n",
      "2018-06-26 00:19:53: Loss after num_examples_seen=80 epoch=10: 1.030337\n",
      "2018-06-26 00:20:02: Loss after num_examples_seen=120 epoch=15: 0.999575\n",
      "2018-06-26 00:20:10: Loss after num_examples_seen=160 epoch=20: 1.020363\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:20:19: Loss after num_examples_seen=200 epoch=25: 0.943264\n",
      "2018-06-26 00:20:28: Loss after num_examples_seen=240 epoch=30: 0.917935\n",
      "2018-06-26 00:20:36: Loss after num_examples_seen=280 epoch=35: 0.907257\n",
      "2018-06-26 00:20:45: Loss after num_examples_seen=320 epoch=40: 0.857530\n",
      "2018-06-26 00:20:53: Loss after num_examples_seen=360 epoch=45: 0.821693\n",
      "2018-06-26 00:21:02: Loss after num_examples_seen=400 epoch=50: 0.755215\n",
      "2018-06-26 00:21:10: Loss after num_examples_seen=440 epoch=55: 0.789050\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:21:19: Loss after num_examples_seen=480 epoch=60: 0.680962\n",
      "2018-06-26 00:21:27: Loss after num_examples_seen=520 epoch=65: 0.620273\n",
      "2018-06-26 00:21:36: Loss after num_examples_seen=560 epoch=70: 0.548129\n",
      "2018-06-26 00:21:44: Loss after num_examples_seen=600 epoch=75: 0.542165\n",
      "2018-06-26 00:21:53: Loss after num_examples_seen=640 epoch=80: 0.426439\n",
      "2018-06-26 00:22:01: Loss after num_examples_seen=680 epoch=85: 0.367024\n",
      "2018-06-26 00:22:10: Loss after num_examples_seen=720 epoch=90: 0.352494\n",
      "2018-06-26 00:22:19: Loss after num_examples_seen=760 epoch=95: 0.517104\n",
      "Setting learning rate to 0.000625\n",
      "total training time: 2.85 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMidTraining_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSROFC_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:22:27: Loss after num_examples_seen=0 epoch=0: 1.164207\n",
      "2018-06-26 00:22:43: Loss after num_examples_seen=270 epoch=5: 0.676849\n",
      "2018-06-26 00:23:00: Loss after num_examples_seen=540 epoch=10: 0.664989\n",
      "2018-06-26 00:23:15: Loss after num_examples_seen=810 epoch=15: 0.659516\n",
      "2018-06-26 00:23:31: Loss after num_examples_seen=1080 epoch=20: 0.650163\n",
      "2018-06-26 00:23:47: Loss after num_examples_seen=1350 epoch=25: 0.634541\n",
      "2018-06-26 00:24:03: Loss after num_examples_seen=1620 epoch=30: 0.599628\n",
      "2018-06-26 00:24:19: Loss after num_examples_seen=1890 epoch=35: 0.934091\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:24:35: Loss after num_examples_seen=2160 epoch=40: 0.443311\n",
      "2018-06-26 00:24:51: Loss after num_examples_seen=2430 epoch=45: 0.409210\n",
      "2018-06-26 00:25:07: Loss after num_examples_seen=2700 epoch=50: 0.390059\n",
      "2018-06-26 00:25:23: Loss after num_examples_seen=2970 epoch=55: 0.297870\n",
      "2018-06-26 00:25:39: Loss after num_examples_seen=3240 epoch=60: 0.473366\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:25:55: Loss after num_examples_seen=3510 epoch=65: 0.184890\n",
      "2018-06-26 00:26:12: Loss after num_examples_seen=3780 epoch=70: 0.160040\n",
      "2018-06-26 00:26:30: Loss after num_examples_seen=4050 epoch=75: 0.140167\n",
      "2018-06-26 00:26:46: Loss after num_examples_seen=4320 epoch=80: 0.125887\n",
      "2018-06-26 00:27:02: Loss after num_examples_seen=4590 epoch=85: 0.115850\n",
      "2018-06-26 00:27:18: Loss after num_examples_seen=4860 epoch=90: 0.112181\n",
      "2018-06-26 00:27:34: Loss after num_examples_seen=5130 epoch=95: 0.107318\n",
      "total training time: 5.39 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSROFC_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:27:50: Loss after num_examples_seen=0 epoch=0: 1.230688\n",
      "2018-06-26 00:28:01: Loss after num_examples_seen=40 epoch=5: 0.550558\n",
      "2018-06-26 00:28:12: Loss after num_examples_seen=80 epoch=10: 0.551639\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:28:23: Loss after num_examples_seen=120 epoch=15: 0.520738\n",
      "2018-06-26 00:28:35: Loss after num_examples_seen=160 epoch=20: 0.519176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 00:28:46: Loss after num_examples_seen=200 epoch=25: 0.519062\n",
      "2018-06-26 00:28:58: Loss after num_examples_seen=240 epoch=30: 0.520176\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:29:10: Loss after num_examples_seen=280 epoch=35: 0.491815\n",
      "2018-06-26 00:29:22: Loss after num_examples_seen=320 epoch=40: 0.488586\n",
      "2018-06-26 00:29:35: Loss after num_examples_seen=360 epoch=45: 0.486206\n",
      "2018-06-26 00:29:48: Loss after num_examples_seen=400 epoch=50: 0.479150\n",
      "2018-06-26 00:30:00: Loss after num_examples_seen=440 epoch=55: 0.464414\n",
      "2018-06-26 00:30:13: Loss after num_examples_seen=480 epoch=60: 0.457738\n",
      "2018-06-26 00:30:26: Loss after num_examples_seen=520 epoch=65: 0.447186\n",
      "2018-06-26 00:30:38: Loss after num_examples_seen=560 epoch=70: 0.442184\n",
      "2018-06-26 00:30:49: Loss after num_examples_seen=600 epoch=75: 0.437104\n",
      "2018-06-26 00:31:00: Loss after num_examples_seen=640 epoch=80: 0.436556\n",
      "2018-06-26 00:31:14: Loss after num_examples_seen=680 epoch=85: 0.432128\n",
      "2018-06-26 00:31:27: Loss after num_examples_seen=720 epoch=90: 0.418500\n",
      "2018-06-26 00:31:39: Loss after num_examples_seen=760 epoch=95: 0.408906\n",
      "total training time: 3.99 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMPFC_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:31:50: Loss after num_examples_seen=0 epoch=0: 1.577342\n",
      "2018-06-26 00:32:01: Loss after num_examples_seen=40 epoch=5: 1.173194\n",
      "2018-06-26 00:32:11: Loss after num_examples_seen=80 epoch=10: 1.187051\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:32:22: Loss after num_examples_seen=120 epoch=15: 1.070814\n",
      "2018-06-26 00:32:33: Loss after num_examples_seen=160 epoch=20: 1.048573\n",
      "2018-06-26 00:32:45: Loss after num_examples_seen=200 epoch=25: 1.030697\n",
      "2018-06-26 00:32:56: Loss after num_examples_seen=240 epoch=30: 1.013163\n",
      "2018-06-26 00:33:08: Loss after num_examples_seen=280 epoch=35: 0.984827\n",
      "2018-06-26 00:33:20: Loss after num_examples_seen=320 epoch=40: 0.971029\n",
      "2018-06-26 00:33:32: Loss after num_examples_seen=360 epoch=45: 0.948115\n",
      "2018-06-26 00:33:43: Loss after num_examples_seen=400 epoch=50: 0.879421\n",
      "2018-06-26 00:33:54: Loss after num_examples_seen=440 epoch=55: 0.899668\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:34:06: Loss after num_examples_seen=480 epoch=60: 0.718348\n",
      "2018-06-26 00:34:16: Loss after num_examples_seen=520 epoch=65: 0.672760\n",
      "2018-06-26 00:34:27: Loss after num_examples_seen=560 epoch=70: 0.637263\n",
      "2018-06-26 00:34:39: Loss after num_examples_seen=600 epoch=75: 0.582316\n",
      "2018-06-26 00:34:52: Loss after num_examples_seen=640 epoch=80: 0.539075\n",
      "2018-06-26 00:35:03: Loss after num_examples_seen=680 epoch=85: 0.517116\n",
      "2018-06-26 00:35:19: Loss after num_examples_seen=720 epoch=90: 0.401089\n",
      "2018-06-26 00:35:36: Loss after num_examples_seen=760 epoch=95: 0.498033\n",
      "Setting learning rate to 0.000625\n",
      "total training time: 3.97 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRIpsi_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSROFC_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:35:48: Loss after num_examples_seen=0 epoch=0: 1.607455\n",
      "2018-06-26 00:36:07: Loss after num_examples_seen=265 epoch=5: 0.681035\n",
      "2018-06-26 00:36:28: Loss after num_examples_seen=530 epoch=10: 0.661685\n",
      "2018-06-26 00:36:49: Loss after num_examples_seen=795 epoch=15: 0.628603\n",
      "2018-06-26 00:37:08: Loss after num_examples_seen=1060 epoch=20: 0.608017\n",
      "2018-06-26 00:37:26: Loss after num_examples_seen=1325 epoch=25: 0.546771\n",
      "2018-06-26 00:37:42: Loss after num_examples_seen=1590 epoch=30: 0.528673\n",
      "2018-06-26 00:37:58: Loss after num_examples_seen=1855 epoch=35: 0.499876\n",
      "2018-06-26 00:38:16: Loss after num_examples_seen=2120 epoch=40: 0.595163\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:38:47: Loss after num_examples_seen=2385 epoch=45: 0.266093\n",
      "2018-06-26 00:39:07: Loss after num_examples_seen=2650 epoch=50: 0.204323\n",
      "2018-06-26 00:39:24: Loss after num_examples_seen=2915 epoch=55: 0.169149\n",
      "2018-06-26 00:39:42: Loss after num_examples_seen=3180 epoch=60: 0.152802\n",
      "2018-06-26 00:39:59: Loss after num_examples_seen=3445 epoch=65: 0.567352\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:40:22: Loss after num_examples_seen=3710 epoch=70: 0.188881\n",
      "2018-06-26 00:40:38: Loss after num_examples_seen=3975 epoch=75: 0.142861\n",
      "2018-06-26 00:40:56: Loss after num_examples_seen=4240 epoch=80: 0.123131\n",
      "2018-06-26 00:41:15: Loss after num_examples_seen=4505 epoch=85: 0.110552\n",
      "2018-06-26 00:41:38: Loss after num_examples_seen=4770 epoch=90: 0.101024\n",
      "2018-06-26 00:41:57: Loss after num_examples_seen=5035 epoch=95: 0.097074\n",
      "total training time: 6.45 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSROFC_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:42:15: Loss after num_examples_seen=0 epoch=0: 1.127636\n",
      "2018-06-26 00:42:54: Loss after num_examples_seen=175 epoch=5: 0.641964\n",
      "2018-06-26 00:43:37: Loss after num_examples_seen=350 epoch=10: 0.629782\n",
      "2018-06-26 00:44:17: Loss after num_examples_seen=525 epoch=15: 0.622898\n",
      "2018-06-26 00:45:03: Loss after num_examples_seen=700 epoch=20: 0.604911\n",
      "2018-06-26 00:45:43: Loss after num_examples_seen=875 epoch=25: 0.613127\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 00:46:18: Loss after num_examples_seen=1050 epoch=30: 0.568539\n",
      "2018-06-26 00:46:54: Loss after num_examples_seen=1225 epoch=35: 0.560837\n",
      "2018-06-26 00:47:33: Loss after num_examples_seen=1400 epoch=40: 0.553480\n",
      "2018-06-26 00:48:06: Loss after num_examples_seen=1575 epoch=45: 0.582689\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 00:48:38: Loss after num_examples_seen=1750 epoch=50: 0.522785\n",
      "2018-06-26 00:49:15: Loss after num_examples_seen=1925 epoch=55: 0.515971\n",
      "2018-06-26 00:50:13: Loss after num_examples_seen=2100 epoch=60: 0.536561\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 00:51:03: Loss after num_examples_seen=2275 epoch=65: 0.518210\n",
      "2018-06-26 00:51:56: Loss after num_examples_seen=2450 epoch=70: 0.495306\n",
      "2018-06-26 00:52:50: Loss after num_examples_seen=2625 epoch=75: 0.472037\n",
      "2018-06-26 00:53:44: Loss after num_examples_seen=2800 epoch=80: 0.464332\n",
      "2018-06-26 00:54:41: Loss after num_examples_seen=2975 epoch=85: 0.607052\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 00:55:24: Loss after num_examples_seen=3150 epoch=90: 0.432722\n",
      "2018-06-26 00:56:12: Loss after num_examples_seen=3325 epoch=95: 0.416477\n",
      "total training time: 14.68 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRSaline_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 00:56:56: Loss after num_examples_seen=0 epoch=0: 1.678769\n",
      "2018-06-26 00:57:26: Loss after num_examples_seen=335 epoch=5: 0.555982\n",
      "2018-06-26 00:57:53: Loss after num_examples_seen=670 epoch=10: 0.531496\n",
      "2018-06-26 00:58:23: Loss after num_examples_seen=1005 epoch=15: 0.509564\n",
      "2018-06-26 00:58:55: Loss after num_examples_seen=1340 epoch=20: 0.487669\n",
      "2018-06-26 00:59:26: Loss after num_examples_seen=1675 epoch=25: 0.457854\n",
      "2018-06-26 00:59:51: Loss after num_examples_seen=2010 epoch=30: 0.415337\n",
      "2018-06-26 01:00:25: Loss after num_examples_seen=2345 epoch=35: 0.408909\n",
      "2018-06-26 01:00:59: Loss after num_examples_seen=2680 epoch=40: 0.368298\n",
      "2018-06-26 01:01:25: Loss after num_examples_seen=3015 epoch=45: 0.855296\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:01:56: Loss after num_examples_seen=3350 epoch=50: 0.590340\n",
      "2018-06-26 01:02:19: Loss after num_examples_seen=3685 epoch=55: 0.537214\n",
      "2018-06-26 01:02:44: Loss after num_examples_seen=4020 epoch=60: 0.530442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 01:03:07: Loss after num_examples_seen=4355 epoch=65: 0.664002\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 01:03:34: Loss after num_examples_seen=4690 epoch=70: 0.539252\n",
      "2018-06-26 01:04:07: Loss after num_examples_seen=5025 epoch=75: 0.526641\n",
      "2018-06-26 01:04:36: Loss after num_examples_seen=5360 epoch=80: 0.507189\n",
      "2018-06-26 01:05:09: Loss after num_examples_seen=5695 epoch=85: 0.494504\n",
      "2018-06-26 01:05:45: Loss after num_examples_seen=6030 epoch=90: 0.480496\n",
      "2018-06-26 01:06:13: Loss after num_examples_seen=6365 epoch=95: 0.468315\n",
      "total training time: 9.76 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMPFC_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 01:06:42: Loss after num_examples_seen=0 epoch=0: 1.592387\n",
      "2018-06-26 01:08:03: Loss after num_examples_seen=1105 epoch=5: 1.096687\n",
      "2018-06-26 01:09:18: Loss after num_examples_seen=2210 epoch=10: 1.076107\n",
      "2018-06-26 01:10:25: Loss after num_examples_seen=3315 epoch=15: 1.100377\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:11:34: Loss after num_examples_seen=4420 epoch=20: 0.996039\n",
      "2018-06-26 01:13:01: Loss after num_examples_seen=5525 epoch=25: 1.037684\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 01:16:56: Loss after num_examples_seen=6630 epoch=30: 0.821602\n",
      "2018-06-26 01:18:53: Loss after num_examples_seen=7735 epoch=35: 0.775330\n",
      "2018-06-26 01:20:01: Loss after num_examples_seen=8840 epoch=40: 0.741832\n",
      "2018-06-26 01:21:07: Loss after num_examples_seen=9945 epoch=45: 0.767720\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 01:22:14: Loss after num_examples_seen=11050 epoch=50: 0.546751\n",
      "2018-06-26 01:23:24: Loss after num_examples_seen=12155 epoch=55: 0.626865\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 01:24:35: Loss after num_examples_seen=13260 epoch=60: 0.416702\n",
      "2018-06-26 01:25:45: Loss after num_examples_seen=14365 epoch=65: 0.402196\n",
      "2018-06-26 01:27:31: Loss after num_examples_seen=15470 epoch=70: 0.387049\n",
      "2018-06-26 01:29:17: Loss after num_examples_seen=16575 epoch=75: 0.355218\n",
      "2018-06-26 01:30:29: Loss after num_examples_seen=17680 epoch=80: 0.382431\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-26 01:31:41: Loss after num_examples_seen=18785 epoch=85: 0.290397\n",
      "2018-06-26 01:32:51: Loss after num_examples_seen=19890 epoch=90: 0.282289\n",
      "2018-06-26 01:34:01: Loss after num_examples_seen=20995 epoch=95: 0.271132\n",
      "total training time: 28.51 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRSaline_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRContra_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 01:35:12: Loss after num_examples_seen=0 epoch=0: 1.102664\n",
      "2018-06-26 01:35:32: Loss after num_examples_seen=300 epoch=5: 0.622373\n",
      "2018-06-26 01:35:53: Loss after num_examples_seen=600 epoch=10: 0.622375\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:36:12: Loss after num_examples_seen=900 epoch=15: 0.594420\n",
      "2018-06-26 01:36:34: Loss after num_examples_seen=1200 epoch=20: 0.587839\n",
      "2018-06-26 01:36:56: Loss after num_examples_seen=1500 epoch=25: 0.575821\n",
      "2018-06-26 01:37:16: Loss after num_examples_seen=1800 epoch=30: 0.569608\n",
      "2018-06-26 01:37:35: Loss after num_examples_seen=2100 epoch=35: 0.547755\n",
      "2018-06-26 01:37:54: Loss after num_examples_seen=2400 epoch=40: 0.525560\n",
      "2018-06-26 01:38:13: Loss after num_examples_seen=2700 epoch=45: 0.519366\n",
      "2018-06-26 01:38:33: Loss after num_examples_seen=3000 epoch=50: 0.496384\n",
      "2018-06-26 01:38:52: Loss after num_examples_seen=3300 epoch=55: 0.476129\n",
      "2018-06-26 01:39:12: Loss after num_examples_seen=3600 epoch=60: 0.447205\n",
      "2018-06-26 01:39:31: Loss after num_examples_seen=3900 epoch=65: 0.470023\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 01:39:50: Loss after num_examples_seen=4200 epoch=70: 0.320751\n",
      "2018-06-26 01:40:09: Loss after num_examples_seen=4500 epoch=75: 0.322981\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 01:40:40: Loss after num_examples_seen=4800 epoch=80: 0.224128\n",
      "2018-06-26 01:41:09: Loss after num_examples_seen=5100 epoch=85: 0.204602\n",
      "2018-06-26 01:41:34: Loss after num_examples_seen=5400 epoch=90: 0.225448\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 01:41:54: Loss after num_examples_seen=5700 epoch=95: 0.167607\n",
      "total training time: 7.15 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRContra_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 01:42:22: Loss after num_examples_seen=0 epoch=0: 1.597307\n",
      "2018-06-26 01:42:52: Loss after num_examples_seen=270 epoch=5: 1.087977\n",
      "2018-06-26 01:43:15: Loss after num_examples_seen=540 epoch=10: 1.040704\n",
      "2018-06-26 01:43:35: Loss after num_examples_seen=810 epoch=15: 1.019467\n",
      "2018-06-26 01:43:57: Loss after num_examples_seen=1080 epoch=20: 0.945117\n",
      "2018-06-26 01:44:16: Loss after num_examples_seen=1350 epoch=25: 0.872022\n",
      "2018-06-26 01:44:37: Loss after num_examples_seen=1620 epoch=30: 0.823207\n",
      "2018-06-26 01:45:00: Loss after num_examples_seen=1890 epoch=35: 1.383911\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:45:20: Loss after num_examples_seen=2160 epoch=40: 1.147124\n",
      "2018-06-26 01:45:37: Loss after num_examples_seen=2430 epoch=45: 1.090483\n",
      "2018-06-26 01:45:54: Loss after num_examples_seen=2700 epoch=50: 1.119875\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 01:46:12: Loss after num_examples_seen=2970 epoch=55: 1.059896\n",
      "2018-06-26 01:46:30: Loss after num_examples_seen=3240 epoch=60: 1.071334\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 01:46:47: Loss after num_examples_seen=3510 epoch=65: 1.002400\n",
      "2018-06-26 01:47:05: Loss after num_examples_seen=3780 epoch=70: 1.025149\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 01:47:23: Loss after num_examples_seen=4050 epoch=75: 0.983743\n",
      "2018-06-26 01:47:41: Loss after num_examples_seen=4320 epoch=80: 0.968145\n",
      "2018-06-26 01:47:58: Loss after num_examples_seen=4590 epoch=85: 0.952266\n",
      "2018-06-26 01:48:16: Loss after num_examples_seen=4860 epoch=90: 0.937672\n",
      "2018-06-26 01:48:34: Loss after num_examples_seen=5130 epoch=95: 0.923571\n",
      "total training time: 6.53 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRIpsi_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 01:48:53: Loss after num_examples_seen=0 epoch=0: 1.236727\n",
      "2018-06-26 01:49:02: Loss after num_examples_seen=40 epoch=5: 0.600483\n",
      "2018-06-26 01:49:10: Loss after num_examples_seen=80 epoch=10: 0.576275\n",
      "2018-06-26 01:49:18: Loss after num_examples_seen=120 epoch=15: 0.586716\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:49:26: Loss after num_examples_seen=160 epoch=20: 0.555598\n",
      "2018-06-26 01:49:33: Loss after num_examples_seen=200 epoch=25: 0.552648\n",
      "2018-06-26 01:49:40: Loss after num_examples_seen=240 epoch=30: 0.545391\n",
      "2018-06-26 01:49:47: Loss after num_examples_seen=280 epoch=35: 0.539796\n",
      "2018-06-26 01:49:53: Loss after num_examples_seen=320 epoch=40: 0.534012\n",
      "2018-06-26 01:50:02: Loss after num_examples_seen=360 epoch=45: 0.528783\n",
      "2018-06-26 01:50:09: Loss after num_examples_seen=400 epoch=50: 0.527878\n",
      "2018-06-26 01:50:15: Loss after num_examples_seen=440 epoch=55: 0.520889\n",
      "2018-06-26 01:50:23: Loss after num_examples_seen=480 epoch=60: 0.517563\n",
      "2018-06-26 01:50:30: Loss after num_examples_seen=520 epoch=65: 0.510343\n",
      "2018-06-26 01:50:37: Loss after num_examples_seen=560 epoch=70: 0.506377\n",
      "2018-06-26 01:50:44: Loss after num_examples_seen=600 epoch=75: 0.501638\n",
      "2018-06-26 01:50:51: Loss after num_examples_seen=640 epoch=80: 0.472988\n",
      "2018-06-26 01:50:59: Loss after num_examples_seen=680 epoch=85: 0.588139\n",
      "Setting learning rate to 0.001250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 01:51:07: Loss after num_examples_seen=720 epoch=90: 0.415931\n",
      "2018-06-26 01:51:14: Loss after num_examples_seen=760 epoch=95: 0.397498\n",
      "total training time: 2.47 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRFirstTraining_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 01:51:22: Loss after num_examples_seen=0 epoch=0: 1.183222\n",
      "2018-06-26 01:51:31: Loss after num_examples_seen=40 epoch=5: 0.668670\n",
      "2018-06-26 01:51:40: Loss after num_examples_seen=80 epoch=10: 0.652787\n",
      "2018-06-26 01:51:49: Loss after num_examples_seen=120 epoch=15: 0.652452\n",
      "2018-06-26 01:51:58: Loss after num_examples_seen=160 epoch=20: 0.649184\n",
      "2018-06-26 01:52:07: Loss after num_examples_seen=200 epoch=25: 0.639597\n",
      "2018-06-26 01:52:15: Loss after num_examples_seen=240 epoch=30: 0.698147\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:52:24: Loss after num_examples_seen=280 epoch=35: 0.634732\n",
      "2018-06-26 01:52:33: Loss after num_examples_seen=320 epoch=40: 0.628990\n",
      "2018-06-26 01:52:41: Loss after num_examples_seen=360 epoch=45: 0.622732\n",
      "2018-06-26 01:52:50: Loss after num_examples_seen=400 epoch=50: 0.618650\n",
      "2018-06-26 01:53:00: Loss after num_examples_seen=440 epoch=55: 0.611790\n",
      "2018-06-26 01:53:08: Loss after num_examples_seen=480 epoch=60: 0.596246\n",
      "2018-06-26 01:53:17: Loss after num_examples_seen=520 epoch=65: 0.578503\n",
      "2018-06-26 01:53:26: Loss after num_examples_seen=560 epoch=70: 0.555940\n",
      "2018-06-26 01:53:35: Loss after num_examples_seen=600 epoch=75: 0.558245\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 01:53:44: Loss after num_examples_seen=640 epoch=80: 0.495614\n",
      "2018-06-26 01:53:52: Loss after num_examples_seen=680 epoch=85: 0.475943\n",
      "2018-06-26 01:54:02: Loss after num_examples_seen=720 epoch=90: 0.456605\n",
      "2018-06-26 01:54:11: Loss after num_examples_seen=760 epoch=95: 0.447661\n",
      "total training time: 2.97 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMidTraining_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 01:54:19: Loss after num_examples_seen=0 epoch=0: 1.572162\n",
      "2018-06-26 01:54:25: Loss after num_examples_seen=40 epoch=5: 0.740663\n",
      "2018-06-26 01:54:30: Loss after num_examples_seen=80 epoch=10: 0.691971\n",
      "2018-06-26 01:54:35: Loss after num_examples_seen=120 epoch=15: 0.679134\n",
      "2018-06-26 01:54:40: Loss after num_examples_seen=160 epoch=20: 0.714203\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:54:46: Loss after num_examples_seen=200 epoch=25: 0.613879\n",
      "2018-06-26 01:54:51: Loss after num_examples_seen=240 epoch=30: 0.605279\n",
      "2018-06-26 01:54:56: Loss after num_examples_seen=280 epoch=35: 0.592226\n",
      "2018-06-26 01:55:02: Loss after num_examples_seen=320 epoch=40: 0.568897\n",
      "2018-06-26 01:55:07: Loss after num_examples_seen=360 epoch=45: 0.593002\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 01:55:12: Loss after num_examples_seen=400 epoch=50: 0.512798\n",
      "2018-06-26 01:55:17: Loss after num_examples_seen=440 epoch=55: 0.497189\n",
      "2018-06-26 01:55:23: Loss after num_examples_seen=480 epoch=60: 0.480338\n",
      "2018-06-26 01:55:28: Loss after num_examples_seen=520 epoch=65: 0.462006\n",
      "2018-06-26 01:55:33: Loss after num_examples_seen=560 epoch=70: 0.477811\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 01:55:38: Loss after num_examples_seen=600 epoch=75: 0.416623\n",
      "2018-06-26 01:55:44: Loss after num_examples_seen=640 epoch=80: 0.402732\n",
      "2018-06-26 01:55:49: Loss after num_examples_seen=680 epoch=85: 0.390816\n",
      "2018-06-26 01:55:54: Loss after num_examples_seen=720 epoch=90: 0.384869\n",
      "2018-06-26 01:55:59: Loss after num_examples_seen=760 epoch=95: 0.371399\n",
      "total training time: 1.75 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRFirstTraining_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 01:56:05: Loss after num_examples_seen=0 epoch=0: 1.107557\n",
      "2018-06-26 01:56:41: Loss after num_examples_seen=160 epoch=5: 0.674838\n",
      "2018-06-26 01:57:18: Loss after num_examples_seen=320 epoch=10: 0.674832\n",
      "2018-06-26 01:57:55: Loss after num_examples_seen=480 epoch=15: 0.675749\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 01:58:32: Loss after num_examples_seen=640 epoch=20: 0.666720\n",
      "2018-06-26 01:59:09: Loss after num_examples_seen=800 epoch=25: 0.668462\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 01:59:46: Loss after num_examples_seen=960 epoch=30: 0.662219\n",
      "2018-06-26 02:00:23: Loss after num_examples_seen=1120 epoch=35: 0.668773\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 02:01:00: Loss after num_examples_seen=1280 epoch=40: 0.657249\n",
      "2018-06-26 02:01:37: Loss after num_examples_seen=1440 epoch=45: 0.655481\n",
      "2018-06-26 02:02:14: Loss after num_examples_seen=1600 epoch=50: 0.650920\n",
      "2018-06-26 02:02:51: Loss after num_examples_seen=1760 epoch=55: 0.638886\n",
      "2018-06-26 02:03:29: Loss after num_examples_seen=1920 epoch=60: 0.638081\n",
      "2018-06-26 02:04:06: Loss after num_examples_seen=2080 epoch=65: 0.642784\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 02:04:43: Loss after num_examples_seen=2240 epoch=70: 0.631972\n",
      "2018-06-26 02:05:20: Loss after num_examples_seen=2400 epoch=75: 0.631034\n",
      "2018-06-26 02:05:57: Loss after num_examples_seen=2560 epoch=80: 0.630408\n",
      "2018-06-26 02:06:33: Loss after num_examples_seen=2720 epoch=85: 0.631134\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-26 02:07:11: Loss after num_examples_seen=2880 epoch=90: 0.630349\n",
      "2018-06-26 02:07:48: Loss after num_examples_seen=3040 epoch=95: 0.629348\n",
      "total training time: 12.34 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRSaline_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:08:25: Loss after num_examples_seen=0 epoch=0: 1.544608\n",
      "2018-06-26 02:08:34: Loss after num_examples_seen=40 epoch=5: 0.765641\n",
      "2018-06-26 02:08:42: Loss after num_examples_seen=80 epoch=10: 0.721935\n",
      "2018-06-26 02:08:51: Loss after num_examples_seen=120 epoch=15: 0.770572\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:09:00: Loss after num_examples_seen=160 epoch=20: 0.664342\n",
      "2018-06-26 02:09:09: Loss after num_examples_seen=200 epoch=25: 0.660144\n",
      "2018-06-26 02:09:17: Loss after num_examples_seen=240 epoch=30: 0.664670\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:09:26: Loss after num_examples_seen=280 epoch=35: 0.620893\n",
      "2018-06-26 02:09:35: Loss after num_examples_seen=320 epoch=40: 0.611862\n",
      "2018-06-26 02:09:43: Loss after num_examples_seen=360 epoch=45: 0.603175\n",
      "2018-06-26 02:09:52: Loss after num_examples_seen=400 epoch=50: 0.593815\n",
      "2018-06-26 02:10:01: Loss after num_examples_seen=440 epoch=55: 0.586317\n",
      "2018-06-26 02:10:09: Loss after num_examples_seen=480 epoch=60: 0.578035\n",
      "2018-06-26 02:10:18: Loss after num_examples_seen=520 epoch=65: 0.570825\n",
      "2018-06-26 02:10:27: Loss after num_examples_seen=560 epoch=70: 0.558480\n",
      "2018-06-26 02:10:35: Loss after num_examples_seen=600 epoch=75: 0.550588\n",
      "2018-06-26 02:10:44: Loss after num_examples_seen=640 epoch=80: 0.532913\n",
      "2018-06-26 02:10:53: Loss after num_examples_seen=680 epoch=85: 0.530924\n",
      "2018-06-26 02:11:01: Loss after num_examples_seen=720 epoch=90: 0.508750\n",
      "2018-06-26 02:11:10: Loss after num_examples_seen=760 epoch=95: 0.504658\n",
      "total training time: 2.90 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRIpsi_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_only_split_sequences.p\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 02:11:19: Loss after num_examples_seen=0 epoch=0: 1.119344\n",
      "2018-06-26 02:11:58: Loss after num_examples_seen=910 epoch=5: 0.627003\n",
      "2018-06-26 02:12:38: Loss after num_examples_seen=1820 epoch=10: 0.614232\n",
      "2018-06-26 02:13:17: Loss after num_examples_seen=2730 epoch=15: 0.606292\n",
      "2018-06-26 02:13:57: Loss after num_examples_seen=3640 epoch=20: 0.597549\n",
      "2018-06-26 02:14:36: Loss after num_examples_seen=4550 epoch=25: 0.605464\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:15:16: Loss after num_examples_seen=5460 epoch=30: 0.569517\n",
      "2018-06-26 02:15:55: Loss after num_examples_seen=6370 epoch=35: 0.567437\n",
      "2018-06-26 02:16:35: Loss after num_examples_seen=7280 epoch=40: 0.556669\n",
      "2018-06-26 02:17:15: Loss after num_examples_seen=8190 epoch=45: 0.540746\n",
      "2018-06-26 02:17:54: Loss after num_examples_seen=9100 epoch=50: 0.528079\n",
      "2018-06-26 02:18:33: Loss after num_examples_seen=10010 epoch=55: 0.579257\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:19:13: Loss after num_examples_seen=10920 epoch=60: 0.447233\n",
      "2018-06-26 02:19:53: Loss after num_examples_seen=11830 epoch=65: 0.431043\n",
      "2018-06-26 02:20:32: Loss after num_examples_seen=12740 epoch=70: 0.411957\n",
      "2018-06-26 02:21:12: Loss after num_examples_seen=13650 epoch=75: 0.403900\n",
      "2018-06-26 02:21:51: Loss after num_examples_seen=14560 epoch=80: 0.435699\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 02:22:30: Loss after num_examples_seen=15470 epoch=85: 0.319433\n",
      "2018-06-26 02:23:10: Loss after num_examples_seen=16380 epoch=90: 0.302825\n",
      "2018-06-26 02:23:49: Loss after num_examples_seen=17290 epoch=95: 0.305629\n",
      "Setting learning rate to 0.000313\n",
      "total training time: 13.16 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRSaline_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:24:29: Loss after num_examples_seen=0 epoch=0: 1.162453\n",
      "2018-06-26 02:24:37: Loss after num_examples_seen=210 epoch=5: 0.589182\n",
      "2018-06-26 02:24:46: Loss after num_examples_seen=420 epoch=10: 0.579467\n",
      "2018-06-26 02:24:54: Loss after num_examples_seen=630 epoch=15: 0.587680\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:25:02: Loss after num_examples_seen=840 epoch=20: 0.549371\n",
      "2018-06-26 02:25:11: Loss after num_examples_seen=1050 epoch=25: 0.544686\n",
      "2018-06-26 02:25:19: Loss after num_examples_seen=1260 epoch=30: 0.535709\n",
      "2018-06-26 02:25:28: Loss after num_examples_seen=1470 epoch=35: 0.532397\n",
      "2018-06-26 02:25:36: Loss after num_examples_seen=1680 epoch=40: 0.524102\n",
      "2018-06-26 02:25:45: Loss after num_examples_seen=1890 epoch=45: 0.518882\n",
      "2018-06-26 02:25:53: Loss after num_examples_seen=2100 epoch=50: 0.510259\n",
      "2018-06-26 02:26:02: Loss after num_examples_seen=2310 epoch=55: 0.496624\n",
      "2018-06-26 02:26:10: Loss after num_examples_seen=2520 epoch=60: 0.484701\n",
      "2018-06-26 02:26:19: Loss after num_examples_seen=2730 epoch=65: 0.465490\n",
      "2018-06-26 02:26:27: Loss after num_examples_seen=2940 epoch=70: 0.445191\n",
      "2018-06-26 02:26:35: Loss after num_examples_seen=3150 epoch=75: 0.537566\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:26:44: Loss after num_examples_seen=3360 epoch=80: 0.363826\n",
      "2018-06-26 02:26:52: Loss after num_examples_seen=3570 epoch=85: 0.335420\n",
      "2018-06-26 02:27:01: Loss after num_examples_seen=3780 epoch=90: 0.307432\n",
      "2018-06-26 02:27:09: Loss after num_examples_seen=3990 epoch=95: 0.282133\n",
      "total training time: 2.82 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRFirstTraining_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:27:18: Loss after num_examples_seen=0 epoch=0: 1.612408\n",
      "2018-06-26 02:27:27: Loss after num_examples_seen=195 epoch=5: 1.014338\n",
      "2018-06-26 02:27:36: Loss after num_examples_seen=390 epoch=10: 0.979241\n",
      "2018-06-26 02:27:45: Loss after num_examples_seen=585 epoch=15: 1.079095\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:27:53: Loss after num_examples_seen=780 epoch=20: 0.915232\n",
      "2018-06-26 02:28:02: Loss after num_examples_seen=975 epoch=25: 0.864422\n",
      "2018-06-26 02:28:11: Loss after num_examples_seen=1170 epoch=30: 0.778917\n",
      "2018-06-26 02:28:20: Loss after num_examples_seen=1365 epoch=35: 0.690598\n",
      "2018-06-26 02:28:29: Loss after num_examples_seen=1560 epoch=40: 0.582977\n",
      "2018-06-26 02:28:37: Loss after num_examples_seen=1755 epoch=45: 0.678923\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:28:46: Loss after num_examples_seen=1950 epoch=50: 0.354656\n",
      "2018-06-26 02:28:55: Loss after num_examples_seen=2145 epoch=55: 0.299171\n",
      "2018-06-26 02:29:04: Loss after num_examples_seen=2340 epoch=60: 0.284581\n",
      "2018-06-26 02:29:13: Loss after num_examples_seen=2535 epoch=65: 0.290918\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 02:29:22: Loss after num_examples_seen=2730 epoch=70: 0.178440\n",
      "2018-06-26 02:29:31: Loss after num_examples_seen=2925 epoch=75: 0.164290\n",
      "2018-06-26 02:29:40: Loss after num_examples_seen=3120 epoch=80: 0.153482\n",
      "2018-06-26 02:29:48: Loss after num_examples_seen=3315 epoch=85: 0.144607\n",
      "2018-06-26 02:29:57: Loss after num_examples_seen=3510 epoch=90: 0.137241\n",
      "2018-06-26 02:30:06: Loss after num_examples_seen=3705 epoch=95: 0.130585\n",
      "total training time: 2.95 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRFirstTraining_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:30:15: Loss after num_examples_seen=0 epoch=0: 1.177076\n",
      "2018-06-26 02:30:25: Loss after num_examples_seen=40 epoch=5: 0.737224\n",
      "2018-06-26 02:30:35: Loss after num_examples_seen=80 epoch=10: 0.684559\n",
      "2018-06-26 02:30:45: Loss after num_examples_seen=120 epoch=15: 0.684068\n",
      "2018-06-26 02:30:55: Loss after num_examples_seen=160 epoch=20: 0.685380\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:31:05: Loss after num_examples_seen=200 epoch=25: 0.651858\n",
      "2018-06-26 02:31:16: Loss after num_examples_seen=240 epoch=30: 0.650067\n",
      "2018-06-26 02:31:26: Loss after num_examples_seen=280 epoch=35: 0.648502\n",
      "2018-06-26 02:31:36: Loss after num_examples_seen=320 epoch=40: 0.646002\n",
      "2018-06-26 02:31:46: Loss after num_examples_seen=360 epoch=45: 0.643598\n",
      "2018-06-26 02:31:56: Loss after num_examples_seen=400 epoch=50: 0.641312\n",
      "2018-06-26 02:32:06: Loss after num_examples_seen=440 epoch=55: 0.638207\n",
      "2018-06-26 02:32:16: Loss after num_examples_seen=480 epoch=60: 0.642171\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:32:26: Loss after num_examples_seen=520 epoch=65: 0.618966\n",
      "2018-06-26 02:32:36: Loss after num_examples_seen=560 epoch=70: 0.612825\n",
      "2018-06-26 02:32:46: Loss after num_examples_seen=600 epoch=75: 0.618091\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 02:32:56: Loss after num_examples_seen=640 epoch=80: 0.606428\n",
      "2018-06-26 02:33:07: Loss after num_examples_seen=680 epoch=85: 0.603272\n",
      "2018-06-26 02:33:17: Loss after num_examples_seen=720 epoch=90: 0.596664\n",
      "2018-06-26 02:33:27: Loss after num_examples_seen=760 epoch=95: 0.596333\n",
      "total training time: 3.37 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRIpsi_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:33:37: Loss after num_examples_seen=0 epoch=0: 1.611490\n",
      "2018-06-26 02:33:50: Loss after num_examples_seen=230 epoch=5: 1.023316\n",
      "2018-06-26 02:34:03: Loss after num_examples_seen=460 epoch=10: 0.955880\n",
      "2018-06-26 02:34:16: Loss after num_examples_seen=690 epoch=15: 0.902118\n",
      "2018-06-26 02:34:30: Loss after num_examples_seen=920 epoch=20: 0.790236\n",
      "2018-06-26 02:34:43: Loss after num_examples_seen=1150 epoch=25: 0.682882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 02:34:56: Loss after num_examples_seen=1380 epoch=30: 1.193353\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:35:09: Loss after num_examples_seen=1610 epoch=35: 0.894403\n",
      "2018-06-26 02:35:22: Loss after num_examples_seen=1840 epoch=40: 0.694811\n",
      "2018-06-26 02:35:36: Loss after num_examples_seen=2070 epoch=45: 0.589203\n",
      "2018-06-26 02:35:49: Loss after num_examples_seen=2300 epoch=50: 0.901206\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:36:02: Loss after num_examples_seen=2530 epoch=55: 0.425706\n",
      "2018-06-26 02:36:15: Loss after num_examples_seen=2760 epoch=60: 0.314393\n",
      "2018-06-26 02:36:28: Loss after num_examples_seen=2990 epoch=65: 0.252732\n",
      "2018-06-26 02:36:41: Loss after num_examples_seen=3220 epoch=70: 0.215896\n",
      "2018-06-26 02:36:54: Loss after num_examples_seen=3450 epoch=75: 0.197257\n",
      "2018-06-26 02:37:08: Loss after num_examples_seen=3680 epoch=80: 0.156196\n",
      "2018-06-26 02:37:21: Loss after num_examples_seen=3910 epoch=85: 0.135128\n",
      "2018-06-26 02:37:34: Loss after num_examples_seen=4140 epoch=90: 0.120740\n",
      "2018-06-26 02:37:47: Loss after num_examples_seen=4370 epoch=95: 0.111529\n",
      "total training time: 4.39 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMidTraining_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSROFC_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:38:00: Loss after num_examples_seen=0 epoch=0: 1.183591\n",
      "2018-06-26 02:38:13: Loss after num_examples_seen=245 epoch=5: 0.630305\n",
      "2018-06-26 02:38:26: Loss after num_examples_seen=490 epoch=10: 0.617650\n",
      "2018-06-26 02:38:39: Loss after num_examples_seen=735 epoch=15: 0.607943\n",
      "2018-06-26 02:38:52: Loss after num_examples_seen=980 epoch=20: 0.596285\n",
      "2018-06-26 02:39:04: Loss after num_examples_seen=1225 epoch=25: 0.585239\n",
      "2018-06-26 02:39:17: Loss after num_examples_seen=1470 epoch=30: 0.575545\n",
      "2018-06-26 02:39:30: Loss after num_examples_seen=1715 epoch=35: 0.608618\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:39:43: Loss after num_examples_seen=1960 epoch=40: 0.514943\n",
      "2018-06-26 02:39:56: Loss after num_examples_seen=2205 epoch=45: 0.495101\n",
      "2018-06-26 02:40:08: Loss after num_examples_seen=2450 epoch=50: 0.492063\n",
      "2018-06-26 02:40:21: Loss after num_examples_seen=2695 epoch=55: 0.461907\n",
      "2018-06-26 02:40:34: Loss after num_examples_seen=2940 epoch=60: 0.624841\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:40:47: Loss after num_examples_seen=3185 epoch=65: 0.525974\n",
      "2018-06-26 02:41:00: Loss after num_examples_seen=3430 epoch=70: 0.460247\n",
      "2018-06-26 02:41:13: Loss after num_examples_seen=3675 epoch=75: 0.362988\n",
      "2018-06-26 02:41:25: Loss after num_examples_seen=3920 epoch=80: 0.320380\n",
      "2018-06-26 02:41:38: Loss after num_examples_seen=4165 epoch=85: 0.284640\n",
      "2018-06-26 02:41:51: Loss after num_examples_seen=4410 epoch=90: 0.264212\n",
      "2018-06-26 02:42:04: Loss after num_examples_seen=4655 epoch=95: 0.270990\n",
      "Setting learning rate to 0.000625\n",
      "total training time: 4.27 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSROFC_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:42:17: Loss after num_examples_seen=0 epoch=0: 1.262179\n",
      "2018-06-26 02:42:28: Loss after num_examples_seen=40 epoch=5: 0.587966\n",
      "2018-06-26 02:42:39: Loss after num_examples_seen=80 epoch=10: 0.553876\n",
      "2018-06-26 02:42:50: Loss after num_examples_seen=120 epoch=15: 0.531518\n",
      "2018-06-26 02:43:01: Loss after num_examples_seen=160 epoch=20: 0.528547\n",
      "2018-06-26 02:43:12: Loss after num_examples_seen=200 epoch=25: 9.290868\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:43:23: Loss after num_examples_seen=240 epoch=30: 4.455066\n",
      "2018-06-26 02:43:34: Loss after num_examples_seen=280 epoch=35: 3.999241\n",
      "2018-06-26 02:43:45: Loss after num_examples_seen=320 epoch=40: 3.727843\n",
      "2018-06-26 02:43:55: Loss after num_examples_seen=360 epoch=45: 4.877007\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:44:06: Loss after num_examples_seen=400 epoch=50: 2.537047\n",
      "2018-06-26 02:44:17: Loss after num_examples_seen=440 epoch=55: 2.514306\n",
      "2018-06-26 02:44:28: Loss after num_examples_seen=480 epoch=60: 2.427429\n",
      "2018-06-26 02:44:39: Loss after num_examples_seen=520 epoch=65: 2.403769\n",
      "2018-06-26 02:44:50: Loss after num_examples_seen=560 epoch=70: 2.330937\n",
      "2018-06-26 02:45:01: Loss after num_examples_seen=600 epoch=75: 2.053241\n",
      "2018-06-26 02:45:12: Loss after num_examples_seen=640 epoch=80: 1.752046\n",
      "2018-06-26 02:45:23: Loss after num_examples_seen=680 epoch=85: 1.659938\n",
      "2018-06-26 02:45:34: Loss after num_examples_seen=720 epoch=90: 1.590634\n",
      "2018-06-26 02:45:45: Loss after num_examples_seen=760 epoch=95: 1.544454\n",
      "total training time: 3.65 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMPFC_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:45:56: Loss after num_examples_seen=0 epoch=0: 1.074199\n",
      "2018-06-26 02:46:19: Loss after num_examples_seen=325 epoch=5: 0.576628\n",
      "2018-06-26 02:46:42: Loss after num_examples_seen=650 epoch=10: 0.526055\n",
      "2018-06-26 02:47:05: Loss after num_examples_seen=975 epoch=15: 0.509642\n",
      "2018-06-26 02:47:28: Loss after num_examples_seen=1300 epoch=20: 0.496148\n",
      "2018-06-26 02:47:51: Loss after num_examples_seen=1625 epoch=25: 0.475742\n",
      "2018-06-26 02:48:13: Loss after num_examples_seen=1950 epoch=30: 0.449282\n",
      "2018-06-26 02:48:36: Loss after num_examples_seen=2275 epoch=35: 2.455297\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:48:59: Loss after num_examples_seen=2600 epoch=40: 0.788587\n",
      "2018-06-26 02:49:22: Loss after num_examples_seen=2925 epoch=45: 0.640105\n",
      "2018-06-26 02:49:45: Loss after num_examples_seen=3250 epoch=50: 0.576030\n",
      "2018-06-26 02:50:08: Loss after num_examples_seen=3575 epoch=55: 0.532315\n",
      "2018-06-26 02:50:31: Loss after num_examples_seen=3900 epoch=60: 0.521221\n",
      "2018-06-26 02:50:54: Loss after num_examples_seen=4225 epoch=65: 0.517776\n",
      "2018-06-26 02:51:17: Loss after num_examples_seen=4550 epoch=70: 0.613300\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:51:39: Loss after num_examples_seen=4875 epoch=75: 0.552029\n",
      "2018-06-26 02:52:02: Loss after num_examples_seen=5200 epoch=80: 0.541892\n",
      "2018-06-26 02:52:25: Loss after num_examples_seen=5525 epoch=85: 0.529177\n",
      "2018-06-26 02:52:48: Loss after num_examples_seen=5850 epoch=90: 0.512801\n",
      "2018-06-26 02:53:11: Loss after num_examples_seen=6175 epoch=95: 0.505920\n",
      "total training time: 7.63 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMPFC_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:53:34: Loss after num_examples_seen=0 epoch=0: 1.555547\n",
      "2018-06-26 02:53:40: Loss after num_examples_seen=40 epoch=5: 0.950537\n",
      "2018-06-26 02:53:46: Loss after num_examples_seen=80 epoch=10: 0.766505\n",
      "2018-06-26 02:53:51: Loss after num_examples_seen=120 epoch=15: 0.736024\n",
      "2018-06-26 02:53:57: Loss after num_examples_seen=160 epoch=20: 0.741800\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:54:04: Loss after num_examples_seen=200 epoch=25: 0.675129\n",
      "2018-06-26 02:54:10: Loss after num_examples_seen=240 epoch=30: 0.653268\n",
      "2018-06-26 02:54:16: Loss after num_examples_seen=280 epoch=35: 0.648022\n",
      "2018-06-26 02:54:22: Loss after num_examples_seen=320 epoch=40: 0.614899\n",
      "2018-06-26 02:54:28: Loss after num_examples_seen=360 epoch=45: 0.658437\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:54:34: Loss after num_examples_seen=400 epoch=50: 0.589629\n",
      "2018-06-26 02:54:40: Loss after num_examples_seen=440 epoch=55: 0.587658\n",
      "2018-06-26 02:54:46: Loss after num_examples_seen=480 epoch=60: 0.599647\n",
      "Setting learning rate to 0.000625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 02:54:52: Loss after num_examples_seen=520 epoch=65: 0.473058\n",
      "2018-06-26 02:54:58: Loss after num_examples_seen=560 epoch=70: 0.457399\n",
      "2018-06-26 02:55:04: Loss after num_examples_seen=600 epoch=75: 0.442815\n",
      "2018-06-26 02:55:10: Loss after num_examples_seen=640 epoch=80: 0.429778\n",
      "2018-06-26 02:55:16: Loss after num_examples_seen=680 epoch=85: 0.428632\n",
      "2018-06-26 02:55:22: Loss after num_examples_seen=720 epoch=90: 0.497560\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 02:55:28: Loss after num_examples_seen=760 epoch=95: 0.376426\n",
      "total training time: 2.01 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMidTraining_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:55:34: Loss after num_examples_seen=0 epoch=0: 1.629423\n",
      "2018-06-26 02:55:45: Loss after num_examples_seen=40 epoch=5: 0.985705\n",
      "2018-06-26 02:55:56: Loss after num_examples_seen=80 epoch=10: 0.995354\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:56:07: Loss after num_examples_seen=120 epoch=15: 0.915219\n",
      "2018-06-26 02:56:18: Loss after num_examples_seen=160 epoch=20: 0.904108\n",
      "2018-06-26 02:56:29: Loss after num_examples_seen=200 epoch=25: 0.885682\n",
      "2018-06-26 02:56:40: Loss after num_examples_seen=240 epoch=30: 0.924249\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 02:56:51: Loss after num_examples_seen=280 epoch=35: 0.877209\n",
      "2018-06-26 02:57:02: Loss after num_examples_seen=320 epoch=40: 0.848245\n",
      "2018-06-26 02:57:13: Loss after num_examples_seen=360 epoch=45: 0.820724\n",
      "2018-06-26 02:57:24: Loss after num_examples_seen=400 epoch=50: 0.809178\n",
      "2018-06-26 02:57:35: Loss after num_examples_seen=440 epoch=55: 0.768930\n",
      "2018-06-26 02:57:46: Loss after num_examples_seen=480 epoch=60: 0.752335\n",
      "2018-06-26 02:57:57: Loss after num_examples_seen=520 epoch=65: 0.740045\n",
      "2018-06-26 02:58:08: Loss after num_examples_seen=560 epoch=70: 0.694145\n",
      "2018-06-26 02:58:19: Loss after num_examples_seen=600 epoch=75: 0.653163\n",
      "2018-06-26 02:58:29: Loss after num_examples_seen=640 epoch=80: 0.931105\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 02:58:41: Loss after num_examples_seen=680 epoch=85: 0.757388\n",
      "2018-06-26 02:58:52: Loss after num_examples_seen=720 epoch=90: 0.657802\n",
      "2018-06-26 02:59:03: Loss after num_examples_seen=760 epoch=95: 0.639241\n",
      "total training time: 3.66 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMPFC_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRContra_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 02:59:14: Loss after num_examples_seen=0 epoch=0: 1.594868\n",
      "2018-06-26 02:59:24: Loss after num_examples_seen=40 epoch=5: 1.161818\n",
      "2018-06-26 02:59:35: Loss after num_examples_seen=80 epoch=10: 1.181459\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 02:59:45: Loss after num_examples_seen=120 epoch=15: 1.134826\n",
      "2018-06-26 02:59:56: Loss after num_examples_seen=160 epoch=20: 1.130666\n",
      "2018-06-26 03:00:06: Loss after num_examples_seen=200 epoch=25: 1.123263\n",
      "2018-06-26 03:00:17: Loss after num_examples_seen=240 epoch=30: 1.090484\n",
      "2018-06-26 03:00:27: Loss after num_examples_seen=280 epoch=35: 1.079520\n",
      "2018-06-26 03:00:38: Loss after num_examples_seen=320 epoch=40: 1.044922\n",
      "2018-06-26 03:00:48: Loss after num_examples_seen=360 epoch=45: 1.040094\n",
      "2018-06-26 03:00:59: Loss after num_examples_seen=400 epoch=50: 0.979824\n",
      "2018-06-26 03:01:09: Loss after num_examples_seen=440 epoch=55: 1.071854\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:01:20: Loss after num_examples_seen=480 epoch=60: 0.836092\n",
      "2018-06-26 03:01:30: Loss after num_examples_seen=520 epoch=65: 0.796445\n",
      "2018-06-26 03:01:41: Loss after num_examples_seen=560 epoch=70: 0.755713\n",
      "2018-06-26 03:01:51: Loss after num_examples_seen=600 epoch=75: 0.794474\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:02:02: Loss after num_examples_seen=640 epoch=80: 0.633309\n",
      "2018-06-26 03:02:12: Loss after num_examples_seen=680 epoch=85: 0.603191\n",
      "2018-06-26 03:02:23: Loss after num_examples_seen=720 epoch=90: 0.603062\n",
      "2018-06-26 03:02:33: Loss after num_examples_seen=760 epoch=95: 0.669677\n",
      "Setting learning rate to 0.000313\n",
      "total training time: 3.51 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRContra_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRContra_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:02:44: Loss after num_examples_seen=0 epoch=0: 1.710525\n",
      "2018-06-26 03:03:03: Loss after num_examples_seen=300 epoch=5: 0.720606\n",
      "2018-06-26 03:03:23: Loss after num_examples_seen=600 epoch=10: 0.704480\n",
      "2018-06-26 03:03:42: Loss after num_examples_seen=900 epoch=15: 0.671079\n",
      "2018-06-26 03:04:01: Loss after num_examples_seen=1200 epoch=20: 0.655599\n",
      "2018-06-26 03:04:20: Loss after num_examples_seen=1500 epoch=25: 0.648444\n",
      "2018-06-26 03:04:40: Loss after num_examples_seen=1800 epoch=30: 1.175545\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:04:59: Loss after num_examples_seen=2100 epoch=35: 0.684065\n",
      "2018-06-26 03:05:18: Loss after num_examples_seen=2400 epoch=40: 0.660047\n",
      "2018-06-26 03:05:38: Loss after num_examples_seen=2700 epoch=45: 0.641661\n",
      "2018-06-26 03:05:57: Loss after num_examples_seen=3000 epoch=50: 0.618635\n",
      "2018-06-26 03:06:16: Loss after num_examples_seen=3300 epoch=55: 0.602028\n",
      "2018-06-26 03:06:35: Loss after num_examples_seen=3600 epoch=60: 0.721087\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:06:54: Loss after num_examples_seen=3900 epoch=65: 0.634343\n",
      "2018-06-26 03:07:14: Loss after num_examples_seen=4200 epoch=70: 0.595799\n",
      "2018-06-26 03:07:33: Loss after num_examples_seen=4500 epoch=75: 0.594352\n",
      "2018-06-26 03:07:52: Loss after num_examples_seen=4800 epoch=80: 0.625409\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:08:11: Loss after num_examples_seen=5100 epoch=85: 0.585505\n",
      "2018-06-26 03:08:31: Loss after num_examples_seen=5400 epoch=90: 0.542511\n",
      "2018-06-26 03:08:50: Loss after num_examples_seen=5700 epoch=95: 0.523796\n",
      "total training time: 6.42 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRContra_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRIpsi_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:09:09: Loss after num_examples_seen=0 epoch=0: 1.166891\n",
      "2018-06-26 03:09:28: Loss after num_examples_seen=275 epoch=5: 0.671869\n",
      "2018-06-26 03:09:46: Loss after num_examples_seen=550 epoch=10: 0.670328\n",
      "2018-06-26 03:10:04: Loss after num_examples_seen=825 epoch=15: 0.669661\n",
      "2018-06-26 03:10:23: Loss after num_examples_seen=1100 epoch=20: 0.668432\n",
      "2018-06-26 03:10:41: Loss after num_examples_seen=1375 epoch=25: 0.665148\n",
      "2018-06-26 03:11:00: Loss after num_examples_seen=1650 epoch=30: 0.659011\n",
      "2018-06-26 03:11:18: Loss after num_examples_seen=1925 epoch=35: 0.654430\n",
      "2018-06-26 03:11:36: Loss after num_examples_seen=2200 epoch=40: 0.640317\n",
      "2018-06-26 03:11:55: Loss after num_examples_seen=2475 epoch=45: 0.652473\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:12:13: Loss after num_examples_seen=2750 epoch=50: 0.587158\n",
      "2018-06-26 03:12:32: Loss after num_examples_seen=3025 epoch=55: 0.577441\n",
      "2018-06-26 03:12:50: Loss after num_examples_seen=3300 epoch=60: 0.581298\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:13:08: Loss after num_examples_seen=3575 epoch=65: 0.544792\n",
      "2018-06-26 03:13:27: Loss after num_examples_seen=3850 epoch=70: 0.503190\n",
      "2018-06-26 03:13:45: Loss after num_examples_seen=4125 epoch=75: 0.501546\n",
      "2018-06-26 03:14:04: Loss after num_examples_seen=4400 epoch=80: 0.449045\n",
      "2018-06-26 03:14:22: Loss after num_examples_seen=4675 epoch=85: 0.378956\n",
      "2018-06-26 03:14:41: Loss after num_examples_seen=4950 epoch=90: 0.328664\n",
      "2018-06-26 03:14:59: Loss after num_examples_seen=5225 epoch=95: 0.307924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time: 6.14 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRIpsi_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRFirstTraining_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:15:17: Loss after num_examples_seen=0 epoch=0: 1.615773\n",
      "2018-06-26 03:15:24: Loss after num_examples_seen=40 epoch=5: 1.074988\n",
      "2018-06-26 03:15:31: Loss after num_examples_seen=80 epoch=10: 1.032085\n",
      "2018-06-26 03:15:38: Loss after num_examples_seen=120 epoch=15: 1.041786\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:15:44: Loss after num_examples_seen=160 epoch=20: 0.997453\n",
      "2018-06-26 03:15:51: Loss after num_examples_seen=200 epoch=25: 0.977930\n",
      "2018-06-26 03:15:58: Loss after num_examples_seen=240 epoch=30: 0.958033\n",
      "2018-06-26 03:16:04: Loss after num_examples_seen=280 epoch=35: 0.936373\n",
      "2018-06-26 03:16:11: Loss after num_examples_seen=320 epoch=40: 0.923588\n",
      "2018-06-26 03:16:18: Loss after num_examples_seen=360 epoch=45: 0.921807\n",
      "2018-06-26 03:16:25: Loss after num_examples_seen=400 epoch=50: 0.901508\n",
      "2018-06-26 03:16:31: Loss after num_examples_seen=440 epoch=55: 0.825900\n",
      "2018-06-26 03:16:38: Loss after num_examples_seen=480 epoch=60: 0.770475\n",
      "2018-06-26 03:16:45: Loss after num_examples_seen=520 epoch=65: 2.427909\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:16:52: Loss after num_examples_seen=560 epoch=70: 0.787735\n",
      "2018-06-26 03:16:58: Loss after num_examples_seen=600 epoch=75: 0.688623\n",
      "2018-06-26 03:17:05: Loss after num_examples_seen=640 epoch=80: 0.684081\n",
      "2018-06-26 03:17:12: Loss after num_examples_seen=680 epoch=85: 0.552928\n",
      "2018-06-26 03:17:19: Loss after num_examples_seen=720 epoch=90: 0.493868\n",
      "2018-06-26 03:17:25: Loss after num_examples_seen=760 epoch=95: 0.499678\n",
      "Setting learning rate to 0.000625\n",
      "total training time: 2.25 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRFirstTraining_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:17:32: Loss after num_examples_seen=0 epoch=0: 1.667006\n",
      "2018-06-26 03:17:56: Loss after num_examples_seen=340 epoch=5: 0.972202\n",
      "2018-06-26 03:18:20: Loss after num_examples_seen=680 epoch=10: 0.947526\n",
      "2018-06-26 03:18:44: Loss after num_examples_seen=1020 epoch=15: 0.944345\n",
      "2018-06-26 03:19:08: Loss after num_examples_seen=1360 epoch=20: 0.889512\n",
      "2018-06-26 03:19:32: Loss after num_examples_seen=1700 epoch=25: 0.800520\n",
      "2018-06-26 03:19:56: Loss after num_examples_seen=2040 epoch=30: 0.995169\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:20:20: Loss after num_examples_seen=2380 epoch=35: 0.366796\n",
      "2018-06-26 03:20:44: Loss after num_examples_seen=2720 epoch=40: 0.322186\n",
      "2018-06-26 03:21:08: Loss after num_examples_seen=3060 epoch=45: 0.611607\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:21:32: Loss after num_examples_seen=3400 epoch=50: 0.223765\n",
      "2018-06-26 03:21:56: Loss after num_examples_seen=3740 epoch=55: 0.173780\n",
      "2018-06-26 03:22:20: Loss after num_examples_seen=4080 epoch=60: 0.134326\n",
      "2018-06-26 03:22:44: Loss after num_examples_seen=4420 epoch=65: 0.117653\n",
      "2018-06-26 03:23:08: Loss after num_examples_seen=4760 epoch=70: 0.229505\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:23:32: Loss after num_examples_seen=5100 epoch=75: 0.108505\n",
      "2018-06-26 03:23:56: Loss after num_examples_seen=5440 epoch=80: 0.098869\n",
      "2018-06-26 03:24:20: Loss after num_examples_seen=5780 epoch=85: 0.093396\n",
      "2018-06-26 03:24:44: Loss after num_examples_seen=6120 epoch=90: 0.089528\n",
      "2018-06-26 03:25:08: Loss after num_examples_seen=6460 epoch=95: 0.086549\n",
      "total training time: 7.99 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMPFC_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRContra_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:25:31: Loss after num_examples_seen=0 epoch=0: 1.162698\n",
      "2018-06-26 03:25:41: Loss after num_examples_seen=40 epoch=5: 0.697835\n",
      "2018-06-26 03:25:50: Loss after num_examples_seen=80 epoch=10: 0.646594\n",
      "2018-06-26 03:25:59: Loss after num_examples_seen=120 epoch=15: 0.664247\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:26:08: Loss after num_examples_seen=160 epoch=20: 0.627468\n",
      "2018-06-26 03:26:18: Loss after num_examples_seen=200 epoch=25: 0.623963\n",
      "2018-06-26 03:26:27: Loss after num_examples_seen=240 epoch=30: 0.619545\n",
      "2018-06-26 03:26:36: Loss after num_examples_seen=280 epoch=35: 0.612988\n",
      "2018-06-26 03:26:45: Loss after num_examples_seen=320 epoch=40: 0.602802\n",
      "2018-06-26 03:26:54: Loss after num_examples_seen=360 epoch=45: 0.591913\n",
      "2018-06-26 03:27:04: Loss after num_examples_seen=400 epoch=50: 0.567945\n",
      "2018-06-26 03:27:13: Loss after num_examples_seen=440 epoch=55: 0.559842\n",
      "2018-06-26 03:27:22: Loss after num_examples_seen=480 epoch=60: 0.542377\n",
      "2018-06-26 03:27:31: Loss after num_examples_seen=520 epoch=65: 0.536286\n",
      "2018-06-26 03:27:40: Loss after num_examples_seen=560 epoch=70: 0.535680\n",
      "2018-06-26 03:27:49: Loss after num_examples_seen=600 epoch=75: 0.507426\n",
      "2018-06-26 03:27:58: Loss after num_examples_seen=640 epoch=80: 0.488337\n",
      "2018-06-26 03:28:08: Loss after num_examples_seen=680 epoch=85: 0.450052\n",
      "2018-06-26 03:28:17: Loss after num_examples_seen=720 epoch=90: 0.510695\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:28:26: Loss after num_examples_seen=760 epoch=95: 0.463791\n",
      "total training time: 3.06 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRContra_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:28:35: Loss after num_examples_seen=0 epoch=0: 1.123409\n",
      "2018-06-26 03:28:43: Loss after num_examples_seen=190 epoch=5: 0.629567\n",
      "2018-06-26 03:28:51: Loss after num_examples_seen=380 epoch=10: 0.617285\n",
      "2018-06-26 03:28:58: Loss after num_examples_seen=570 epoch=15: 0.608455\n",
      "2018-06-26 03:29:06: Loss after num_examples_seen=760 epoch=20: 0.601170\n",
      "2018-06-26 03:29:13: Loss after num_examples_seen=950 epoch=25: 0.594054\n",
      "2018-06-26 03:29:21: Loss after num_examples_seen=1140 epoch=30: 0.589542\n",
      "2018-06-26 03:29:29: Loss after num_examples_seen=1330 epoch=35: 0.585424\n",
      "2018-06-26 03:29:36: Loss after num_examples_seen=1520 epoch=40: 0.597920\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:29:44: Loss after num_examples_seen=1710 epoch=45: 0.517562\n",
      "2018-06-26 03:29:52: Loss after num_examples_seen=1900 epoch=50: 0.495856\n",
      "2018-06-26 03:30:00: Loss after num_examples_seen=2090 epoch=55: 0.531671\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:30:07: Loss after num_examples_seen=2280 epoch=60: 0.428605\n",
      "2018-06-26 03:30:15: Loss after num_examples_seen=2470 epoch=65: 0.397387\n",
      "2018-06-26 03:30:23: Loss after num_examples_seen=2660 epoch=70: 0.385337\n",
      "2018-06-26 03:30:30: Loss after num_examples_seen=2850 epoch=75: 0.360880\n",
      "2018-06-26 03:30:38: Loss after num_examples_seen=3040 epoch=80: 0.397030\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:30:46: Loss after num_examples_seen=3230 epoch=85: 0.284977\n",
      "2018-06-26 03:30:53: Loss after num_examples_seen=3420 epoch=90: 0.261636\n",
      "2018-06-26 03:31:01: Loss after num_examples_seen=3610 epoch=95: 0.251075\n",
      "total training time: 2.56 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMidTraining_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:31:09: Loss after num_examples_seen=0 epoch=0: 1.623096\n",
      "2018-06-26 03:31:45: Loss after num_examples_seen=160 epoch=5: 1.106614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 03:32:22: Loss after num_examples_seen=320 epoch=10: 1.098219\n",
      "2018-06-26 03:32:58: Loss after num_examples_seen=480 epoch=15: 1.085729\n",
      "2018-06-26 03:33:35: Loss after num_examples_seen=640 epoch=20: 1.060192\n",
      "2018-06-26 03:34:11: Loss after num_examples_seen=800 epoch=25: 1.055355\n",
      "2018-06-26 03:34:48: Loss after num_examples_seen=960 epoch=30: 1.044878\n",
      "2018-06-26 03:35:24: Loss after num_examples_seen=1120 epoch=35: 7.726483\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:36:01: Loss after num_examples_seen=1280 epoch=40: 1.554079\n",
      "2018-06-26 03:36:37: Loss after num_examples_seen=1440 epoch=45: 1.391551\n",
      "2018-06-26 03:37:14: Loss after num_examples_seen=1600 epoch=50: 1.461458\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:37:50: Loss after num_examples_seen=1760 epoch=55: 1.136141\n",
      "2018-06-26 03:38:27: Loss after num_examples_seen=1920 epoch=60: 1.124375\n",
      "2018-06-26 03:39:03: Loss after num_examples_seen=2080 epoch=65: 1.122756\n",
      "2018-06-26 03:39:40: Loss after num_examples_seen=2240 epoch=70: 1.151206\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:40:16: Loss after num_examples_seen=2400 epoch=75: 1.109558\n",
      "2018-06-26 03:40:53: Loss after num_examples_seen=2560 epoch=80: 1.099367\n",
      "2018-06-26 03:41:29: Loss after num_examples_seen=2720 epoch=85: 1.093695\n",
      "2018-06-26 03:42:06: Loss after num_examples_seen=2880 epoch=90: 1.086552\n",
      "2018-06-26 03:42:42: Loss after num_examples_seen=3040 epoch=95: 1.083097\n",
      "total training time: 12.16 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRSaline_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:43:18: Loss after num_examples_seen=0 epoch=0: 1.156436\n",
      "2018-06-26 03:43:24: Loss after num_examples_seen=40 epoch=5: 0.672374\n",
      "2018-06-26 03:43:30: Loss after num_examples_seen=80 epoch=10: 0.636179\n",
      "2018-06-26 03:43:36: Loss after num_examples_seen=120 epoch=15: 0.658824\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:43:42: Loss after num_examples_seen=160 epoch=20: 0.621470\n",
      "2018-06-26 03:43:48: Loss after num_examples_seen=200 epoch=25: 0.653495\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:43:54: Loss after num_examples_seen=240 epoch=30: 0.625777\n",
      "2018-06-26 03:44:00: Loss after num_examples_seen=280 epoch=35: 0.625655\n",
      "2018-06-26 03:44:06: Loss after num_examples_seen=320 epoch=40: 0.624709\n",
      "2018-06-26 03:44:12: Loss after num_examples_seen=360 epoch=45: 0.620508\n",
      "2018-06-26 03:44:18: Loss after num_examples_seen=400 epoch=50: 0.614912\n",
      "2018-06-26 03:44:24: Loss after num_examples_seen=440 epoch=55: 0.574175\n",
      "2018-06-26 03:44:30: Loss after num_examples_seen=480 epoch=60: 0.599714\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:44:36: Loss after num_examples_seen=520 epoch=65: 0.573025\n",
      "2018-06-26 03:44:42: Loss after num_examples_seen=560 epoch=70: 0.570924\n",
      "2018-06-26 03:44:48: Loss after num_examples_seen=600 epoch=75: 0.569209\n",
      "2018-06-26 03:44:54: Loss after num_examples_seen=640 epoch=80: 0.568284\n",
      "2018-06-26 03:45:00: Loss after num_examples_seen=680 epoch=85: 0.580389\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 03:45:06: Loss after num_examples_seen=720 epoch=90: 0.543084\n",
      "2018-06-26 03:45:12: Loss after num_examples_seen=760 epoch=95: 0.541725\n",
      "total training time: 1.98 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMidTraining_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSROFC_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:45:18: Loss after num_examples_seen=0 epoch=0: 1.641926\n",
      "2018-06-26 03:45:31: Loss after num_examples_seen=255 epoch=5: 1.101026\n",
      "2018-06-26 03:45:44: Loss after num_examples_seen=510 epoch=10: 1.060673\n",
      "2018-06-26 03:45:58: Loss after num_examples_seen=765 epoch=15: 1.002625\n",
      "2018-06-26 03:46:11: Loss after num_examples_seen=1020 epoch=20: 0.940916\n",
      "2018-06-26 03:46:24: Loss after num_examples_seen=1275 epoch=25: 0.845224\n",
      "2018-06-26 03:46:38: Loss after num_examples_seen=1530 epoch=30: 1.691189\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:46:51: Loss after num_examples_seen=1785 epoch=35: 1.152764\n",
      "2018-06-26 03:47:05: Loss after num_examples_seen=2040 epoch=40: 1.117062\n",
      "2018-06-26 03:47:18: Loss after num_examples_seen=2295 epoch=45: 1.203125\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:47:31: Loss after num_examples_seen=2550 epoch=50: 1.164940\n",
      "2018-06-26 03:47:45: Loss after num_examples_seen=2805 epoch=55: 1.133471\n",
      "2018-06-26 03:47:58: Loss after num_examples_seen=3060 epoch=60: 1.074918\n",
      "2018-06-26 03:48:11: Loss after num_examples_seen=3315 epoch=65: 1.086889\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:48:25: Loss after num_examples_seen=3570 epoch=70: 1.052821\n",
      "2018-06-26 03:48:38: Loss after num_examples_seen=3825 epoch=75: 1.044092\n",
      "2018-06-26 03:48:52: Loss after num_examples_seen=4080 epoch=80: 1.022858\n",
      "2018-06-26 03:49:05: Loss after num_examples_seen=4335 epoch=85: 1.034448\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 03:49:18: Loss after num_examples_seen=4590 epoch=90: 1.020007\n",
      "2018-06-26 03:49:32: Loss after num_examples_seen=4845 epoch=95: 0.999176\n",
      "total training time: 4.46 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSROFC_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:49:45: Loss after num_examples_seen=0 epoch=0: 1.706315\n",
      "2018-06-26 03:50:02: Loss after num_examples_seen=290 epoch=5: 0.674394\n",
      "2018-06-26 03:50:18: Loss after num_examples_seen=580 epoch=10: 0.645612\n",
      "2018-06-26 03:50:35: Loss after num_examples_seen=870 epoch=15: 0.674889\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:50:51: Loss after num_examples_seen=1160 epoch=20: 0.550158\n",
      "2018-06-26 03:51:08: Loss after num_examples_seen=1450 epoch=25: 0.496683\n",
      "2018-06-26 03:51:25: Loss after num_examples_seen=1740 epoch=30: 0.464546\n",
      "2018-06-26 03:51:41: Loss after num_examples_seen=2030 epoch=35: 0.413118\n",
      "2018-06-26 03:51:58: Loss after num_examples_seen=2320 epoch=40: 0.381165\n",
      "2018-06-26 03:52:14: Loss after num_examples_seen=2610 epoch=45: 0.469788\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:52:31: Loss after num_examples_seen=2900 epoch=50: 0.242414\n",
      "2018-06-26 03:52:48: Loss after num_examples_seen=3190 epoch=55: 0.204432\n",
      "2018-06-26 03:53:04: Loss after num_examples_seen=3480 epoch=60: 0.177419\n",
      "2018-06-26 03:53:21: Loss after num_examples_seen=3770 epoch=65: 0.151524\n",
      "2018-06-26 03:53:37: Loss after num_examples_seen=4060 epoch=70: 0.136166\n",
      "2018-06-26 03:53:54: Loss after num_examples_seen=4350 epoch=75: 0.127947\n",
      "2018-06-26 03:54:10: Loss after num_examples_seen=4640 epoch=80: 0.132092\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 03:54:27: Loss after num_examples_seen=4930 epoch=85: 0.106297\n",
      "2018-06-26 03:54:44: Loss after num_examples_seen=5220 epoch=90: 0.099937\n",
      "2018-06-26 03:55:00: Loss after num_examples_seen=5510 epoch=95: 0.095669\n",
      "total training time: 5.53 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRIpsi_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMidTraining_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:55:17: Loss after num_examples_seen=0 epoch=0: 1.009976\n",
      "2018-06-26 03:55:29: Loss after num_examples_seen=255 epoch=5: 0.654633\n",
      "2018-06-26 03:55:42: Loss after num_examples_seen=510 epoch=10: 0.650112\n",
      "2018-06-26 03:55:55: Loss after num_examples_seen=765 epoch=15: 0.651692\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 03:56:07: Loss after num_examples_seen=1020 epoch=20: 0.641237\n",
      "2018-06-26 03:56:20: Loss after num_examples_seen=1275 epoch=25: 0.637352\n",
      "2018-06-26 03:56:33: Loss after num_examples_seen=1530 epoch=30: 0.633293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 03:56:45: Loss after num_examples_seen=1785 epoch=35: 0.623870\n",
      "2018-06-26 03:56:58: Loss after num_examples_seen=2040 epoch=40: 0.608908\n",
      "2018-06-26 03:57:10: Loss after num_examples_seen=2295 epoch=45: 0.588407\n",
      "2018-06-26 03:57:23: Loss after num_examples_seen=2550 epoch=50: 0.563042\n",
      "2018-06-26 03:57:35: Loss after num_examples_seen=2805 epoch=55: 0.531557\n",
      "2018-06-26 03:57:48: Loss after num_examples_seen=3060 epoch=60: 0.494053\n",
      "2018-06-26 03:58:01: Loss after num_examples_seen=3315 epoch=65: 0.450728\n",
      "2018-06-26 03:58:13: Loss after num_examples_seen=3570 epoch=70: 0.413593\n",
      "2018-06-26 03:58:26: Loss after num_examples_seen=3825 epoch=75: 0.394651\n",
      "2018-06-26 03:58:39: Loss after num_examples_seen=4080 epoch=80: 0.403578\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 03:58:51: Loss after num_examples_seen=4335 epoch=85: 0.262497\n",
      "2018-06-26 03:59:04: Loss after num_examples_seen=4590 epoch=90: 0.239191\n",
      "2018-06-26 03:59:17: Loss after num_examples_seen=4845 epoch=95: 0.253138\n",
      "Setting learning rate to 0.000625\n",
      "total training time: 4.21 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMidTraining_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMPFC_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 03:59:29: Loss after num_examples_seen=0 epoch=0: 1.584936\n",
      "2018-06-26 03:59:40: Loss after num_examples_seen=40 epoch=5: 0.826343\n",
      "2018-06-26 03:59:51: Loss after num_examples_seen=80 epoch=10: 8.473601\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:00:02: Loss after num_examples_seen=120 epoch=15: 3.124227\n",
      "2018-06-26 04:00:12: Loss after num_examples_seen=160 epoch=20: 1.955483\n",
      "2018-06-26 04:00:23: Loss after num_examples_seen=200 epoch=25: 1.913104\n",
      "2018-06-26 04:00:34: Loss after num_examples_seen=240 epoch=30: 2.418800\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:00:45: Loss after num_examples_seen=280 epoch=35: 0.792032\n",
      "2018-06-26 04:00:56: Loss after num_examples_seen=320 epoch=40: 0.756594\n",
      "2018-06-26 04:01:06: Loss after num_examples_seen=360 epoch=45: 0.724633\n",
      "2018-06-26 04:01:17: Loss after num_examples_seen=400 epoch=50: 0.704171\n",
      "2018-06-26 04:01:28: Loss after num_examples_seen=440 epoch=55: 0.692297\n",
      "2018-06-26 04:01:38: Loss after num_examples_seen=480 epoch=60: 0.684379\n",
      "2018-06-26 04:01:49: Loss after num_examples_seen=520 epoch=65: 0.682242\n",
      "2018-06-26 04:02:00: Loss after num_examples_seen=560 epoch=70: 0.654331\n",
      "2018-06-26 04:02:11: Loss after num_examples_seen=600 epoch=75: 0.651961\n",
      "2018-06-26 04:02:22: Loss after num_examples_seen=640 epoch=80: 0.633359\n",
      "2018-06-26 04:02:32: Loss after num_examples_seen=680 epoch=85: 0.614746\n",
      "2018-06-26 04:02:43: Loss after num_examples_seen=720 epoch=90: 0.616498\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 04:02:54: Loss after num_examples_seen=760 epoch=95: 0.586068\n",
      "total training time: 3.59 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMPFC_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRSaline_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:03:05: Loss after num_examples_seen=0 epoch=0: 1.606841\n",
      "2018-06-26 04:03:35: Loss after num_examples_seen=175 epoch=5: 0.742761\n",
      "2018-06-26 04:04:06: Loss after num_examples_seen=350 epoch=10: 0.679837\n",
      "2018-06-26 04:04:37: Loss after num_examples_seen=525 epoch=15: 0.661963\n",
      "2018-06-26 04:05:08: Loss after num_examples_seen=700 epoch=20: 0.647934\n",
      "2018-06-26 04:05:39: Loss after num_examples_seen=875 epoch=25: 0.666097\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:06:09: Loss after num_examples_seen=1050 epoch=30: 0.618997\n",
      "2018-06-26 04:06:40: Loss after num_examples_seen=1225 epoch=35: 0.633450\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:07:11: Loss after num_examples_seen=1400 epoch=40: 0.560499\n",
      "2018-06-26 04:07:41: Loss after num_examples_seen=1575 epoch=45: 0.548574\n",
      "2018-06-26 04:08:12: Loss after num_examples_seen=1750 epoch=50: 0.536853\n",
      "2018-06-26 04:08:43: Loss after num_examples_seen=1925 epoch=55: 0.545432\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 04:09:14: Loss after num_examples_seen=2100 epoch=60: 0.474331\n",
      "2018-06-26 04:09:44: Loss after num_examples_seen=2275 epoch=65: 0.457395\n",
      "2018-06-26 04:10:15: Loss after num_examples_seen=2450 epoch=70: 0.448900\n",
      "2018-06-26 04:10:46: Loss after num_examples_seen=2625 epoch=75: 0.433975\n",
      "2018-06-26 04:11:17: Loss after num_examples_seen=2800 epoch=80: 0.468954\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 04:11:47: Loss after num_examples_seen=2975 epoch=85: 0.383326\n",
      "2018-06-26 04:12:18: Loss after num_examples_seen=3150 epoch=90: 0.364459\n",
      "2018-06-26 04:12:49: Loss after num_examples_seen=3325 epoch=95: 0.369745\n",
      "Setting learning rate to 0.000156\n",
      "total training time: 10.25 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRSaline_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRMPFC_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:13:20: Loss after num_examples_seen=0 epoch=0: 1.183466\n",
      "2018-06-26 04:13:44: Loss after num_examples_seen=345 epoch=5: 0.508708\n",
      "2018-06-26 04:14:09: Loss after num_examples_seen=690 epoch=10: 0.497406\n",
      "2018-06-26 04:14:33: Loss after num_examples_seen=1035 epoch=15: 0.494601\n",
      "2018-06-26 04:14:57: Loss after num_examples_seen=1380 epoch=20: 0.477800\n",
      "2018-06-26 04:15:21: Loss after num_examples_seen=1725 epoch=25: 0.453009\n",
      "2018-06-26 04:15:45: Loss after num_examples_seen=2070 epoch=30: 0.416702\n",
      "2018-06-26 04:16:10: Loss after num_examples_seen=2415 epoch=35: 0.471462\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:16:34: Loss after num_examples_seen=2760 epoch=40: 0.570574\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:16:58: Loss after num_examples_seen=3105 epoch=45: 0.453981\n",
      "2018-06-26 04:17:23: Loss after num_examples_seen=3450 epoch=50: 0.330880\n",
      "2018-06-26 04:17:47: Loss after num_examples_seen=3795 epoch=55: 0.308371\n",
      "2018-06-26 04:18:11: Loss after num_examples_seen=4140 epoch=60: 0.279738\n",
      "2018-06-26 04:18:36: Loss after num_examples_seen=4485 epoch=65: 0.252778\n",
      "2018-06-26 04:19:00: Loss after num_examples_seen=4830 epoch=70: 0.255530\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 04:19:24: Loss after num_examples_seen=5175 epoch=75: 0.165019\n",
      "2018-06-26 04:19:48: Loss after num_examples_seen=5520 epoch=80: 0.149105\n",
      "2018-06-26 04:20:13: Loss after num_examples_seen=5865 epoch=85: 0.141045\n",
      "2018-06-26 04:20:37: Loss after num_examples_seen=6210 epoch=90: 0.136298\n",
      "2018-06-26 04:21:01: Loss after num_examples_seen=6555 epoch=95: 0.126024\n",
      "total training time: 8.09 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRMPFC_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:21:25: Loss after num_examples_seen=0 epoch=0: 1.188358\n",
      "2018-06-26 04:21:30: Loss after num_examples_seen=40 epoch=5: 0.640255\n",
      "2018-06-26 04:21:36: Loss after num_examples_seen=80 epoch=10: 0.623083\n",
      "2018-06-26 04:21:41: Loss after num_examples_seen=120 epoch=15: 0.610444\n",
      "2018-06-26 04:21:46: Loss after num_examples_seen=160 epoch=20: 0.593113\n",
      "2018-06-26 04:21:51: Loss after num_examples_seen=200 epoch=25: 0.584731\n",
      "2018-06-26 04:21:57: Loss after num_examples_seen=240 epoch=30: 0.574269\n",
      "2018-06-26 04:22:02: Loss after num_examples_seen=280 epoch=35: 0.563207\n",
      "2018-06-26 04:22:07: Loss after num_examples_seen=320 epoch=40: 0.539829\n",
      "2018-06-26 04:22:12: Loss after num_examples_seen=360 epoch=45: 0.534033\n",
      "2018-06-26 04:22:17: Loss after num_examples_seen=400 epoch=50: 0.468519\n",
      "2018-06-26 04:22:22: Loss after num_examples_seen=440 epoch=55: 0.984966\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:22:28: Loss after num_examples_seen=480 epoch=60: 0.556990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 04:22:33: Loss after num_examples_seen=520 epoch=65: 0.496132\n",
      "2018-06-26 04:22:38: Loss after num_examples_seen=560 epoch=70: 0.455061\n",
      "2018-06-26 04:22:43: Loss after num_examples_seen=600 epoch=75: 0.454517\n",
      "2018-06-26 04:22:48: Loss after num_examples_seen=640 epoch=80: 0.401234\n",
      "2018-06-26 04:22:54: Loss after num_examples_seen=680 epoch=85: 0.365590\n",
      "2018-06-26 04:22:59: Loss after num_examples_seen=720 epoch=90: 0.346987\n",
      "2018-06-26 04:23:04: Loss after num_examples_seen=760 epoch=95: 0.323416\n",
      "total training time: 1.73 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRFirstTraining_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:23:09: Loss after num_examples_seen=0 epoch=0: 1.093397\n",
      "2018-06-26 04:23:26: Loss after num_examples_seen=290 epoch=5: 0.617470\n",
      "2018-06-26 04:23:42: Loss after num_examples_seen=580 epoch=10: 0.606101\n",
      "2018-06-26 04:23:59: Loss after num_examples_seen=870 epoch=15: 0.591155\n",
      "2018-06-26 04:24:16: Loss after num_examples_seen=1160 epoch=20: 0.578223\n",
      "2018-06-26 04:24:33: Loss after num_examples_seen=1450 epoch=25: 0.564586\n",
      "2018-06-26 04:24:49: Loss after num_examples_seen=1740 epoch=30: 0.567136\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:25:06: Loss after num_examples_seen=2030 epoch=35: 0.497074\n",
      "2018-06-26 04:25:23: Loss after num_examples_seen=2320 epoch=40: 0.481218\n",
      "2018-06-26 04:25:39: Loss after num_examples_seen=2610 epoch=45: 0.416484\n",
      "2018-06-26 04:25:56: Loss after num_examples_seen=2900 epoch=50: 0.420320\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:26:13: Loss after num_examples_seen=3190 epoch=55: 0.321830\n",
      "2018-06-26 04:26:29: Loss after num_examples_seen=3480 epoch=60: 0.309712\n",
      "2018-06-26 04:26:46: Loss after num_examples_seen=3770 epoch=65: 0.298645\n",
      "2018-06-26 04:27:03: Loss after num_examples_seen=4060 epoch=70: 0.504342\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 04:27:19: Loss after num_examples_seen=4350 epoch=75: 0.186274\n",
      "2018-06-26 04:27:36: Loss after num_examples_seen=4640 epoch=80: 0.165432\n",
      "2018-06-26 04:27:53: Loss after num_examples_seen=4930 epoch=85: 0.152363\n",
      "2018-06-26 04:28:10: Loss after num_examples_seen=5220 epoch=90: 0.141344\n",
      "2018-06-26 04:28:26: Loss after num_examples_seen=5510 epoch=95: 0.132773\n",
      "total training time: 5.56 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRIpsi_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSROFC_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:28:43: Loss after num_examples_seen=0 epoch=0: 1.543436\n",
      "2018-06-26 04:28:51: Loss after num_examples_seen=40 epoch=5: 0.721144\n",
      "2018-06-26 04:28:58: Loss after num_examples_seen=80 epoch=10: 0.762105\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:29:06: Loss after num_examples_seen=120 epoch=15: 0.669306\n",
      "2018-06-26 04:29:14: Loss after num_examples_seen=160 epoch=20: 0.646011\n",
      "2018-06-26 04:29:21: Loss after num_examples_seen=200 epoch=25: 0.637521\n",
      "2018-06-26 04:29:29: Loss after num_examples_seen=240 epoch=30: 0.624054\n",
      "2018-06-26 04:29:36: Loss after num_examples_seen=280 epoch=35: 0.609774\n",
      "2018-06-26 04:29:44: Loss after num_examples_seen=320 epoch=40: 0.601974\n",
      "2018-06-26 04:29:52: Loss after num_examples_seen=360 epoch=45: 0.576997\n",
      "2018-06-26 04:30:00: Loss after num_examples_seen=400 epoch=50: 0.548751\n",
      "2018-06-26 04:30:07: Loss after num_examples_seen=440 epoch=55: 0.531117\n",
      "2018-06-26 04:30:15: Loss after num_examples_seen=480 epoch=60: 0.529898\n",
      "2018-06-26 04:30:23: Loss after num_examples_seen=520 epoch=65: 0.476054\n",
      "2018-06-26 04:30:31: Loss after num_examples_seen=560 epoch=70: 0.681927\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:30:38: Loss after num_examples_seen=600 epoch=75: 0.367517\n",
      "2018-06-26 04:30:46: Loss after num_examples_seen=640 epoch=80: 0.338528\n",
      "2018-06-26 04:30:54: Loss after num_examples_seen=680 epoch=85: 0.297428\n",
      "2018-06-26 04:31:01: Loss after num_examples_seen=720 epoch=90: 0.289504\n",
      "2018-06-26 04:31:09: Loss after num_examples_seen=760 epoch=95: 0.245599\n",
      "total training time: 2.56 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSROFC_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRContra_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:31:17: Loss after num_examples_seen=0 epoch=0: 1.066282\n",
      "2018-06-26 04:31:35: Loss after num_examples_seen=310 epoch=5: 0.648789\n",
      "2018-06-26 04:31:53: Loss after num_examples_seen=620 epoch=10: 0.641090\n",
      "2018-06-26 04:32:11: Loss after num_examples_seen=930 epoch=15: 0.634453\n",
      "2018-06-26 04:32:29: Loss after num_examples_seen=1240 epoch=20: 0.629197\n",
      "2018-06-26 04:32:47: Loss after num_examples_seen=1550 epoch=25: 0.622674\n",
      "2018-06-26 04:33:05: Loss after num_examples_seen=1860 epoch=30: 0.612850\n",
      "2018-06-26 04:33:23: Loss after num_examples_seen=2170 epoch=35: 0.612128\n",
      "2018-06-26 04:33:41: Loss after num_examples_seen=2480 epoch=40: 0.617933\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:33:59: Loss after num_examples_seen=2790 epoch=45: 0.564586\n",
      "2018-06-26 04:34:18: Loss after num_examples_seen=3100 epoch=50: 0.671472\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:34:36: Loss after num_examples_seen=3410 epoch=55: 0.643114\n",
      "2018-06-26 04:34:54: Loss after num_examples_seen=3720 epoch=60: 0.625968\n",
      "2018-06-26 04:35:12: Loss after num_examples_seen=4030 epoch=65: 0.618158\n",
      "2018-06-26 04:35:30: Loss after num_examples_seen=4340 epoch=70: 0.608079\n",
      "2018-06-26 04:35:48: Loss after num_examples_seen=4650 epoch=75: 0.580097\n",
      "2018-06-26 04:36:06: Loss after num_examples_seen=4960 epoch=80: 0.568675\n",
      "2018-06-26 04:36:25: Loss after num_examples_seen=5270 epoch=85: 0.557376\n",
      "2018-06-26 04:36:43: Loss after num_examples_seen=5580 epoch=90: 0.626257\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 04:37:01: Loss after num_examples_seen=5890 epoch=95: 0.499291\n",
      "total training time: 6.03 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRContra_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRContra_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:37:19: Loss after num_examples_seen=0 epoch=0: 1.674945\n",
      "2018-06-26 04:37:39: Loss after num_examples_seen=295 epoch=5: 1.109852\n",
      "2018-06-26 04:37:59: Loss after num_examples_seen=590 epoch=10: 1.069546\n",
      "2018-06-26 04:38:19: Loss after num_examples_seen=885 epoch=15: 0.980143\n",
      "2018-06-26 04:38:38: Loss after num_examples_seen=1180 epoch=20: 0.877036\n",
      "2018-06-26 04:38:58: Loss after num_examples_seen=1475 epoch=25: 0.670752\n",
      "2018-06-26 04:39:18: Loss after num_examples_seen=1770 epoch=30: 0.792169\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:39:37: Loss after num_examples_seen=2065 epoch=35: 0.269625\n",
      "2018-06-26 04:39:57: Loss after num_examples_seen=2360 epoch=40: 0.187641\n",
      "2018-06-26 04:40:17: Loss after num_examples_seen=2655 epoch=45: 0.202993\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:40:37: Loss after num_examples_seen=2950 epoch=50: 0.114908\n",
      "2018-06-26 04:40:57: Loss after num_examples_seen=3245 epoch=55: 0.100139\n",
      "2018-06-26 04:41:16: Loss after num_examples_seen=3540 epoch=60: 0.091329\n",
      "2018-06-26 04:41:36: Loss after num_examples_seen=3835 epoch=65: 0.085713\n",
      "2018-06-26 04:41:56: Loss after num_examples_seen=4130 epoch=70: 0.080969\n",
      "2018-06-26 04:42:16: Loss after num_examples_seen=4425 epoch=75: 0.077632\n",
      "2018-06-26 04:42:36: Loss after num_examples_seen=4720 epoch=80: 0.075190\n",
      "2018-06-26 04:42:55: Loss after num_examples_seen=5015 epoch=85: 0.072946\n",
      "2018-06-26 04:43:15: Loss after num_examples_seen=5310 epoch=90: 0.071240\n",
      "2018-06-26 04:43:35: Loss after num_examples_seen=5605 epoch=95: 0.069677\n",
      "total training time: 6.59 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRContra_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSROFC_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:43:55: Loss after num_examples_seen=0 epoch=0: 1.584236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 04:44:03: Loss after num_examples_seen=40 epoch=5: 1.138204\n",
      "2018-06-26 04:44:12: Loss after num_examples_seen=80 epoch=10: 1.117093\n",
      "2018-06-26 04:44:20: Loss after num_examples_seen=120 epoch=15: 1.102939\n",
      "2018-06-26 04:44:29: Loss after num_examples_seen=160 epoch=20: 1.068661\n",
      "2018-06-26 04:44:37: Loss after num_examples_seen=200 epoch=25: 1.034955\n",
      "2018-06-26 04:44:46: Loss after num_examples_seen=240 epoch=30: 1.026633\n",
      "2018-06-26 04:44:55: Loss after num_examples_seen=280 epoch=35: 1.011262\n",
      "2018-06-26 04:45:03: Loss after num_examples_seen=320 epoch=40: 1.007146\n",
      "2018-06-26 04:45:12: Loss after num_examples_seen=360 epoch=45: 0.947640\n",
      "2018-06-26 04:45:20: Loss after num_examples_seen=400 epoch=50: 0.859721\n",
      "2018-06-26 04:45:29: Loss after num_examples_seen=440 epoch=55: 0.882046\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:45:37: Loss after num_examples_seen=480 epoch=60: 0.512252\n",
      "2018-06-26 04:45:46: Loss after num_examples_seen=520 epoch=65: 0.437824\n",
      "2018-06-26 04:45:54: Loss after num_examples_seen=560 epoch=70: 0.676692\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:46:03: Loss after num_examples_seen=600 epoch=75: 0.268938\n",
      "2018-06-26 04:46:12: Loss after num_examples_seen=640 epoch=80: 0.197080\n",
      "2018-06-26 04:46:20: Loss after num_examples_seen=680 epoch=85: 0.152882\n",
      "2018-06-26 04:46:29: Loss after num_examples_seen=720 epoch=90: 0.154109\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 04:46:37: Loss after num_examples_seen=760 epoch=95: 0.107866\n",
      "total training time: 2.86 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSROFC_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSROFC_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:46:46: Loss after num_examples_seen=0 epoch=0: 1.169105\n",
      "2018-06-26 04:46:54: Loss after num_examples_seen=40 epoch=5: 0.677014\n",
      "2018-06-26 04:47:03: Loss after num_examples_seen=80 epoch=10: 0.665732\n",
      "2018-06-26 04:47:11: Loss after num_examples_seen=120 epoch=15: 0.663908\n",
      "2018-06-26 04:47:20: Loss after num_examples_seen=160 epoch=20: 0.661682\n",
      "2018-06-26 04:47:28: Loss after num_examples_seen=200 epoch=25: 0.660737\n",
      "2018-06-26 04:47:36: Loss after num_examples_seen=240 epoch=30: 0.663066\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:47:45: Loss after num_examples_seen=280 epoch=35: 0.648145\n",
      "2018-06-26 04:47:53: Loss after num_examples_seen=320 epoch=40: 0.646495\n",
      "2018-06-26 04:48:02: Loss after num_examples_seen=360 epoch=45: 0.639457\n",
      "2018-06-26 04:48:10: Loss after num_examples_seen=400 epoch=50: 0.639984\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:48:19: Loss after num_examples_seen=440 epoch=55: 0.626984\n",
      "2018-06-26 04:48:27: Loss after num_examples_seen=480 epoch=60: 0.623531\n",
      "2018-06-26 04:48:36: Loss after num_examples_seen=520 epoch=65: 0.619129\n",
      "2018-06-26 04:48:44: Loss after num_examples_seen=560 epoch=70: 0.614626\n",
      "2018-06-26 04:48:53: Loss after num_examples_seen=600 epoch=75: 0.609751\n",
      "2018-06-26 04:49:01: Loss after num_examples_seen=640 epoch=80: 0.604493\n",
      "2018-06-26 04:49:10: Loss after num_examples_seen=680 epoch=85: 0.599297\n",
      "2018-06-26 04:49:18: Loss after num_examples_seen=720 epoch=90: 0.594263\n",
      "2018-06-26 04:49:26: Loss after num_examples_seen=760 epoch=95: 0.588485\n",
      "total training time: 2.82 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSROFC_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRMidTraining_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:49:35: Loss after num_examples_seen=0 epoch=0: 1.667630\n",
      "2018-06-26 04:49:42: Loss after num_examples_seen=210 epoch=5: 0.692027\n",
      "2018-06-26 04:49:50: Loss after num_examples_seen=420 epoch=10: 0.664532\n",
      "2018-06-26 04:49:57: Loss after num_examples_seen=630 epoch=15: 0.626796\n",
      "2018-06-26 04:50:05: Loss after num_examples_seen=840 epoch=20: 0.605119\n",
      "2018-06-26 04:50:12: Loss after num_examples_seen=1050 epoch=25: 0.553846\n",
      "2018-06-26 04:50:19: Loss after num_examples_seen=1260 epoch=30: 0.498077\n",
      "2018-06-26 04:50:27: Loss after num_examples_seen=1470 epoch=35: 0.462011\n",
      "2018-06-26 04:50:34: Loss after num_examples_seen=1680 epoch=40: 0.482901\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:50:42: Loss after num_examples_seen=1890 epoch=45: 0.297178\n",
      "2018-06-26 04:50:49: Loss after num_examples_seen=2100 epoch=50: 0.271366\n",
      "2018-06-26 04:50:57: Loss after num_examples_seen=2310 epoch=55: 0.247714\n",
      "2018-06-26 04:51:04: Loss after num_examples_seen=2520 epoch=60: 0.191025\n",
      "2018-06-26 04:51:11: Loss after num_examples_seen=2730 epoch=65: 0.185685\n",
      "2018-06-26 04:51:19: Loss after num_examples_seen=2940 epoch=70: 0.139732\n",
      "2018-06-26 04:51:26: Loss after num_examples_seen=3150 epoch=75: 0.264368\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:51:33: Loss after num_examples_seen=3360 epoch=80: 0.116511\n",
      "2018-06-26 04:51:41: Loss after num_examples_seen=3570 epoch=85: 0.109387\n",
      "2018-06-26 04:51:48: Loss after num_examples_seen=3780 epoch=90: 0.105151\n",
      "2018-06-26 04:51:56: Loss after num_examples_seen=3990 epoch=95: 0.102068\n",
      "total training time: 2.47 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRMidTraining_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRIpsi_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:52:03: Loss after num_examples_seen=0 epoch=0: 1.138033\n",
      "2018-06-26 04:52:12: Loss after num_examples_seen=40 epoch=5: 0.635612\n",
      "2018-06-26 04:52:20: Loss after num_examples_seen=80 epoch=10: 0.618499\n",
      "2018-06-26 04:52:29: Loss after num_examples_seen=120 epoch=15: 0.601095\n",
      "2018-06-26 04:52:38: Loss after num_examples_seen=160 epoch=20: 0.601112\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 04:52:46: Loss after num_examples_seen=200 epoch=25: 0.578801\n",
      "2018-06-26 04:52:55: Loss after num_examples_seen=240 epoch=30: 0.578140\n",
      "2018-06-26 04:53:03: Loss after num_examples_seen=280 epoch=35: 0.564693\n",
      "2018-06-26 04:53:12: Loss after num_examples_seen=320 epoch=40: 0.618100\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 04:53:21: Loss after num_examples_seen=360 epoch=45: 0.537698\n",
      "2018-06-26 04:53:29: Loss after num_examples_seen=400 epoch=50: 0.532302\n",
      "2018-06-26 04:53:38: Loss after num_examples_seen=440 epoch=55: 0.534182\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 04:53:46: Loss after num_examples_seen=480 epoch=60: 0.515185\n",
      "2018-06-26 04:53:55: Loss after num_examples_seen=520 epoch=65: 0.508015\n",
      "2018-06-26 04:54:04: Loss after num_examples_seen=560 epoch=70: 0.505629\n",
      "2018-06-26 04:54:12: Loss after num_examples_seen=600 epoch=75: 0.493479\n",
      "2018-06-26 04:54:21: Loss after num_examples_seen=640 epoch=80: 0.487380\n",
      "2018-06-26 04:54:30: Loss after num_examples_seen=680 epoch=85: 0.474311\n",
      "2018-06-26 04:54:38: Loss after num_examples_seen=720 epoch=90: 0.466650\n",
      "2018-06-26 04:54:47: Loss after num_examples_seen=760 epoch=95: 0.460094\n",
      "total training time: 2.87 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRIpsi_choice_only_session_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRSaline_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 04:54:56: Loss after num_examples_seen=0 epoch=0: 1.225089\n",
      "2018-06-26 04:56:01: Loss after num_examples_seen=1140 epoch=5: 0.670540\n",
      "2018-06-26 04:57:07: Loss after num_examples_seen=2280 epoch=10: 0.669397\n",
      "2018-06-26 04:58:12: Loss after num_examples_seen=3420 epoch=15: 0.666043\n",
      "2018-06-26 04:59:17: Loss after num_examples_seen=4560 epoch=20: 0.666107\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 05:00:23: Loss after num_examples_seen=5700 epoch=25: 0.653597\n",
      "2018-06-26 05:01:28: Loss after num_examples_seen=6840 epoch=30: 0.651418\n",
      "2018-06-26 05:02:34: Loss after num_examples_seen=7980 epoch=35: 0.652961\n",
      "Setting learning rate to 0.001250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 05:03:39: Loss after num_examples_seen=9120 epoch=40: 0.646038\n",
      "2018-06-26 05:04:44: Loss after num_examples_seen=10260 epoch=45: 0.644364\n",
      "2018-06-26 05:05:50: Loss after num_examples_seen=11400 epoch=50: 0.642624\n",
      "2018-06-26 05:06:55: Loss after num_examples_seen=12540 epoch=55: 0.646778\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 05:08:00: Loss after num_examples_seen=13680 epoch=60: 0.629359\n",
      "2018-06-26 05:09:05: Loss after num_examples_seen=14820 epoch=65: 0.622734\n",
      "2018-06-26 05:10:11: Loss after num_examples_seen=15960 epoch=70: 0.616734\n",
      "2018-06-26 05:11:16: Loss after num_examples_seen=17100 epoch=75: 0.610549\n",
      "2018-06-26 05:12:21: Loss after num_examples_seen=18240 epoch=80: 0.609430\n",
      "2018-06-26 05:13:26: Loss after num_examples_seen=19380 epoch=85: 0.598531\n",
      "2018-06-26 05:14:32: Loss after num_examples_seen=20520 epoch=90: 0.600717\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 05:15:37: Loss after num_examples_seen=21660 epoch=95: 0.571505\n",
      "total training time: 21.78 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRSaline_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_only_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 05:16:42: Loss after num_examples_seen=0 epoch=0: 1.097469\n",
      "2018-06-26 05:16:48: Loss after num_examples_seen=175 epoch=5: 0.624640\n",
      "2018-06-26 05:16:53: Loss after num_examples_seen=350 epoch=10: 0.615550\n",
      "2018-06-26 05:16:58: Loss after num_examples_seen=525 epoch=15: 0.609342\n",
      "2018-06-26 05:17:03: Loss after num_examples_seen=700 epoch=20: 0.603703\n",
      "2018-06-26 05:17:08: Loss after num_examples_seen=875 epoch=25: 0.590905\n",
      "2018-06-26 05:17:14: Loss after num_examples_seen=1050 epoch=30: 0.585955\n",
      "2018-06-26 05:17:19: Loss after num_examples_seen=1225 epoch=35: 0.568216\n",
      "2018-06-26 05:17:24: Loss after num_examples_seen=1400 epoch=40: 0.553930\n",
      "2018-06-26 05:17:29: Loss after num_examples_seen=1575 epoch=45: 0.505478\n",
      "2018-06-26 05:17:35: Loss after num_examples_seen=1750 epoch=50: 0.466546\n",
      "2018-06-26 05:17:40: Loss after num_examples_seen=1925 epoch=55: 0.523160\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 05:17:45: Loss after num_examples_seen=2100 epoch=60: 0.323690\n",
      "2018-06-26 05:17:51: Loss after num_examples_seen=2275 epoch=65: 0.329679\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 05:17:56: Loss after num_examples_seen=2450 epoch=70: 0.214525\n",
      "2018-06-26 05:18:01: Loss after num_examples_seen=2625 epoch=75: 0.183920\n",
      "2018-06-26 05:18:06: Loss after num_examples_seen=2800 epoch=80: 0.168201\n",
      "2018-06-26 05:18:12: Loss after num_examples_seen=2975 epoch=85: 0.156996\n",
      "2018-06-26 05:18:17: Loss after num_examples_seen=3150 epoch=90: 0.242155\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 05:18:22: Loss after num_examples_seen=3325 epoch=95: 0.141880\n",
      "total training time: 1.76 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRFirstTraining_choice_only_split_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRContra_choice_reward_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 05:18:28: Loss after num_examples_seen=0 epoch=0: 1.560663\n",
      "2018-06-26 05:18:37: Loss after num_examples_seen=40 epoch=5: 0.770239\n",
      "2018-06-26 05:18:46: Loss after num_examples_seen=80 epoch=10: 0.750879\n",
      "2018-06-26 05:18:55: Loss after num_examples_seen=120 epoch=15: 0.735548\n",
      "2018-06-26 05:19:04: Loss after num_examples_seen=160 epoch=20: 0.738270\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 05:19:14: Loss after num_examples_seen=200 epoch=25: 0.673130\n",
      "2018-06-26 05:19:23: Loss after num_examples_seen=240 epoch=30: 0.648294\n",
      "2018-06-26 05:19:32: Loss after num_examples_seen=280 epoch=35: 0.622380\n",
      "2018-06-26 05:19:41: Loss after num_examples_seen=320 epoch=40: 0.627323\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 05:19:50: Loss after num_examples_seen=360 epoch=45: 0.587946\n",
      "2018-06-26 05:20:00: Loss after num_examples_seen=400 epoch=50: 0.626957\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-26 05:20:09: Loss after num_examples_seen=440 epoch=55: 0.555828\n",
      "2018-06-26 05:20:18: Loss after num_examples_seen=480 epoch=60: 0.548710\n",
      "2018-06-26 05:20:27: Loss after num_examples_seen=520 epoch=65: 0.537614\n",
      "2018-06-26 05:20:36: Loss after num_examples_seen=560 epoch=70: 0.522748\n",
      "2018-06-26 05:20:46: Loss after num_examples_seen=600 epoch=75: 0.510408\n",
      "2018-06-26 05:20:55: Loss after num_examples_seen=640 epoch=80: 0.523377\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-26 05:21:04: Loss after num_examples_seen=680 epoch=85: 0.506446\n",
      "2018-06-26 05:21:13: Loss after num_examples_seen=720 epoch=90: 0.501153\n",
      "2018-06-26 05:21:22: Loss after num_examples_seen=760 epoch=95: 0.496111\n",
      "total training time: 3.06 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRContra_choice_reward_session_sequences.npz.\n",
      "********************************************************************************\n",
      "DSRFirstTraining_choice_reward_split_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 05:21:31: Loss after num_examples_seen=0 epoch=0: 1.601484\n",
      "2018-06-26 05:21:39: Loss after num_examples_seen=185 epoch=5: 0.743014\n",
      "2018-06-26 05:21:46: Loss after num_examples_seen=370 epoch=10: 0.675717\n",
      "2018-06-26 05:21:53: Loss after num_examples_seen=555 epoch=15: 0.662959\n",
      "2018-06-26 05:22:00: Loss after num_examples_seen=740 epoch=20: 0.635694\n",
      "2018-06-26 05:22:07: Loss after num_examples_seen=925 epoch=25: 0.595943\n",
      "2018-06-26 05:22:14: Loss after num_examples_seen=1110 epoch=30: 0.543955\n",
      "2018-06-26 05:22:21: Loss after num_examples_seen=1295 epoch=35: 0.508952\n",
      "2018-06-26 05:22:28: Loss after num_examples_seen=1480 epoch=40: 0.525922\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 05:22:36: Loss after num_examples_seen=1665 epoch=45: 0.347343\n",
      "2018-06-26 05:22:43: Loss after num_examples_seen=1850 epoch=50: 0.297686\n",
      "2018-06-26 05:22:50: Loss after num_examples_seen=2035 epoch=55: 0.282360\n",
      "2018-06-26 05:22:57: Loss after num_examples_seen=2220 epoch=60: 0.196923\n",
      "2018-06-26 05:23:04: Loss after num_examples_seen=2405 epoch=65: 0.269899\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 05:23:11: Loss after num_examples_seen=2590 epoch=70: 0.135508\n",
      "2018-06-26 05:23:18: Loss after num_examples_seen=2775 epoch=75: 0.120849\n",
      "2018-06-26 05:23:25: Loss after num_examples_seen=2960 epoch=80: 0.112173\n",
      "2018-06-26 05:23:32: Loss after num_examples_seen=3145 epoch=85: 0.105002\n",
      "2018-06-26 05:23:39: Loss after num_examples_seen=3330 epoch=90: 0.099753\n",
      "2018-06-26 05:23:46: Loss after num_examples_seen=3515 epoch=95: 0.095983\n",
      "total training time: 2.36 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/DSRFirstTraining_choice_reward_split_sequences.npz.\n",
      "********************************************************************************\n",
      "PSRContra_choice_only_session_sequences.p\n",
      "********************************************************************************\n",
      "2018-06-26 05:23:53: Loss after num_examples_seen=0 epoch=0: 1.192709\n",
      "2018-06-26 05:24:04: Loss after num_examples_seen=40 epoch=5: 0.686815\n",
      "2018-06-26 05:24:14: Loss after num_examples_seen=80 epoch=10: 0.654595\n",
      "2018-06-26 05:24:25: Loss after num_examples_seen=120 epoch=15: 1.063334\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-26 05:24:35: Loss after num_examples_seen=160 epoch=20: 0.653325\n",
      "2018-06-26 05:24:46: Loss after num_examples_seen=200 epoch=25: 0.641463\n",
      "2018-06-26 05:24:56: Loss after num_examples_seen=240 epoch=30: 0.640205\n",
      "2018-06-26 05:25:07: Loss after num_examples_seen=280 epoch=35: 0.639296\n",
      "2018-06-26 05:25:17: Loss after num_examples_seen=320 epoch=40: 0.638323\n",
      "2018-06-26 05:25:28: Loss after num_examples_seen=360 epoch=45: 0.637195\n",
      "2018-06-26 05:25:38: Loss after num_examples_seen=400 epoch=50: 0.635811\n",
      "2018-06-26 05:25:49: Loss after num_examples_seen=440 epoch=55: 0.633973\n",
      "2018-06-26 05:25:59: Loss after num_examples_seen=480 epoch=60: 0.631517\n",
      "2018-06-26 05:26:10: Loss after num_examples_seen=520 epoch=65: 0.628826\n",
      "2018-06-26 05:26:21: Loss after num_examples_seen=560 epoch=70: 0.627112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 05:26:31: Loss after num_examples_seen=600 epoch=75: 0.629760\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-26 05:26:42: Loss after num_examples_seen=640 epoch=80: 0.625479\n",
      "2018-06-26 05:26:52: Loss after num_examples_seen=680 epoch=85: 0.624096\n",
      "2018-06-26 05:27:02: Loss after num_examples_seen=720 epoch=90: 0.621947\n",
      "2018-06-26 05:27:13: Loss after num_examples_seen=760 epoch=95: 0.620532\n",
      "total training time: 3.50 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models/PSRContra_choice_only_session_sequences.npz.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source = ROOT + '/DATA_structures/RNN_sequences/'\n",
    "target = ROOT + '/DATA_structures/RNN_models/'\n",
    "\n",
    "for sequences in os.listdir(source):\n",
    "    print '*' * 80\n",
    "    print sequences\n",
    "    print '*' * 80\n",
    "    \n",
    "    x, y = pickle.load(open(source + sequences, 'rb'))\n",
    "    x_train, y_train, x_test, y_test = split_sequences_train_test(x, y, test_size = 0.2, random_state = 17) \n",
    "    elements_in_seq = np.max(x[0]) + 1\n",
    "\n",
    "    #initialize RNN\n",
    "    RNN = behaviorRNN(noFeatures = elements_in_seq, hidden_dim = 100, bptt_truncate = 30)    \n",
    "\n",
    "    #train the network\n",
    "    start = time.time()\n",
    "    RNN.train_with_sgd(x_train, y_train, learning_rate = 0.005, nepoch = 100)\n",
    "    print 'total training time: %1.2f minutes' %((time.time() - start)/60)\n",
    "    save_model_parameters(target + sequences[:sequences.find('.')] + '.npz', RNN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Network Performance\n",
    "\n",
    "All networks are trained, and training time was not bad at all. Everything was done over night, with no parallelization. I see some that only took 3 minutes, some that took 20 minutes, perhaps we can still train them a little harder. In any case, now we will see how they perform by checking each network on their respective test set. Also, for our purposes, we will test how each network does on the other datasets. We will only do this *within* input sequence type. So we don't care to test the network trained on split choice_only sequences on another dataset split with choice_reward sequences by session. In fact, that doesn't make any sense because the different sequences have different \"vocabulary\" size. So, our output will be a square matrix with dimensions = 14 x 56. We will make this a pandas dataframe for ease of manipulation and plotting purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_to_labels(sequences):\n",
    "    task = sequences[0] + 'SR'\n",
    "    regime = sequences[3: sequences.find('_')]\n",
    "    if sequences.find('reward') > 0:\n",
    "        seq_type = 'choice_reward'\n",
    "    elif sequences.find('reward') < 0:\n",
    "        seq_type = 'choice_only'\n",
    "    if sequences.find('split') > 0:\n",
    "        seq_split = 'split'\n",
    "    elif sequences.find('split') < 0:\n",
    "        seq_split = 'whole'\n",
    "    return task, regime, seq_type, seq_split\n",
    "    \n",
    "    \n",
    "def evaluate_model(test_seq, seq_type, model):\n",
    "   \n",
    "    noTrials = len(test_seq)\n",
    "    prediction = np.zeros(noTrials)\n",
    "    #first trial must be given\n",
    "    prediction[0] = test_seq[0]\n",
    "    \n",
    "    for trial in range(1, noTrials):\n",
    "        p = model.predict(test_seq[:trial])\n",
    "        prediction[trial] = p[-1]\n",
    "    \n",
    "    if seq_type == 'choice_only':\n",
    "        #first element of sequence was given so must subtract 1\n",
    "        hits = np.sum(test_seq == prediction) - 1\n",
    "        return hits, (noTrials - 1)\n",
    "    elif seq_type == 'choice_reward':\n",
    "        #get a sense of how well sequence did\n",
    "        sequence_hits = np.sum(test_seq == prediction) - 1\n",
    "        #we care if choice got decoded, not choice AND reward\n",
    "        task_hits = 0\n",
    "        for trial in range(1, noTrials):\n",
    "            if test_seq[trial] < 2 and prediction[trial] < 2:\n",
    "                task_hits += 1\n",
    "            elif test_seq[trial] > 1 and prediction[trial] > 1:\n",
    "                task_hits += 1\n",
    "        return task_hits, (noTrials - 1), sequence_hits\n",
    "\n",
    "\n",
    "def test_sequences(sequences, sequences2):\n",
    "    \n",
    "    #loading previously trained model\n",
    "    RNN = behaviorRNN()\n",
    "    load_model_parameters(target + sequences, RNN)\n",
    "    \n",
    "    #loading appropriate dataset\n",
    "    if sequences == sequences2:\n",
    "        tmp_seq = sequences[:sequences.find('.')] + '.p'\n",
    "        x, y = pickle.load(open(source + tmp_seq, 'rb'))\n",
    "        x_train, y_train, x_test, y_test = \\\n",
    "                split_sequences_train_test(x, y, test_size = 0.2, random_state = 17) \n",
    "        x = x_test\n",
    "    else:\n",
    "        tmp_seq = sequences2[:sequences2.find('.')] + '.p'\n",
    "        x, y = pickle.load(open(source + tmp_seq, 'rb'))\n",
    "    \n",
    "    #checking accuracy\n",
    "    hits = 0\n",
    "    trials = 0\n",
    "    for test_seq in x:\n",
    "        out = evaluate_model(test_seq, seq_type, RNN)\n",
    "        hits += out[0]\n",
    "        trials += out[1]\n",
    "            \n",
    "    return float(hits)/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: DSR - MPFC - choice_only - whole\n",
      "time elapsed: 1.10 minutes\n",
      "finished: DSR - Saline - choice_only - whole\n",
      "time elapsed: 1.02 minutes\n",
      "finished: PSR - Ipsi - choice_reward - whole\n",
      "time elapsed: 1.12 minutes\n",
      "finished: DSR - FirstTraining - choice_reward - whole\n",
      "time elapsed: 1.15 minutes\n",
      "finished: PSR - Saline - choice_reward - split\n",
      "time elapsed: 0.83 minutes\n",
      "finished: DSR - Contra - choice_only - split\n",
      "time elapsed: 0.96 minutes\n",
      "finished: PSR - OFC - choice_only - whole\n",
      "time elapsed: 1.10 minutes\n",
      "finished: DSR - OFC - choice_only - whole\n",
      "time elapsed: 1.13 minutes\n",
      "finished: DSR - MPFC - choice_reward - whole\n",
      "time elapsed: 1.14 minutes\n",
      "finished: DSR - Contra - choice_only - whole\n",
      "time elapsed: 1.12 minutes\n",
      "finished: DSR - Saline - choice_reward - whole\n",
      "time elapsed: 1.04 minutes\n",
      "finished: PSR - FirstTraining - choice_reward - split\n",
      "time elapsed: 0.99 minutes\n",
      "finished: PSR - Contra - choice_reward - split\n",
      "time elapsed: 0.97 minutes\n",
      "finished: DSR - MidTraining - choice_reward - split\n",
      "time elapsed: 1.00 minutes\n",
      "finished: PSR - MPFC - choice_reward - split\n",
      "time elapsed: 0.95 minutes\n",
      "finished: PSR - MPFC - choice_only - split\n",
      "time elapsed: 0.95 minutes\n",
      "finished: DSR - MidTraining - choice_only - whole\n",
      "time elapsed: 1.14 minutes\n",
      "finished: PSR - MPFC - choice_only - whole\n",
      "time elapsed: 1.11 minutes\n",
      "finished: PSR - Contra - choice_only - split\n",
      "time elapsed: 0.95 minutes\n",
      "finished: DSR - MidTraining - choice_reward - whole\n",
      "time elapsed: 1.14 minutes\n",
      "finished: PSR - FirstTraining - choice_only - whole\n",
      "time elapsed: 1.16 minutes\n",
      "finished: DSR - Contra - choice_reward - split\n",
      "time elapsed: 0.95 minutes\n",
      "finished: DSR - Ipsi - choice_only - split\n",
      "time elapsed: 0.96 minutes\n",
      "finished: PSR - Contra - choice_only - whole\n",
      "time elapsed: 1.09 minutes\n",
      "finished: PSR - Saline - choice_reward - whole\n",
      "time elapsed: 0.99 minutes\n",
      "finished: PSR - OFC - choice_only - split\n",
      "time elapsed: 0.97 minutes\n",
      "finished: PSR - OFC - choice_reward - split\n",
      "time elapsed: 0.98 minutes\n",
      "finished: PSR - MPFC - choice_reward - whole\n",
      "time elapsed: 1.10 minutes\n",
      "finished: DSR - FirstTraining - choice_only - split\n",
      "time elapsed: 0.99 minutes\n",
      "finished: DSR - OFC - choice_reward - split\n",
      "time elapsed: 0.97 minutes\n",
      "finished: PSR - OFC - choice_reward - whole\n",
      "time elapsed: 1.13 minutes\n",
      "finished: DSR - Ipsi - choice_reward - whole\n",
      "time elapsed: 1.12 minutes\n",
      "finished: DSR - Saline - choice_reward - split\n",
      "time elapsed: 0.92 minutes\n",
      "finished: DSR - MPFC - choice_reward - split\n",
      "time elapsed: 0.94 minutes\n",
      "finished: DSR - MidTraining - choice_only - split\n",
      "time elapsed: 0.99 minutes\n",
      "finished: PSR - FirstTraining - choice_reward - whole\n",
      "time elapsed: 1.17 minutes\n",
      "finished: PSR - Saline - choice_only - whole\n",
      "time elapsed: 0.97 minutes\n",
      "finished: DSR - Contra - choice_reward - whole\n",
      "time elapsed: 1.13 minutes\n",
      "finished: DSR - Saline - choice_only - split\n",
      "time elapsed: 0.92 minutes\n",
      "finished: PSR - Ipsi - choice_reward - split\n",
      "time elapsed: 0.97 minutes\n",
      "finished: DSR - MPFC - choice_only - split\n",
      "time elapsed: 0.97 minutes\n",
      "finished: DSR - FirstTraining - choice_only - whole\n",
      "time elapsed: 1.15 minutes\n",
      "finished: DSR - OFC - choice_reward - whole\n",
      "time elapsed: 1.14 minutes\n",
      "finished: DSR - Ipsi - choice_only - whole\n",
      "time elapsed: 1.11 minutes\n",
      "finished: PSR - MidTraining - choice_reward - whole\n",
      "time elapsed: 1.13 minutes\n",
      "finished: PSR - MidTraining - choice_reward - split\n",
      "time elapsed: 0.95 minutes\n",
      "finished: DSR - OFC - choice_only - split\n",
      "time elapsed: 0.97 minutes\n",
      "finished: PSR - Ipsi - choice_only - split\n",
      "time elapsed: 0.94 minutes\n",
      "finished: PSR - MidTraining - choice_only - whole\n",
      "time elapsed: 1.11 minutes\n",
      "finished: DSR - Ipsi - choice_reward - split\n",
      "time elapsed: 0.94 minutes\n",
      "finished: DSR - FirstTraining - choice_reward - split\n",
      "time elapsed: 0.98 minutes\n",
      "finished: PSR - Saline - choice_only - split\n",
      "time elapsed: 0.81 minutes\n",
      "finished: PSR - MidTraining - choice_only - split\n",
      "time elapsed: 0.97 minutes\n",
      "finished: PSR - FirstTraining - choice_only - split\n",
      "time elapsed: 0.98 minutes\n",
      "finished: PSR - Ipsi - choice_only - whole\n",
      "time elapsed: 1.09 minutes\n",
      "finished: PSR - Contra - choice_reward - whole\n",
      "time elapsed: 1.10 minutes\n",
      "seq_type             choice_only                                            \\\n",
      "seq_split                  split                                             \n",
      "task                         DSR                                             \n",
      "regime             FirstTraining MidTraining    Saline      MPFC       OFC   \n",
      "task regime                                                                  \n",
      "DSR  FirstTraining      0.669591    0.554201  0.542453  0.625097  0.559498   \n",
      "     MidTraining        0.562401    0.778107  0.598929  0.550323  0.601471   \n",
      "     Saline             0.532385    0.585632  0.692708  0.519534  0.610125   \n",
      "     MPFC               0.646919    0.578576  0.496303  0.683805  0.525314   \n",
      "     OFC                0.511058    0.601668  0.617415  0.519793  0.731207   \n",
      "     Ipsi               0.558452    0.596536  0.602881  0.538680  0.585028   \n",
      "     Contra             0.568720    0.571520  0.608746  0.558603  0.610125   \n",
      "PSR  FirstTraining      0.623223    0.582425  0.476798  0.675809  0.521419   \n",
      "     MidTraining        0.541864    0.585632  0.545003  0.576455  0.543920   \n",
      "     Saline             0.553712    0.601668  0.646354  0.538163  0.646041   \n",
      "     MPFC               0.587678    0.534958  0.514916  0.646572  0.523583   \n",
      "     OFC                0.560032    0.580500  0.570627  0.545149  0.570749   \n",
      "     Ipsi               0.548973    0.567672  0.567568  0.575162  0.570749   \n",
      "     Contra             0.571880    0.552919  0.513259  0.657697  0.541324   \n",
      "\n",
      "seq_type                                                                    \\\n",
      "seq_split                                                                    \n",
      "task                                             PSR                         \n",
      "regime                  Ipsi    Contra FirstTraining MidTraining    Saline   \n",
      "task regime                                                                  \n",
      "DSR  FirstTraining  0.580323  0.582873      0.590034    0.587590  0.540495   \n",
      "     MidTraining    0.607155  0.591467      0.523216    0.583369  0.563804   \n",
      "     Saline         0.618507  0.587477      0.498867    0.544956  0.570982   \n",
      "     MPFC           0.566219  0.582259      0.687995    0.593499  0.510768   \n",
      "     OFC            0.595115  0.581952      0.473386    0.517940  0.568111   \n",
      "     Ipsi           0.681985  0.585635      0.534541    0.535669  0.559750   \n",
      "     Contra         0.615411  0.748115      0.527746    0.547488  0.556625   \n",
      "PSR  FirstTraining  0.542484  0.562615      0.768150    0.590967  0.502660   \n",
      "     MidTraining    0.564155  0.577655      0.609853    0.728778  0.530783   \n",
      "     Saline         0.635019  0.608656      0.514723    0.543689  0.628903   \n",
      "     MPFC           0.535260  0.533149      0.630238    0.542001  0.517946   \n",
      "     OFC            0.577571  0.573665      0.523216    0.540734  0.556372   \n",
      "     Ipsi           0.569659  0.578576      0.562854    0.553398  0.538806   \n",
      "     Contra         0.561060  0.571823      0.648924    0.574082  0.530107   \n",
      "\n",
      "seq_type              ...    choice_reward                                    \\\n",
      "seq_split             ...            whole                                     \n",
      "task                  ...              DSR                               PSR   \n",
      "regime                ...              OFC      Ipsi    Contra FirstTraining   \n",
      "task regime           ...                                                      \n",
      "DSR  FirstTraining    ...         0.554745  0.581791  0.602502      0.632885   \n",
      "     MidTraining      ...         0.653690  0.634345  0.647672      0.580145   \n",
      "     Saline           ...         0.685320  0.663212  0.640028      0.537746   \n",
      "     MPFC             ...         0.499594  0.548483  0.587908      0.671148   \n",
      "     OFC              ...         0.682192  0.647668  0.626129      0.518097   \n",
      "     Ipsi             ...         0.688564  0.658974  0.635163      0.590486   \n",
      "     Contra           ...         0.658556  0.663953  0.686461      0.624612   \n",
      "PSR  FirstTraining    ...         0.568532  0.562546  0.574010      0.637755   \n",
      "     MidTraining      ...         0.597729  0.596595  0.610146      0.603930   \n",
      "     Saline           ...         0.732360  0.706884  0.695622      0.595657   \n",
      "     MPFC             ...         0.578264  0.587713  0.587213      0.662875   \n",
      "     OFC              ...         0.611517  0.621021  0.620570      0.597725   \n",
      "     Ipsi             ...         0.635036  0.638046  0.610146      0.599793   \n",
      "     Contra           ...         0.594485  0.614360  0.613621      0.623578   \n",
      "\n",
      "seq_type                                                                \\\n",
      "seq_split                                                                \n",
      "task                                                                     \n",
      "regime             MidTraining    Saline      MPFC       OFC      Ipsi   \n",
      "task regime                                                              \n",
      "DSR  FirstTraining    0.628794  0.551095  0.645218  0.562850  0.593023   \n",
      "     MidTraining      0.598439  0.588360  0.614522  0.566053  0.595930   \n",
      "     Saline           0.574154  0.622359  0.525974  0.590072  0.593023   \n",
      "     MPFC             0.606245  0.502689  0.668241  0.518014  0.559593   \n",
      "     OFC              0.581960  0.593738  0.523022  0.584468  0.552326   \n",
      "     Ipsi             0.611448  0.616788  0.561983  0.613291  0.621366   \n",
      "     Contra           0.632264  0.617941  0.602715  0.626902  0.616279   \n",
      "PSR  FirstTraining    0.606245  0.527660  0.657615  0.570056  0.582122   \n",
      "     MidTraining      0.610092  0.580676  0.610980  0.581265  0.597384   \n",
      "     Saline           0.627927  0.679761  0.570838  0.642114  0.646076   \n",
      "     MPFC             0.606245  0.539762  0.622754  0.566053  0.585029   \n",
      "     OFC              0.588899  0.586247  0.573790  0.626667  0.587209   \n",
      "     Ipsi             0.611448  0.591817  0.606257  0.615693  0.544118   \n",
      "     Contra           0.600173  0.562620  0.611570  0.558847  0.599564   \n",
      "\n",
      "seq_type                      \n",
      "seq_split                     \n",
      "task                          \n",
      "regime                Contra  \n",
      "task regime                   \n",
      "DSR  FirstTraining  0.618246  \n",
      "     MidTraining    0.582456  \n",
      "     Saline         0.573333  \n",
      "     MPFC           0.602807  \n",
      "     OFC            0.558596  \n",
      "     Ipsi           0.588772  \n",
      "     Contra         0.614737  \n",
      "PSR  FirstTraining  0.603509  \n",
      "     MidTraining    0.604912  \n",
      "     Saline         0.606316  \n",
      "     MPFC           0.600000  \n",
      "     OFC            0.560702  \n",
      "     Ipsi           0.593684  \n",
      "     Contra         0.612319  \n",
      "\n",
      "[14 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "#defining score dataframe\n",
    "iterables_row = [['DSR','PSR'], ['FirstTraining', 'MidTraining', 'Saline',\n",
    "                                 'MPFC', 'OFC', 'Ipsi', 'Contra']]\n",
    "iterables_column = [['choice_only', 'choice_reward'], ['split', 'whole'],\n",
    "                    ['DSR','PSR'], ['FirstTraining', 'MidTraining', 'Saline',\n",
    "                                 'MPFC', 'OFC', 'Ipsi', 'Contra']]\n",
    "\n",
    "\n",
    "\n",
    "row_index  = pd.MultiIndex.from_product(iterables_row, names=['task','regime'])\n",
    "column_index = pd.MultiIndex.from_product(iterables_column, names=['seq_type','seq_split','task','regime'])\n",
    "df = pd.DataFrame(np.full([len(row_index),len(column_index)], np.NaN),\n",
    "                                                      index = row_index,\n",
    "                                                      columns=column_index)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "for sequences in os.listdir(target):\n",
    "    task, regime, seq_type, seq_split = sequence_to_labels(sequences)\n",
    "    start = time.time()\n",
    "    for comparator in os.listdir(target):\n",
    "        task2, regime2, seq_type2, seq_split2  = sequence_to_labels(comparator)\n",
    "        #only working within input sequence type\n",
    "        if seq_type == seq_type2 and seq_split == seq_split2:\n",
    "            df.loc[idx[task, regime],\n",
    "                   idx[seq_type2, seq_split2, task2, regime2]] = \\\n",
    "                        test_sequences(sequences, comparator)\n",
    "    print 'finished: %s - %s - %s - %s' %(task, regime, seq_type, seq_split)\n",
    "    print 'time elapsed: %1.2f minutes' %((time.time() - start) / 60)\n",
    "\n",
    "pickle.dump(df, open( ROOT + '/DATA_structures/RNNgrid.p', 'wb'))\n",
    "print df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the grid, one per input sequence, which should be a 16x16 grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_models(grid, labels, title, vrange):\n",
    "    noDataSets = len(labels)\n",
    "    fig = plt.imshow(grid, vmin = vrange[0], vmax = vrange[1])\n",
    "    \n",
    "    plt.xticks(np.linspace(0,noDataSets - 1, noDataSets),\n",
    "                                            labels, rotation=90)\n",
    "    plt.yticks(np.linspace(0,noDataSets - 1, noDataSets),\n",
    "                                            labels, rotation=0)\n",
    "    plt.ylabel('Model')\n",
    "    plt.xlabel('dataset')\n",
    "    fig.axes.xaxis.tick_top()\n",
    "\n",
    "    plt.colorbar()\n",
    "    plt.title(title + '\\n\\n', fontSize=18, y=1.3)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGJCAYAAAB/3c+9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIKgLhEkgiAIgrpEkAiCIAjq8v8BsPuEDf6V1W4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c08e65dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGJCAYAAAB/3c+9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c08e65e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGJCAYAAAB/3c+9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nENQlgkQQBEFQlwgSQRAEQV3+HyomYNB7UOzqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c08e65c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGJCAYAAAB/3c+9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB6+nNMUNTKVEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c0def0450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "ROOT = '/Users/pablomartin/python/'\n",
    "sys.path.append(ROOT)\n",
    "from Visualize.decoding import plot_model_grid\n",
    "\n",
    "\n",
    "df = pickle.load(open( ROOT + '/DATA_structures/RNNgrid.p', 'rb'))\n",
    "\n",
    "labels = [df.index.levels[0][a] + df.index.levels[1][b] \\\n",
    "             for a,b in zip(df.index.labels[0], df.index.labels[1])]\n",
    "\n",
    "for info_included in ['choice_only', 'choice_reward']:\n",
    "    for seq_type in ['split', 'whole']:\n",
    "        input_seq = info_included + '_' + seq_type\n",
    "        plot_model_grid(df[info_included, seq_type], [0.5, 0.8], \n",
    "            title = 'Recurrent Neural Network Decoding\\n %s' %input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Interpretations    \n",
    "\n",
    "Some things to note right away is that there is a big difference in how we prepare the data. Breaking up the sessions into smaller \"chunks\" greatly improves performance of the model. Also, if we include information about the reward, as opposed to just using the choice, we get better decoding (look at diagonal). Neither of these things is surprising. Of course the information about reward is relevant. Also, \"vanilla\" RNNs are supposed to struggle with longer sequences and learning longer dependencies. So it is not surprising that if we fed the dataset \"cut up\" the models learned better.  \n",
    "\n",
    "As for the data itself, the result of FirstTraining and MPFC predicting each other is barely there. I am looking only at choice_reward_split which corresponds to the third graph and the model with the best performance. Overall, decoding along the diagonal was not impressive either. Here are some next steps that come to mind:  \n",
    "\n",
    "1) do some stat to see what models are \"coupled\" together  \n",
    "2) train RNN for more epochs ? the error reduction for a lot of these was already asymptotic so pretty sure that wouldn't really help. EDIT: actually some of them look asymptotic but not all of them  \n",
    "3) Explore where these networks are making their decoding mistakes.    \n",
    "4) to do 3), unfortunately, we would have to retrain all the networks and split the data so as to leave entire sessions out, otherwise the test set is a bunch of small sequences from all over the place, and hard to tell where in the session it's going wrong. what patterns is it picking out ?  \n",
    "5) to combine 2-4 and our conclusion that it was only the choice_reward_splits input sequence that was significantly better than the other we could do the following:    \n",
    "\n",
    "Let's re-train everything with proper training and testing set separation, such that the testing set is taken from intact sessions that WE CAN VISUALIZE. Further, we can try higher batch number and bppt_truncate #, and *only* train with the data formatted as choice_reward_splits. We train 1/4 of the models but with greater depth.   \n",
    "\n",
    "6) AND FINALLY, IF AND WHEN YOU DO THE POINTS ABOVE, THEN we may want to try fancier RNNs. Either \"deep\" ones, with more than one hidden layer, or long short-term memory (LSTM) ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train Network with Greater Depth  \n",
    "\n",
    "Main things to implement here are, proper data splitting and saving, so we don't have to rely on random seeds to know *how* the data was split.  \n",
    "\n",
    "Train with greater depth and only one type of input sequence! What's greater depth here ? Since sequence length will be at most 50, since len(seq) ~ N(mu = 20, sigma = 7), we will set bptt_truncate to that. This means that the entire length of all sequences will be considered. The number of epochs will be doubled. Even that seems excessive as most errors were already plateauing, but let's try it anyways so we are not left with the doubt. AND the final element that can add depth to the network is the # of units of the hidden layer. Currently, it's set at 100. I haven't built enough intuition to know whether this is sufficient, although 100 things to learn about the sequences seems enough to me. We will also double this number so that we are left without a doubt and don't have to train the networks again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "training RNN on PSR - MPFC\n",
      "********************************************************************************\n",
      "2018-06-27 00:19:24: Loss after num_examples_seen=0 epoch=0: 1.667220\n",
      "2018-06-27 00:20:19: Loss after num_examples_seen=305 epoch=5: 0.958414\n",
      "2018-06-27 00:21:13: Loss after num_examples_seen=610 epoch=10: 0.942054\n",
      "2018-06-27 00:22:07: Loss after num_examples_seen=915 epoch=15: 0.984904\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 00:23:01: Loss after num_examples_seen=1220 epoch=20: 0.755833\n",
      "2018-06-27 00:23:55: Loss after num_examples_seen=1525 epoch=25: 0.730143\n",
      "2018-06-27 00:24:49: Loss after num_examples_seen=1830 epoch=30: 0.564398\n",
      "2018-06-27 00:25:42: Loss after num_examples_seen=2135 epoch=35: 1.172298\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 00:26:36: Loss after num_examples_seen=2440 epoch=40: 0.906746\n",
      "2018-06-27 00:27:31: Loss after num_examples_seen=2745 epoch=45: 0.872210\n",
      "2018-06-27 00:28:24: Loss after num_examples_seen=3050 epoch=50: 0.596673\n",
      "2018-06-27 00:29:18: Loss after num_examples_seen=3355 epoch=55: 0.438019\n",
      "2018-06-27 00:30:12: Loss after num_examples_seen=3660 epoch=60: 0.326190\n",
      "2018-06-27 00:31:06: Loss after num_examples_seen=3965 epoch=65: 0.257201\n",
      "2018-06-27 00:32:00: Loss after num_examples_seen=4270 epoch=70: 0.198843\n",
      "2018-06-27 00:32:54: Loss after num_examples_seen=4575 epoch=75: 0.160093\n",
      "2018-06-27 00:33:48: Loss after num_examples_seen=4880 epoch=80: 1.014508\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 00:34:42: Loss after num_examples_seen=5185 epoch=85: 0.912731\n",
      "2018-06-27 00:35:36: Loss after num_examples_seen=5490 epoch=90: 0.883322\n",
      "2018-06-27 00:36:30: Loss after num_examples_seen=5795 epoch=95: 1.000633\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 00:37:24: Loss after num_examples_seen=6100 epoch=100: 0.825175\n",
      "2018-06-27 00:38:17: Loss after num_examples_seen=6405 epoch=105: 0.807125\n",
      "2018-06-27 00:39:11: Loss after num_examples_seen=6710 epoch=110: 0.753798\n",
      "2018-06-27 00:40:05: Loss after num_examples_seen=7015 epoch=115: 0.721772\n",
      "2018-06-27 00:40:59: Loss after num_examples_seen=7320 epoch=120: 0.860759\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-27 00:41:53: Loss after num_examples_seen=7625 epoch=125: 0.852348\n",
      "2018-06-27 00:42:47: Loss after num_examples_seen=7930 epoch=130: 0.787886\n",
      "2018-06-27 00:43:40: Loss after num_examples_seen=8235 epoch=135: 0.794565\n",
      "Setting learning rate to 0.000078\n",
      "2018-06-27 00:44:34: Loss after num_examples_seen=8540 epoch=140: 0.773025\n",
      "2018-06-27 00:45:28: Loss after num_examples_seen=8845 epoch=145: 0.745130\n",
      "2018-06-27 00:46:22: Loss after num_examples_seen=9150 epoch=150: 0.724594\n",
      "2018-06-27 00:47:16: Loss after num_examples_seen=9455 epoch=155: 0.738754\n",
      "Setting learning rate to 0.000039\n",
      "2018-06-27 00:48:09: Loss after num_examples_seen=9760 epoch=160: 0.711621\n",
      "2018-06-27 00:49:03: Loss after num_examples_seen=10065 epoch=165: 0.693759\n",
      "2018-06-27 00:49:57: Loss after num_examples_seen=10370 epoch=170: 0.687717\n",
      "2018-06-27 00:50:51: Loss after num_examples_seen=10675 epoch=175: 0.684082\n",
      "2018-06-27 00:51:45: Loss after num_examples_seen=10980 epoch=180: 0.674219\n",
      "2018-06-27 00:52:39: Loss after num_examples_seen=11285 epoch=185: 0.669031\n",
      "2018-06-27 00:53:33: Loss after num_examples_seen=11590 epoch=190: 0.664687\n",
      "2018-06-27 00:54:27: Loss after num_examples_seen=11895 epoch=195: 0.656275\n",
      "total training time: 35.95 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/PSRMPFC_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on DSR - FirstTraining\n",
      "********************************************************************************\n",
      "2018-06-27 00:55:20: Loss after num_examples_seen=0 epoch=0: 1.589192\n",
      "2018-06-27 00:55:34: Loss after num_examples_seen=165 epoch=5: 0.819519\n",
      "2018-06-27 00:55:48: Loss after num_examples_seen=330 epoch=10: 0.980242\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 00:56:02: Loss after num_examples_seen=495 epoch=15: 0.927426\n",
      "2018-06-27 00:56:16: Loss after num_examples_seen=660 epoch=20: 0.849965\n",
      "2018-06-27 00:56:30: Loss after num_examples_seen=825 epoch=25: 1.140857\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 00:56:44: Loss after num_examples_seen=990 epoch=30: 0.711201\n",
      "2018-06-27 00:56:58: Loss after num_examples_seen=1155 epoch=35: 0.701714\n",
      "2018-06-27 00:57:12: Loss after num_examples_seen=1320 epoch=40: 0.706062\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 00:57:26: Loss after num_examples_seen=1485 epoch=45: 0.636565\n",
      "2018-06-27 00:57:39: Loss after num_examples_seen=1650 epoch=50: 0.629613\n",
      "2018-06-27 00:57:53: Loss after num_examples_seen=1815 epoch=55: 0.624990\n",
      "2018-06-27 00:58:07: Loss after num_examples_seen=1980 epoch=60: 0.622468\n",
      "2018-06-27 00:58:21: Loss after num_examples_seen=2145 epoch=65: 0.621066\n",
      "2018-06-27 00:58:35: Loss after num_examples_seen=2310 epoch=70: 0.620779\n",
      "2018-06-27 00:58:49: Loss after num_examples_seen=2475 epoch=75: 0.621521\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 00:59:03: Loss after num_examples_seen=2640 epoch=80: 0.590541\n",
      "2018-06-27 00:59:17: Loss after num_examples_seen=2805 epoch=85: 0.586673\n",
      "2018-06-27 00:59:31: Loss after num_examples_seen=2970 epoch=90: 0.584376\n",
      "2018-06-27 00:59:45: Loss after num_examples_seen=3135 epoch=95: 0.583079\n",
      "2018-06-27 00:59:58: Loss after num_examples_seen=3300 epoch=100: 0.582334\n",
      "2018-06-27 01:00:12: Loss after num_examples_seen=3465 epoch=105: 0.581658\n",
      "2018-06-27 01:00:26: Loss after num_examples_seen=3630 epoch=110: 0.580741\n",
      "2018-06-27 01:00:40: Loss after num_examples_seen=3795 epoch=115: 0.579532\n",
      "2018-06-27 01:00:54: Loss after num_examples_seen=3960 epoch=120: 0.578092\n",
      "2018-06-27 01:01:08: Loss after num_examples_seen=4125 epoch=125: 0.576480\n",
      "2018-06-27 01:01:22: Loss after num_examples_seen=4290 epoch=130: 0.574752\n",
      "2018-06-27 01:01:36: Loss after num_examples_seen=4455 epoch=135: 0.572957\n",
      "2018-06-27 01:01:50: Loss after num_examples_seen=4620 epoch=140: 0.571117\n",
      "2018-06-27 01:02:04: Loss after num_examples_seen=4785 epoch=145: 0.569214\n",
      "2018-06-27 01:02:17: Loss after num_examples_seen=4950 epoch=150: 0.567203\n",
      "2018-06-27 01:02:31: Loss after num_examples_seen=5115 epoch=155: 0.565044\n",
      "2018-06-27 01:02:45: Loss after num_examples_seen=5280 epoch=160: 0.562712\n",
      "2018-06-27 01:02:59: Loss after num_examples_seen=5445 epoch=165: 0.560174\n",
      "2018-06-27 01:03:13: Loss after num_examples_seen=5610 epoch=170: 0.557401\n",
      "2018-06-27 01:03:27: Loss after num_examples_seen=5775 epoch=175: 0.554404\n",
      "2018-06-27 01:03:41: Loss after num_examples_seen=5940 epoch=180: 0.551236\n",
      "2018-06-27 01:03:54: Loss after num_examples_seen=6105 epoch=185: 0.547958\n",
      "2018-06-27 01:04:08: Loss after num_examples_seen=6270 epoch=190: 0.544602\n",
      "2018-06-27 01:04:22: Loss after num_examples_seen=6435 epoch=195: 0.541152\n",
      "total training time: 9.26 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/DSRFirstTraining_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on PSR - MidTraining\n",
      "********************************************************************************\n",
      "2018-06-27 01:04:36: Loss after num_examples_seen=0 epoch=0: 1.633471\n",
      "2018-06-27 01:05:07: Loss after num_examples_seen=240 epoch=5: 1.046129\n",
      "2018-06-27 01:05:38: Loss after num_examples_seen=480 epoch=10: 1.067237\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 01:06:09: Loss after num_examples_seen=720 epoch=15: 0.938854\n",
      "2018-06-27 01:06:41: Loss after num_examples_seen=960 epoch=20: 0.840914\n",
      "2018-06-27 01:07:12: Loss after num_examples_seen=1200 epoch=25: 0.703832\n",
      "2018-06-27 01:07:43: Loss after num_examples_seen=1440 epoch=30: 0.571761\n",
      "2018-06-27 01:08:14: Loss after num_examples_seen=1680 epoch=35: 0.430378\n",
      "2018-06-27 01:08:45: Loss after num_examples_seen=1920 epoch=40: 0.292820\n",
      "2018-06-27 01:09:16: Loss after num_examples_seen=2160 epoch=45: 0.192853\n",
      "2018-06-27 01:09:47: Loss after num_examples_seen=2400 epoch=50: 3.526522\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 01:10:18: Loss after num_examples_seen=2640 epoch=55: 1.263667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 01:10:49: Loss after num_examples_seen=2880 epoch=60: 1.186851\n",
      "2018-06-27 01:11:20: Loss after num_examples_seen=3120 epoch=65: 1.127247\n",
      "2018-06-27 01:11:51: Loss after num_examples_seen=3360 epoch=70: 1.092265\n",
      "2018-06-27 01:12:22: Loss after num_examples_seen=3600 epoch=75: 1.174236\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 01:12:53: Loss after num_examples_seen=3840 epoch=80: 1.004690\n",
      "2018-06-27 01:13:24: Loss after num_examples_seen=4080 epoch=85: 0.977277\n",
      "2018-06-27 01:13:55: Loss after num_examples_seen=4320 epoch=90: 0.955828\n",
      "2018-06-27 01:14:26: Loss after num_examples_seen=4560 epoch=95: 0.937133\n",
      "2018-06-27 01:14:57: Loss after num_examples_seen=4800 epoch=100: 0.921987\n",
      "2018-06-27 01:15:28: Loss after num_examples_seen=5040 epoch=105: 0.906544\n",
      "2018-06-27 01:15:59: Loss after num_examples_seen=5280 epoch=110: 0.891794\n",
      "2018-06-27 01:16:31: Loss after num_examples_seen=5520 epoch=115: 0.878509\n",
      "2018-06-27 01:17:01: Loss after num_examples_seen=5760 epoch=120: 0.864250\n",
      "2018-06-27 01:17:32: Loss after num_examples_seen=6000 epoch=125: 0.846686\n",
      "2018-06-27 01:18:04: Loss after num_examples_seen=6240 epoch=130: 0.836597\n",
      "2018-06-27 01:18:35: Loss after num_examples_seen=6480 epoch=135: 0.815472\n",
      "2018-06-27 01:19:06: Loss after num_examples_seen=6720 epoch=140: 0.798588\n",
      "2018-06-27 01:19:37: Loss after num_examples_seen=6960 epoch=145: 0.780749\n",
      "2018-06-27 01:20:08: Loss after num_examples_seen=7200 epoch=150: 0.762255\n",
      "2018-06-27 01:20:39: Loss after num_examples_seen=7440 epoch=155: 0.744388\n",
      "2018-06-27 01:21:10: Loss after num_examples_seen=7680 epoch=160: 0.724148\n",
      "2018-06-27 01:21:41: Loss after num_examples_seen=7920 epoch=165: 0.708876\n",
      "2018-06-27 01:22:12: Loss after num_examples_seen=8160 epoch=170: 0.700782\n",
      "2018-06-27 01:22:43: Loss after num_examples_seen=8400 epoch=175: 0.668447\n",
      "2018-06-27 01:23:14: Loss after num_examples_seen=8640 epoch=180: 0.657625\n",
      "2018-06-27 01:23:45: Loss after num_examples_seen=8880 epoch=185: 0.672944\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 01:24:16: Loss after num_examples_seen=9120 epoch=190: 0.598270\n",
      "2018-06-27 01:24:47: Loss after num_examples_seen=9360 epoch=195: 0.584641\n",
      "total training time: 20.70 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/PSRMidTraining_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on PSR - Ipsi\n",
      "********************************************************************************\n",
      "2018-06-27 01:25:18: Loss after num_examples_seen=0 epoch=0: 1.562822\n",
      "2018-06-27 01:26:03: Loss after num_examples_seen=280 epoch=5: 1.138338\n",
      "2018-06-27 01:26:49: Loss after num_examples_seen=560 epoch=10: 1.178168\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 01:27:34: Loss after num_examples_seen=840 epoch=15: 1.072801\n",
      "2018-06-27 01:28:20: Loss after num_examples_seen=1120 epoch=20: 0.965622\n",
      "2018-06-27 01:29:05: Loss after num_examples_seen=1400 epoch=25: 0.814860\n",
      "2018-06-27 01:29:50: Loss after num_examples_seen=1680 epoch=30: 1.435892\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 01:30:35: Loss after num_examples_seen=1960 epoch=35: 1.113047\n",
      "2018-06-27 01:31:21: Loss after num_examples_seen=2240 epoch=40: 1.156939\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 01:32:06: Loss after num_examples_seen=2520 epoch=45: 1.093570\n",
      "2018-06-27 01:32:52: Loss after num_examples_seen=2800 epoch=50: 1.111505\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 01:33:37: Loss after num_examples_seen=3080 epoch=55: 1.066372\n",
      "2018-06-27 01:34:22: Loss after num_examples_seen=3360 epoch=60: 1.051833\n",
      "2018-06-27 01:35:08: Loss after num_examples_seen=3640 epoch=65: 1.050109\n",
      "2018-06-27 01:35:53: Loss after num_examples_seen=3920 epoch=70: 1.046119\n",
      "2018-06-27 01:36:38: Loss after num_examples_seen=4200 epoch=75: 1.046052\n",
      "2018-06-27 01:37:24: Loss after num_examples_seen=4480 epoch=80: 1.019706\n",
      "2018-06-27 01:38:09: Loss after num_examples_seen=4760 epoch=85: 1.017032\n",
      "2018-06-27 01:38:54: Loss after num_examples_seen=5040 epoch=90: 1.011647\n",
      "2018-06-27 01:39:40: Loss after num_examples_seen=5320 epoch=95: 0.995578\n",
      "2018-06-27 01:40:25: Loss after num_examples_seen=5600 epoch=100: 0.984855\n",
      "2018-06-27 01:41:11: Loss after num_examples_seen=5880 epoch=105: 1.059567\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-27 01:41:56: Loss after num_examples_seen=6160 epoch=110: 1.021615\n",
      "2018-06-27 01:42:41: Loss after num_examples_seen=6440 epoch=115: 1.010999\n",
      "2018-06-27 01:43:27: Loss after num_examples_seen=6720 epoch=120: 0.986247\n",
      "2018-06-27 01:44:12: Loss after num_examples_seen=7000 epoch=125: 0.976214\n",
      "2018-06-27 01:44:58: Loss after num_examples_seen=7280 epoch=130: 1.001694\n",
      "Setting learning rate to 0.000078\n",
      "2018-06-27 01:45:43: Loss after num_examples_seen=7560 epoch=135: 0.947593\n",
      "2018-06-27 01:46:28: Loss after num_examples_seen=7840 epoch=140: 0.956044\n",
      "Setting learning rate to 0.000039\n",
      "2018-06-27 01:47:14: Loss after num_examples_seen=8120 epoch=145: 0.936608\n",
      "2018-06-27 01:47:59: Loss after num_examples_seen=8400 epoch=150: 0.933562\n",
      "2018-06-27 01:48:45: Loss after num_examples_seen=8680 epoch=155: 0.930951\n",
      "2018-06-27 01:49:30: Loss after num_examples_seen=8960 epoch=160: 0.927905\n",
      "2018-06-27 01:50:15: Loss after num_examples_seen=9240 epoch=165: 0.927074\n",
      "2018-06-27 01:51:01: Loss after num_examples_seen=9520 epoch=170: 0.923055\n",
      "2018-06-27 01:51:46: Loss after num_examples_seen=9800 epoch=175: 0.916534\n",
      "2018-06-27 01:52:31: Loss after num_examples_seen=10080 epoch=180: 0.913302\n",
      "2018-06-27 01:53:17: Loss after num_examples_seen=10360 epoch=185: 0.910995\n",
      "2018-06-27 01:54:02: Loss after num_examples_seen=10640 epoch=190: 0.908454\n",
      "2018-06-27 01:54:47: Loss after num_examples_seen=10920 epoch=195: 0.905748\n",
      "total training time: 30.24 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/PSRIpsi_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on DSR - OFC\n",
      "********************************************************************************\n",
      "2018-06-27 01:55:33: Loss after num_examples_seen=0 epoch=0: 1.547310\n",
      "2018-06-27 01:55:59: Loss after num_examples_seen=225 epoch=5: 0.733093\n",
      "2018-06-27 01:56:26: Loss after num_examples_seen=450 epoch=10: 0.691744\n",
      "2018-06-27 01:56:53: Loss after num_examples_seen=675 epoch=15: 0.692397\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 01:57:19: Loss after num_examples_seen=900 epoch=20: 0.550037\n",
      "2018-06-27 01:57:46: Loss after num_examples_seen=1125 epoch=25: 0.532626\n",
      "2018-06-27 01:58:13: Loss after num_examples_seen=1350 epoch=30: 0.517899\n",
      "2018-06-27 01:58:39: Loss after num_examples_seen=1575 epoch=35: 0.454498\n",
      "2018-06-27 01:59:06: Loss after num_examples_seen=1800 epoch=40: 0.419597\n",
      "2018-06-27 01:59:33: Loss after num_examples_seen=2025 epoch=45: 0.377788\n",
      "2018-06-27 01:59:59: Loss after num_examples_seen=2250 epoch=50: 0.229842\n",
      "2018-06-27 02:00:26: Loss after num_examples_seen=2475 epoch=55: 0.135809\n",
      "2018-06-27 02:00:53: Loss after num_examples_seen=2700 epoch=60: 0.918288\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 02:01:19: Loss after num_examples_seen=2925 epoch=65: 0.707626\n",
      "2018-06-27 02:01:46: Loss after num_examples_seen=3150 epoch=70: 0.665112\n",
      "2018-06-27 02:02:13: Loss after num_examples_seen=3375 epoch=75: 0.649967\n",
      "2018-06-27 02:02:39: Loss after num_examples_seen=3600 epoch=80: 0.643345\n",
      "2018-06-27 02:03:06: Loss after num_examples_seen=3825 epoch=85: 0.634180\n",
      "2018-06-27 02:03:33: Loss after num_examples_seen=4050 epoch=90: 0.626666\n",
      "2018-06-27 02:04:00: Loss after num_examples_seen=4275 epoch=95: 0.615681\n",
      "2018-06-27 02:04:26: Loss after num_examples_seen=4500 epoch=100: 0.604055\n",
      "2018-06-27 02:04:53: Loss after num_examples_seen=4725 epoch=105: 0.606755\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 02:05:20: Loss after num_examples_seen=4950 epoch=110: 0.578339\n",
      "2018-06-27 02:05:46: Loss after num_examples_seen=5175 epoch=115: 0.568251\n",
      "2018-06-27 02:06:13: Loss after num_examples_seen=5400 epoch=120: 0.557524\n",
      "2018-06-27 02:06:39: Loss after num_examples_seen=5625 epoch=125: 0.547751\n",
      "2018-06-27 02:07:06: Loss after num_examples_seen=5850 epoch=130: 0.538052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 02:07:33: Loss after num_examples_seen=6075 epoch=135: 0.527895\n",
      "2018-06-27 02:07:59: Loss after num_examples_seen=6300 epoch=140: 0.517881\n",
      "2018-06-27 02:08:26: Loss after num_examples_seen=6525 epoch=145: 0.510808\n",
      "2018-06-27 02:08:53: Loss after num_examples_seen=6750 epoch=150: 0.498349\n",
      "2018-06-27 02:09:19: Loss after num_examples_seen=6975 epoch=155: 0.489094\n",
      "2018-06-27 02:09:46: Loss after num_examples_seen=7200 epoch=160: 0.489405\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 02:10:13: Loss after num_examples_seen=7425 epoch=165: 0.466818\n",
      "2018-06-27 02:10:39: Loss after num_examples_seen=7650 epoch=170: 0.460382\n",
      "2018-06-27 02:11:06: Loss after num_examples_seen=7875 epoch=175: 0.454428\n",
      "2018-06-27 02:11:32: Loss after num_examples_seen=8100 epoch=180: 0.448378\n",
      "2018-06-27 02:11:59: Loss after num_examples_seen=8325 epoch=185: 0.442070\n",
      "2018-06-27 02:12:26: Loss after num_examples_seen=8550 epoch=190: 0.435484\n",
      "2018-06-27 02:12:52: Loss after num_examples_seen=8775 epoch=195: 0.428667\n",
      "total training time: 17.77 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/DSROFC_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on PSR - OFC\n",
      "********************************************************************************\n",
      "2018-06-27 02:13:19: Loss after num_examples_seen=0 epoch=0: 1.622622\n",
      "2018-06-27 02:13:53: Loss after num_examples_seen=250 epoch=5: 1.122856\n",
      "2018-06-27 02:14:28: Loss after num_examples_seen=500 epoch=10: 1.113947\n",
      "2018-06-27 02:15:02: Loss after num_examples_seen=750 epoch=15: 1.050345\n",
      "2018-06-27 02:15:36: Loss after num_examples_seen=1000 epoch=20: 0.947090\n",
      "2018-06-27 02:16:10: Loss after num_examples_seen=1250 epoch=25: 1.907687\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 02:16:44: Loss after num_examples_seen=1500 epoch=30: 1.721827\n",
      "2018-06-27 02:17:18: Loss after num_examples_seen=1750 epoch=35: 1.438206\n",
      "2018-06-27 02:17:53: Loss after num_examples_seen=2000 epoch=40: 1.277554\n",
      "2018-06-27 02:18:27: Loss after num_examples_seen=2250 epoch=45: 1.222863\n",
      "2018-06-27 02:19:01: Loss after num_examples_seen=2500 epoch=50: 1.208675\n",
      "2018-06-27 02:19:35: Loss after num_examples_seen=2750 epoch=55: 1.190226\n",
      "2018-06-27 02:20:09: Loss after num_examples_seen=3000 epoch=60: 1.168770\n",
      "2018-06-27 02:20:44: Loss after num_examples_seen=3250 epoch=65: 1.144172\n",
      "2018-06-27 02:21:18: Loss after num_examples_seen=3500 epoch=70: 1.126612\n",
      "2018-06-27 02:21:52: Loss after num_examples_seen=3750 epoch=75: 1.125126\n",
      "2018-06-27 02:22:26: Loss after num_examples_seen=4000 epoch=80: 1.133711\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 02:23:00: Loss after num_examples_seen=4250 epoch=85: 1.063801\n",
      "2018-06-27 02:23:35: Loss after num_examples_seen=4500 epoch=90: 1.110832\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 02:24:09: Loss after num_examples_seen=4750 epoch=95: 1.037563\n",
      "2018-06-27 02:24:43: Loss after num_examples_seen=5000 epoch=100: 1.026282\n",
      "2018-06-27 02:25:17: Loss after num_examples_seen=5250 epoch=105: 1.018096\n",
      "2018-06-27 02:25:51: Loss after num_examples_seen=5500 epoch=110: 1.011248\n",
      "2018-06-27 02:26:25: Loss after num_examples_seen=5750 epoch=115: 1.005318\n",
      "2018-06-27 02:27:00: Loss after num_examples_seen=6000 epoch=120: 1.000159\n",
      "2018-06-27 02:27:34: Loss after num_examples_seen=6250 epoch=125: 0.995314\n",
      "2018-06-27 02:28:08: Loss after num_examples_seen=6500 epoch=130: 0.990448\n",
      "2018-06-27 02:28:42: Loss after num_examples_seen=6750 epoch=135: 0.985830\n",
      "2018-06-27 02:29:16: Loss after num_examples_seen=7000 epoch=140: 1.021793\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 02:29:51: Loss after num_examples_seen=7250 epoch=145: 0.982245\n",
      "2018-06-27 02:30:25: Loss after num_examples_seen=7500 epoch=150: 0.972524\n",
      "2018-06-27 02:30:59: Loss after num_examples_seen=7750 epoch=155: 0.970086\n",
      "2018-06-27 02:31:34: Loss after num_examples_seen=8000 epoch=160: 0.966099\n",
      "2018-06-27 02:32:08: Loss after num_examples_seen=8250 epoch=165: 0.963158\n",
      "2018-06-27 02:32:42: Loss after num_examples_seen=8500 epoch=170: 0.960538\n",
      "2018-06-27 02:33:16: Loss after num_examples_seen=8750 epoch=175: 0.957953\n",
      "2018-06-27 02:33:50: Loss after num_examples_seen=9000 epoch=180: 0.955372\n",
      "2018-06-27 02:34:25: Loss after num_examples_seen=9250 epoch=185: 0.952754\n",
      "2018-06-27 02:34:59: Loss after num_examples_seen=9500 epoch=190: 0.950058\n",
      "2018-06-27 02:35:33: Loss after num_examples_seen=9750 epoch=195: 0.947301\n",
      "total training time: 22.80 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/PSROFC_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on PSR - Saline\n",
      "********************************************************************************\n",
      "2018-06-27 02:36:08: Loss after num_examples_seen=0 epoch=0: 1.645078\n",
      "2018-06-27 02:38:35: Loss after num_examples_seen=1050 epoch=5: 1.172830\n",
      "2018-06-27 02:41:02: Loss after num_examples_seen=2100 epoch=10: 1.207197\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 02:43:30: Loss after num_examples_seen=3150 epoch=15: 1.116095\n",
      "2018-06-27 02:45:57: Loss after num_examples_seen=4200 epoch=20: 1.178111\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 02:48:25: Loss after num_examples_seen=5250 epoch=25: 1.037159\n",
      "2018-06-27 02:50:52: Loss after num_examples_seen=6300 epoch=30: 1.020397\n",
      "2018-06-27 02:53:20: Loss after num_examples_seen=7350 epoch=35: 0.903448\n",
      "2018-06-27 02:55:47: Loss after num_examples_seen=8400 epoch=40: 0.966842\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 02:58:14: Loss after num_examples_seen=9450 epoch=45: 0.513872\n",
      "2018-06-27 03:00:42: Loss after num_examples_seen=10500 epoch=50: 0.458929\n",
      "2018-06-27 03:03:09: Loss after num_examples_seen=11550 epoch=55: 0.441859\n",
      "2018-06-27 03:05:37: Loss after num_examples_seen=12600 epoch=60: 0.391296\n",
      "2018-06-27 03:08:05: Loss after num_examples_seen=13650 epoch=65: 0.332378\n",
      "2018-06-27 03:10:32: Loss after num_examples_seen=14700 epoch=70: 0.297090\n",
      "2018-06-27 03:13:00: Loss after num_examples_seen=15750 epoch=75: 0.649982\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 03:15:27: Loss after num_examples_seen=16800 epoch=80: 0.232038\n",
      "2018-06-27 03:17:55: Loss after num_examples_seen=17850 epoch=85: 0.170460\n",
      "2018-06-27 03:20:22: Loss after num_examples_seen=18900 epoch=90: 0.146605\n",
      "2018-06-27 03:22:49: Loss after num_examples_seen=19950 epoch=95: 0.135508\n",
      "2018-06-27 03:25:17: Loss after num_examples_seen=21000 epoch=100: 0.129144\n",
      "2018-06-27 03:27:44: Loss after num_examples_seen=22050 epoch=105: 0.124885\n",
      "2018-06-27 03:30:11: Loss after num_examples_seen=23100 epoch=110: 0.121751\n",
      "2018-06-27 03:32:39: Loss after num_examples_seen=24150 epoch=115: 0.119305\n",
      "2018-06-27 03:35:06: Loss after num_examples_seen=25200 epoch=120: 0.117320\n",
      "2018-06-27 03:37:33: Loss after num_examples_seen=26250 epoch=125: 0.115666\n",
      "2018-06-27 03:40:01: Loss after num_examples_seen=27300 epoch=130: 0.114259\n",
      "2018-06-27 03:42:28: Loss after num_examples_seen=28350 epoch=135: 0.113043\n",
      "2018-06-27 03:44:56: Loss after num_examples_seen=29400 epoch=140: 0.111977\n",
      "2018-06-27 03:47:23: Loss after num_examples_seen=30450 epoch=145: 0.111032\n",
      "2018-06-27 03:49:51: Loss after num_examples_seen=31500 epoch=150: 0.110184\n",
      "2018-06-27 03:52:18: Loss after num_examples_seen=32550 epoch=155: 0.109419\n",
      "2018-06-27 03:54:46: Loss after num_examples_seen=33600 epoch=160: 0.108721\n",
      "2018-06-27 03:57:13: Loss after num_examples_seen=34650 epoch=165: 0.108081\n",
      "2018-06-27 03:59:40: Loss after num_examples_seen=35700 epoch=170: 0.107490\n",
      "2018-06-27 04:02:08: Loss after num_examples_seen=36750 epoch=175: 0.106942\n",
      "2018-06-27 04:04:36: Loss after num_examples_seen=37800 epoch=180: 0.106433\n",
      "2018-06-27 04:07:03: Loss after num_examples_seen=38850 epoch=185: 0.105957\n",
      "2018-06-27 04:09:31: Loss after num_examples_seen=39900 epoch=190: 0.105513\n",
      "2018-06-27 04:11:58: Loss after num_examples_seen=40950 epoch=195: 0.105096\n",
      "total training time: 98.30 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/PSRSaline_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on DSR - Ipsi\n",
      "********************************************************************************\n",
      "2018-06-27 04:14:26: Loss after num_examples_seen=0 epoch=0: 1.631061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 04:15:00: Loss after num_examples_seen=250 epoch=5: 0.724324\n",
      "2018-06-27 04:15:33: Loss after num_examples_seen=500 epoch=10: 0.738812\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 04:16:07: Loss after num_examples_seen=750 epoch=15: 0.630588\n",
      "2018-06-27 04:16:41: Loss after num_examples_seen=1000 epoch=20: 0.653030\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 04:17:16: Loss after num_examples_seen=1250 epoch=25: 0.461590\n",
      "2018-06-27 04:17:50: Loss after num_examples_seen=1500 epoch=30: 0.415531\n",
      "2018-06-27 04:18:24: Loss after num_examples_seen=1750 epoch=35: 0.387788\n",
      "2018-06-27 04:18:57: Loss after num_examples_seen=2000 epoch=40: 0.342254\n",
      "2018-06-27 04:19:32: Loss after num_examples_seen=2250 epoch=45: 0.313721\n",
      "2018-06-27 04:20:06: Loss after num_examples_seen=2500 epoch=50: 0.298592\n",
      "2018-06-27 04:20:40: Loss after num_examples_seen=2750 epoch=55: 0.234780\n",
      "2018-06-27 04:21:13: Loss after num_examples_seen=3000 epoch=60: 0.196665\n",
      "2018-06-27 04:21:47: Loss after num_examples_seen=3250 epoch=65: 0.174504\n",
      "2018-06-27 04:22:21: Loss after num_examples_seen=3500 epoch=70: 0.146191\n",
      "2018-06-27 04:22:56: Loss after num_examples_seen=3750 epoch=75: 0.132026\n",
      "2018-06-27 04:23:30: Loss after num_examples_seen=4000 epoch=80: 0.119736\n",
      "2018-06-27 04:24:04: Loss after num_examples_seen=4250 epoch=85: 0.110618\n",
      "2018-06-27 04:24:38: Loss after num_examples_seen=4500 epoch=90: 0.105525\n",
      "2018-06-27 04:25:12: Loss after num_examples_seen=4750 epoch=95: 0.702715\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 04:25:46: Loss after num_examples_seen=5000 epoch=100: 0.653193\n",
      "2018-06-27 04:26:20: Loss after num_examples_seen=5250 epoch=105: 0.644141\n",
      "2018-06-27 04:26:54: Loss after num_examples_seen=5500 epoch=110: 0.627645\n",
      "2018-06-27 04:27:28: Loss after num_examples_seen=5750 epoch=115: 0.614471\n",
      "2018-06-27 04:28:02: Loss after num_examples_seen=6000 epoch=120: 0.605243\n",
      "2018-06-27 04:28:36: Loss after num_examples_seen=6250 epoch=125: 0.592226\n",
      "2018-06-27 04:29:10: Loss after num_examples_seen=6500 epoch=130: 0.580244\n",
      "2018-06-27 04:29:44: Loss after num_examples_seen=6750 epoch=135: 0.566788\n",
      "2018-06-27 04:30:18: Loss after num_examples_seen=7000 epoch=140: 0.555989\n",
      "2018-06-27 04:30:52: Loss after num_examples_seen=7250 epoch=145: 0.540265\n",
      "2018-06-27 04:31:26: Loss after num_examples_seen=7500 epoch=150: 0.526839\n",
      "2018-06-27 04:32:00: Loss after num_examples_seen=7750 epoch=155: 0.632197\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 04:32:34: Loss after num_examples_seen=8000 epoch=160: 0.594077\n",
      "2018-06-27 04:33:08: Loss after num_examples_seen=8250 epoch=165: 0.580815\n",
      "2018-06-27 04:33:42: Loss after num_examples_seen=8500 epoch=170: 0.585257\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-27 04:34:16: Loss after num_examples_seen=8750 epoch=175: 0.629606\n",
      "Setting learning rate to 0.000078\n",
      "2018-06-27 04:34:50: Loss after num_examples_seen=9000 epoch=180: 0.610503\n",
      "2018-06-27 04:35:24: Loss after num_examples_seen=9250 epoch=185: 0.602802\n",
      "2018-06-27 04:35:59: Loss after num_examples_seen=9500 epoch=190: 0.595244\n",
      "2018-06-27 04:36:33: Loss after num_examples_seen=9750 epoch=195: 0.588100\n",
      "total training time: 22.68 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/DSRIpsi_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on PSR - Contra\n",
      "********************************************************************************\n",
      "2018-06-27 04:37:07: Loss after num_examples_seen=0 epoch=0: 1.587354\n",
      "2018-06-27 04:37:59: Loss after num_examples_seen=290 epoch=5: 1.196029\n",
      "2018-06-27 04:38:52: Loss after num_examples_seen=580 epoch=10: 1.174862\n",
      "2018-06-27 04:39:44: Loss after num_examples_seen=870 epoch=15: 1.029011\n",
      "2018-06-27 04:40:37: Loss after num_examples_seen=1160 epoch=20: 9.419694\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 04:41:29: Loss after num_examples_seen=1450 epoch=25: 8.752794\n",
      "2018-06-27 04:42:22: Loss after num_examples_seen=1740 epoch=30: 1.731150\n",
      "2018-06-27 04:43:15: Loss after num_examples_seen=2030 epoch=35: 1.786150\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 04:44:07: Loss after num_examples_seen=2320 epoch=40: 1.325599\n",
      "2018-06-27 04:44:59: Loss after num_examples_seen=2610 epoch=45: 1.282822\n",
      "2018-06-27 04:45:52: Loss after num_examples_seen=2900 epoch=50: 1.259090\n",
      "2018-06-27 04:46:45: Loss after num_examples_seen=3190 epoch=55: 1.240221\n",
      "2018-06-27 04:47:37: Loss after num_examples_seen=3480 epoch=60: 1.227271\n",
      "2018-06-27 04:48:30: Loss after num_examples_seen=3770 epoch=65: 1.216800\n",
      "2018-06-27 04:49:22: Loss after num_examples_seen=4060 epoch=70: 1.210248\n",
      "2018-06-27 04:50:15: Loss after num_examples_seen=4350 epoch=75: 1.199915\n",
      "2018-06-27 04:51:08: Loss after num_examples_seen=4640 epoch=80: 1.188606\n",
      "2018-06-27 04:52:00: Loss after num_examples_seen=4930 epoch=85: 1.181326\n",
      "2018-06-27 04:52:53: Loss after num_examples_seen=5220 epoch=90: 1.179627\n",
      "2018-06-27 04:53:45: Loss after num_examples_seen=5510 epoch=95: 1.167917\n",
      "2018-06-27 04:54:38: Loss after num_examples_seen=5800 epoch=100: 1.164835\n",
      "2018-06-27 04:55:30: Loss after num_examples_seen=6090 epoch=105: 1.166615\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 04:56:23: Loss after num_examples_seen=6380 epoch=110: 1.118260\n",
      "2018-06-27 04:57:15: Loss after num_examples_seen=6670 epoch=115: 1.116818\n",
      "2018-06-27 04:58:08: Loss after num_examples_seen=6960 epoch=120: 1.113852\n",
      "2018-06-27 04:59:00: Loss after num_examples_seen=7250 epoch=125: 1.108773\n",
      "2018-06-27 04:59:53: Loss after num_examples_seen=7540 epoch=130: 1.105873\n",
      "2018-06-27 05:00:45: Loss after num_examples_seen=7830 epoch=135: 1.104931\n",
      "2018-06-27 05:01:38: Loss after num_examples_seen=8120 epoch=140: 1.100478\n",
      "2018-06-27 05:02:30: Loss after num_examples_seen=8410 epoch=145: 1.096456\n",
      "2018-06-27 05:03:23: Loss after num_examples_seen=8700 epoch=150: 1.100823\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 05:04:15: Loss after num_examples_seen=8990 epoch=155: 1.077701\n",
      "2018-06-27 05:05:08: Loss after num_examples_seen=9280 epoch=160: 1.075678\n",
      "2018-06-27 05:06:00: Loss after num_examples_seen=9570 epoch=165: 1.073727\n",
      "2018-06-27 05:06:53: Loss after num_examples_seen=9860 epoch=170: 1.072246\n",
      "2018-06-27 05:07:45: Loss after num_examples_seen=10150 epoch=175: 1.071370\n",
      "2018-06-27 05:08:38: Loss after num_examples_seen=10440 epoch=180: 1.068289\n",
      "2018-06-27 05:09:30: Loss after num_examples_seen=10730 epoch=185: 1.067348\n",
      "2018-06-27 05:10:23: Loss after num_examples_seen=11020 epoch=190: 1.064549\n",
      "2018-06-27 05:11:15: Loss after num_examples_seen=11310 epoch=195: 1.064848\n",
      "Setting learning rate to 0.000156\n",
      "total training time: 35.02 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/PSRContra_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on DSR - MPFC\n",
      "********************************************************************************\n",
      "2018-06-27 05:12:08: Loss after num_examples_seen=0 epoch=0: 1.659613\n",
      "2018-06-27 05:13:00: Loss after num_examples_seen=285 epoch=5: 0.660904\n",
      "2018-06-27 05:13:53: Loss after num_examples_seen=570 epoch=10: 0.566565\n",
      "2018-06-27 05:14:45: Loss after num_examples_seen=855 epoch=15: 0.598454\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 05:15:37: Loss after num_examples_seen=1140 epoch=20: 0.466344\n",
      "2018-06-27 05:16:29: Loss after num_examples_seen=1425 epoch=25: 0.436604\n",
      "2018-06-27 05:17:22: Loss after num_examples_seen=1710 epoch=30: 0.395246\n",
      "2018-06-27 05:18:15: Loss after num_examples_seen=1995 epoch=35: 0.870275\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 05:19:07: Loss after num_examples_seen=2280 epoch=40: 0.621911\n",
      "2018-06-27 05:19:59: Loss after num_examples_seen=2565 epoch=45: 0.571005\n",
      "2018-06-27 05:20:52: Loss after num_examples_seen=2850 epoch=50: 0.524315\n",
      "2018-06-27 05:21:44: Loss after num_examples_seen=3135 epoch=55: 0.507095\n",
      "2018-06-27 05:22:37: Loss after num_examples_seen=3420 epoch=60: 0.487215\n",
      "2018-06-27 05:23:29: Loss after num_examples_seen=3705 epoch=65: 0.541123\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 05:24:21: Loss after num_examples_seen=3990 epoch=70: 0.473278\n",
      "2018-06-27 05:25:14: Loss after num_examples_seen=4275 epoch=75: 0.466350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 05:26:06: Loss after num_examples_seen=4560 epoch=80: 0.458644\n",
      "2018-06-27 05:26:59: Loss after num_examples_seen=4845 epoch=85: 0.454508\n",
      "2018-06-27 05:27:51: Loss after num_examples_seen=5130 epoch=90: 0.546524\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 05:28:44: Loss after num_examples_seen=5415 epoch=95: 0.497541\n",
      "2018-06-27 05:29:36: Loss after num_examples_seen=5700 epoch=100: 0.491742\n",
      "2018-06-27 05:30:28: Loss after num_examples_seen=5985 epoch=105: 0.487904\n",
      "2018-06-27 05:31:21: Loss after num_examples_seen=6270 epoch=110: 0.481506\n",
      "2018-06-27 05:32:13: Loss after num_examples_seen=6555 epoch=115: 0.478647\n",
      "2018-06-27 05:33:06: Loss after num_examples_seen=6840 epoch=120: 0.477621\n",
      "2018-06-27 05:33:58: Loss after num_examples_seen=7125 epoch=125: 0.476238\n",
      "2018-06-27 05:34:51: Loss after num_examples_seen=7410 epoch=130: 0.469886\n",
      "2018-06-27 05:35:43: Loss after num_examples_seen=7695 epoch=135: 0.466279\n",
      "2018-06-27 05:36:36: Loss after num_examples_seen=7980 epoch=140: 0.464902\n",
      "2018-06-27 05:37:28: Loss after num_examples_seen=8265 epoch=145: 0.460732\n",
      "2018-06-27 05:38:20: Loss after num_examples_seen=8550 epoch=150: 0.457283\n",
      "2018-06-27 05:39:13: Loss after num_examples_seen=8835 epoch=155: 0.451636\n",
      "2018-06-27 05:40:05: Loss after num_examples_seen=9120 epoch=160: 0.445041\n",
      "2018-06-27 05:40:58: Loss after num_examples_seen=9405 epoch=165: 0.447056\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-27 05:41:50: Loss after num_examples_seen=9690 epoch=170: 0.431998\n",
      "2018-06-27 05:42:43: Loss after num_examples_seen=9975 epoch=175: 0.427435\n",
      "2018-06-27 05:43:35: Loss after num_examples_seen=10260 epoch=180: 0.425520\n",
      "2018-06-27 05:44:27: Loss after num_examples_seen=10545 epoch=185: 0.423109\n",
      "2018-06-27 05:45:20: Loss after num_examples_seen=10830 epoch=190: 0.450156\n",
      "Setting learning rate to 0.000078\n",
      "2018-06-27 05:46:12: Loss after num_examples_seen=11115 epoch=195: 0.423489\n",
      "total training time: 34.95 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/DSRMPFC_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on DSR - Contra\n",
      "********************************************************************************\n",
      "2018-06-27 05:47:05: Loss after num_examples_seen=0 epoch=0: 1.702065\n",
      "2018-06-27 05:47:44: Loss after num_examples_seen=260 epoch=5: 0.717704\n",
      "2018-06-27 05:48:24: Loss after num_examples_seen=520 epoch=10: 0.687010\n",
      "2018-06-27 05:49:03: Loss after num_examples_seen=780 epoch=15: 0.710857\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 05:49:43: Loss after num_examples_seen=1040 epoch=20: 0.629606\n",
      "2018-06-27 05:50:22: Loss after num_examples_seen=1300 epoch=25: 0.581904\n",
      "2018-06-27 05:51:02: Loss after num_examples_seen=1560 epoch=30: 0.532793\n",
      "2018-06-27 05:51:41: Loss after num_examples_seen=1820 epoch=35: 0.461073\n",
      "2018-06-27 05:52:21: Loss after num_examples_seen=2080 epoch=40: 1.269742\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 05:53:00: Loss after num_examples_seen=2340 epoch=45: 0.745209\n",
      "2018-06-27 05:53:40: Loss after num_examples_seen=2600 epoch=50: 0.747355\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 05:54:19: Loss after num_examples_seen=2860 epoch=55: 0.668658\n",
      "2018-06-27 05:54:59: Loss after num_examples_seen=3120 epoch=60: 0.643590\n",
      "2018-06-27 05:55:38: Loss after num_examples_seen=3380 epoch=65: 0.643426\n",
      "2018-06-27 05:56:18: Loss after num_examples_seen=3640 epoch=70: 0.625900\n",
      "2018-06-27 05:56:57: Loss after num_examples_seen=3900 epoch=75: 0.612234\n",
      "2018-06-27 05:57:36: Loss after num_examples_seen=4160 epoch=80: 0.613979\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 05:58:16: Loss after num_examples_seen=4420 epoch=85: 0.572606\n",
      "2018-06-27 05:58:55: Loss after num_examples_seen=4680 epoch=90: 0.555549\n",
      "2018-06-27 05:59:35: Loss after num_examples_seen=4940 epoch=95: 0.542665\n",
      "2018-06-27 06:00:14: Loss after num_examples_seen=5200 epoch=100: 0.533008\n",
      "2018-06-27 06:00:54: Loss after num_examples_seen=5460 epoch=105: 0.526410\n",
      "2018-06-27 06:01:33: Loss after num_examples_seen=5720 epoch=110: 0.517731\n",
      "2018-06-27 06:02:13: Loss after num_examples_seen=5980 epoch=115: 0.500428\n",
      "2018-06-27 06:02:52: Loss after num_examples_seen=6240 epoch=120: 0.491881\n",
      "2018-06-27 06:03:32: Loss after num_examples_seen=6500 epoch=125: 0.483168\n",
      "2018-06-27 06:04:11: Loss after num_examples_seen=6760 epoch=130: 0.477367\n",
      "2018-06-27 06:04:51: Loss after num_examples_seen=7020 epoch=135: 0.470593\n",
      "2018-06-27 06:05:30: Loss after num_examples_seen=7280 epoch=140: 0.473543\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-27 06:06:10: Loss after num_examples_seen=7540 epoch=145: 0.446982\n",
      "2018-06-27 06:06:49: Loss after num_examples_seen=7800 epoch=150: 0.441293\n",
      "2018-06-27 06:07:29: Loss after num_examples_seen=8060 epoch=155: 0.432899\n",
      "2018-06-27 06:08:08: Loss after num_examples_seen=8320 epoch=160: 0.424711\n",
      "2018-06-27 06:08:48: Loss after num_examples_seen=8580 epoch=165: 0.417705\n",
      "2018-06-27 06:09:27: Loss after num_examples_seen=8840 epoch=170: 0.409943\n",
      "2018-06-27 06:10:07: Loss after num_examples_seen=9100 epoch=175: 0.403764\n",
      "2018-06-27 06:10:46: Loss after num_examples_seen=9360 epoch=180: 0.401255\n",
      "2018-06-27 06:11:26: Loss after num_examples_seen=9620 epoch=185: 0.388791\n",
      "2018-06-27 06:12:05: Loss after num_examples_seen=9880 epoch=190: 0.393437\n",
      "Setting learning rate to 0.000078\n",
      "2018-06-27 06:12:45: Loss after num_examples_seen=10140 epoch=195: 0.379428\n",
      "total training time: 26.33 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/DSRContra_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on DSR - MidTraining\n",
      "********************************************************************************\n",
      "2018-06-27 06:13:24: Loss after num_examples_seen=0 epoch=0: 1.642587\n",
      "2018-06-27 06:13:42: Loss after num_examples_seen=185 epoch=5: 0.691571\n",
      "2018-06-27 06:14:00: Loss after num_examples_seen=370 epoch=10: 0.654461\n",
      "2018-06-27 06:14:19: Loss after num_examples_seen=555 epoch=15: 0.675770\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 06:14:37: Loss after num_examples_seen=740 epoch=20: 0.600803\n",
      "2018-06-27 06:14:55: Loss after num_examples_seen=925 epoch=25: 0.550368\n",
      "2018-06-27 06:15:13: Loss after num_examples_seen=1110 epoch=30: 0.497694\n",
      "2018-06-27 06:15:31: Loss after num_examples_seen=1295 epoch=35: 0.510408\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 06:15:49: Loss after num_examples_seen=1480 epoch=40: 0.324662\n",
      "2018-06-27 06:16:08: Loss after num_examples_seen=1665 epoch=45: 0.298108\n",
      "2018-06-27 06:16:26: Loss after num_examples_seen=1850 epoch=50: 0.271018\n",
      "2018-06-27 06:16:44: Loss after num_examples_seen=2035 epoch=55: 0.210287\n",
      "2018-06-27 06:17:02: Loss after num_examples_seen=2220 epoch=60: 0.199072\n",
      "2018-06-27 06:17:20: Loss after num_examples_seen=2405 epoch=65: 0.160281\n",
      "2018-06-27 06:17:38: Loss after num_examples_seen=2590 epoch=70: 0.143896\n",
      "2018-06-27 06:17:56: Loss after num_examples_seen=2775 epoch=75: 0.131273\n",
      "2018-06-27 06:18:14: Loss after num_examples_seen=2960 epoch=80: 0.116997\n",
      "2018-06-27 06:18:32: Loss after num_examples_seen=3145 epoch=85: 0.105209\n",
      "2018-06-27 06:18:51: Loss after num_examples_seen=3330 epoch=90: 0.097878\n",
      "2018-06-27 06:19:09: Loss after num_examples_seen=3515 epoch=95: 0.092831\n",
      "2018-06-27 06:19:27: Loss after num_examples_seen=3700 epoch=100: 0.089321\n",
      "2018-06-27 06:19:45: Loss after num_examples_seen=3885 epoch=105: 0.086767\n",
      "2018-06-27 06:20:03: Loss after num_examples_seen=4070 epoch=110: 0.084798\n",
      "2018-06-27 06:20:22: Loss after num_examples_seen=4255 epoch=115: 0.083180\n",
      "2018-06-27 06:20:40: Loss after num_examples_seen=4440 epoch=120: 0.081770\n",
      "2018-06-27 06:20:58: Loss after num_examples_seen=4625 epoch=125: 0.080538\n",
      "2018-06-27 06:21:16: Loss after num_examples_seen=4810 epoch=130: 0.079487\n",
      "2018-06-27 06:21:34: Loss after num_examples_seen=4995 epoch=135: 0.078569\n",
      "2018-06-27 06:21:52: Loss after num_examples_seen=5180 epoch=140: 0.077736\n",
      "2018-06-27 06:22:10: Loss after num_examples_seen=5365 epoch=145: 0.076985\n",
      "2018-06-27 06:22:28: Loss after num_examples_seen=5550 epoch=150: 0.076306\n",
      "2018-06-27 06:22:47: Loss after num_examples_seen=5735 epoch=155: 0.075684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 06:23:05: Loss after num_examples_seen=5920 epoch=160: 0.075114\n",
      "2018-06-27 06:23:23: Loss after num_examples_seen=6105 epoch=165: 0.074587\n",
      "2018-06-27 06:23:41: Loss after num_examples_seen=6290 epoch=170: 0.074100\n",
      "2018-06-27 06:23:59: Loss after num_examples_seen=6475 epoch=175: 0.073647\n",
      "2018-06-27 06:24:17: Loss after num_examples_seen=6660 epoch=180: 0.073225\n",
      "2018-06-27 06:24:36: Loss after num_examples_seen=6845 epoch=185: 0.072831\n",
      "2018-06-27 06:24:54: Loss after num_examples_seen=7030 epoch=190: 0.072461\n",
      "2018-06-27 06:25:12: Loss after num_examples_seen=7215 epoch=195: 0.072114\n",
      "total training time: 12.09 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/DSRMidTraining_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on DSR - Saline\n",
      "********************************************************************************\n",
      "2018-06-27 06:25:30: Loss after num_examples_seen=0 epoch=0: 1.647598\n",
      "2018-06-27 06:27:06: Loss after num_examples_seen=910 epoch=5: 0.714064\n",
      "2018-06-27 06:28:42: Loss after num_examples_seen=1820 epoch=10: 0.758102\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 06:30:18: Loss after num_examples_seen=2730 epoch=15: 0.684093\n",
      "2018-06-27 06:31:54: Loss after num_examples_seen=3640 epoch=20: 0.670996\n",
      "2018-06-27 06:33:30: Loss after num_examples_seen=4550 epoch=25: 0.680402\n",
      "Setting learning rate to 0.001250\n",
      "2018-06-27 06:35:06: Loss after num_examples_seen=5460 epoch=30: 0.632845\n",
      "2018-06-27 06:36:42: Loss after num_examples_seen=6370 epoch=35: 0.610259\n",
      "2018-06-27 06:38:18: Loss after num_examples_seen=7280 epoch=40: 0.621089\n",
      "Setting learning rate to 0.000625\n",
      "2018-06-27 06:39:54: Loss after num_examples_seen=8190 epoch=45: 0.504970\n",
      "2018-06-27 06:41:30: Loss after num_examples_seen=9100 epoch=50: 0.502527\n",
      "2018-06-27 06:43:06: Loss after num_examples_seen=10010 epoch=55: 0.460474\n",
      "2018-06-27 06:44:42: Loss after num_examples_seen=10920 epoch=60: 0.457076\n",
      "2018-06-27 06:46:18: Loss after num_examples_seen=11830 epoch=65: 0.450387\n",
      "2018-06-27 06:47:54: Loss after num_examples_seen=12740 epoch=70: 0.492979\n",
      "Setting learning rate to 0.000313\n",
      "2018-06-27 06:49:30: Loss after num_examples_seen=13650 epoch=75: 0.287770\n",
      "2018-06-27 06:51:06: Loss after num_examples_seen=14560 epoch=80: 0.260101\n",
      "2018-06-27 06:52:42: Loss after num_examples_seen=15470 epoch=85: 0.244368\n",
      "2018-06-27 06:54:18: Loss after num_examples_seen=16380 epoch=90: 0.230468\n",
      "2018-06-27 06:55:54: Loss after num_examples_seen=17290 epoch=95: 0.216575\n",
      "2018-06-27 06:57:30: Loss after num_examples_seen=18200 epoch=100: 0.222364\n",
      "Setting learning rate to 0.000156\n",
      "2018-06-27 06:59:06: Loss after num_examples_seen=19110 epoch=105: 0.170992\n",
      "2018-06-27 07:00:42: Loss after num_examples_seen=20020 epoch=110: 0.163222\n",
      "2018-06-27 07:02:18: Loss after num_examples_seen=20930 epoch=115: 0.159892\n",
      "2018-06-27 07:03:54: Loss after num_examples_seen=21840 epoch=120: 0.154392\n",
      "2018-06-27 07:05:30: Loss after num_examples_seen=22750 epoch=125: 0.148761\n",
      "2018-06-27 07:07:06: Loss after num_examples_seen=23660 epoch=130: 0.144739\n",
      "2018-06-27 07:08:42: Loss after num_examples_seen=24570 epoch=135: 0.141842\n",
      "2018-06-27 07:10:18: Loss after num_examples_seen=25480 epoch=140: 0.139613\n",
      "2018-06-27 07:11:54: Loss after num_examples_seen=26390 epoch=145: 0.137804\n",
      "2018-06-27 07:13:30: Loss after num_examples_seen=27300 epoch=150: 0.136281\n",
      "2018-06-27 07:15:06: Loss after num_examples_seen=28210 epoch=155: 0.134967\n",
      "2018-06-27 07:16:42: Loss after num_examples_seen=29120 epoch=160: 0.133813\n",
      "2018-06-27 07:18:18: Loss after num_examples_seen=30030 epoch=165: 0.132788\n",
      "2018-06-27 07:19:54: Loss after num_examples_seen=30940 epoch=170: 0.131869\n",
      "2018-06-27 07:21:30: Loss after num_examples_seen=31850 epoch=175: 0.131038\n",
      "2018-06-27 07:23:07: Loss after num_examples_seen=32760 epoch=180: 0.130281\n",
      "2018-06-27 07:24:44: Loss after num_examples_seen=33670 epoch=185: 0.129587\n",
      "2018-06-27 07:26:20: Loss after num_examples_seen=34580 epoch=190: 0.128946\n",
      "2018-06-27 07:27:56: Loss after num_examples_seen=35490 epoch=195: 0.128351\n",
      "total training time: 64.03 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/DSRSaline_choice_reward_split_sequences_train_test.npz.\n",
      "********************************************************************************\n",
      "training RNN on PSR - FirstTraining\n",
      "********************************************************************************\n",
      "2018-06-27 07:29:32: Loss after num_examples_seen=0 epoch=0: 1.610849\n",
      "2018-06-27 07:29:53: Loss after num_examples_seen=195 epoch=5: 1.075536\n",
      "2018-06-27 07:30:14: Loss after num_examples_seen=390 epoch=10: 1.014980\n",
      "2018-06-27 07:30:34: Loss after num_examples_seen=585 epoch=15: 1.036657\n",
      "Setting learning rate to 0.002500\n",
      "2018-06-27 07:30:55: Loss after num_examples_seen=780 epoch=20: 0.907419\n",
      "2018-06-27 07:31:16: Loss after num_examples_seen=975 epoch=25: 0.793698\n",
      "2018-06-27 07:31:36: Loss after num_examples_seen=1170 epoch=30: 0.713228\n",
      "2018-06-27 07:31:57: Loss after num_examples_seen=1365 epoch=35: 0.531713\n",
      "2018-06-27 07:32:18: Loss after num_examples_seen=1560 epoch=40: 0.379308\n",
      "2018-06-27 07:32:39: Loss after num_examples_seen=1755 epoch=45: 0.250183\n",
      "2018-06-27 07:32:59: Loss after num_examples_seen=1950 epoch=50: 0.196001\n",
      "2018-06-27 07:33:20: Loss after num_examples_seen=2145 epoch=55: 0.165730\n",
      "2018-06-27 07:33:40: Loss after num_examples_seen=2340 epoch=60: 0.124064\n",
      "2018-06-27 07:34:01: Loss after num_examples_seen=2535 epoch=65: 0.106408\n",
      "2018-06-27 07:34:22: Loss after num_examples_seen=2730 epoch=70: 0.095718\n",
      "2018-06-27 07:34:42: Loss after num_examples_seen=2925 epoch=75: 0.088269\n",
      "2018-06-27 07:35:03: Loss after num_examples_seen=3120 epoch=80: 0.083749\n",
      "2018-06-27 07:35:24: Loss after num_examples_seen=3315 epoch=85: 0.080578\n",
      "2018-06-27 07:35:44: Loss after num_examples_seen=3510 epoch=90: 0.078202\n",
      "2018-06-27 07:36:05: Loss after num_examples_seen=3705 epoch=95: 0.076345\n",
      "2018-06-27 07:36:26: Loss after num_examples_seen=3900 epoch=100: 0.074848\n",
      "2018-06-27 07:36:47: Loss after num_examples_seen=4095 epoch=105: 0.073613\n",
      "2018-06-27 07:37:07: Loss after num_examples_seen=4290 epoch=110: 0.072574\n",
      "2018-06-27 07:37:28: Loss after num_examples_seen=4485 epoch=115: 0.071687\n",
      "2018-06-27 07:37:48: Loss after num_examples_seen=4680 epoch=120: 0.070919\n",
      "2018-06-27 07:38:09: Loss after num_examples_seen=4875 epoch=125: 0.070247\n",
      "2018-06-27 07:38:30: Loss after num_examples_seen=5070 epoch=130: 0.069651\n",
      "2018-06-27 07:38:50: Loss after num_examples_seen=5265 epoch=135: 0.069119\n",
      "2018-06-27 07:39:11: Loss after num_examples_seen=5460 epoch=140: 0.068639\n",
      "2018-06-27 07:39:32: Loss after num_examples_seen=5655 epoch=145: 0.068205\n",
      "2018-06-27 07:39:52: Loss after num_examples_seen=5850 epoch=150: 0.067811\n",
      "2018-06-27 07:40:13: Loss after num_examples_seen=6045 epoch=155: 0.067451\n",
      "2018-06-27 07:40:34: Loss after num_examples_seen=6240 epoch=160: 0.067123\n",
      "2018-06-27 07:40:55: Loss after num_examples_seen=6435 epoch=165: 0.066823\n",
      "2018-06-27 07:41:15: Loss after num_examples_seen=6630 epoch=170: 0.066547\n",
      "2018-06-27 07:41:36: Loss after num_examples_seen=6825 epoch=175: 0.066293\n",
      "2018-06-27 07:41:57: Loss after num_examples_seen=7020 epoch=180: 0.066058\n",
      "2018-06-27 07:42:17: Loss after num_examples_seen=7215 epoch=185: 0.065839\n",
      "2018-06-27 07:42:38: Loss after num_examples_seen=7410 epoch=190: 0.065636\n",
      "2018-06-27 07:42:59: Loss after num_examples_seen=7605 epoch=195: 0.065445\n",
      "total training time: 13.79 minutes\n",
      "Saved model parameters to /Users/pablomartin/python/DATA_structures/RNN_models2/PSRFirstTraining_choice_reward_split_sequences_train_test.npz.\n",
      "total training time: 7.40 hours\n"
     ]
    }
   ],
   "source": [
    "ROOT = '/Users/pablomartin/python'\n",
    "source = ROOT + '/DATA_structures/RNN_sequences/'\n",
    "target = ROOT + '/DATA_structures/RNN_models2/'\n",
    "\n",
    "script_start = time.time()\n",
    "for sequences in os.listdir(source):\n",
    "    '''\n",
    "    loading right dataset, i processed the split datasets elsewhere and saved them\n",
    "    to the source folder we only care about 'choice_reward' and 'split' datasets that\n",
    "    are already divided into training and testing sets for us\n",
    "    '''\n",
    "    task, regime, seq_type, seq_split = sequence_to_labels(sequences)\n",
    "    \n",
    "    if seq_type == 'choice_reward' \\\n",
    "    and seq_split == 'split' \\\n",
    "    and sequences.find('train') > 0:\n",
    "    \n",
    "        print '*' * 80\n",
    "        print 'training RNN on %s - %s' %(task, regime)\n",
    "        print '*' * 80\n",
    "\n",
    "        x_train, y_train, x_test, y_test = pickle.load(open(source + sequences, 'rb'))\n",
    "        elements_in_seq = 5\n",
    "\n",
    "        #initialize RNN\n",
    "        RNN = behaviorRNN(noFeatures = elements_in_seq, hidden_dim = 200, bptt_truncate = 50)    \n",
    "\n",
    "        #train the network\n",
    "        start = time.time()\n",
    "        RNN.train_with_sgd(x_train, y_train, learning_rate = 0.005, nepoch = 200)\n",
    "        print 'total training time: %1.2f minutes' %((time.time() - start)/60)\n",
    "        save_model_parameters(target + sequences[:sequences.find('.')] + '.npz', RNN)\n",
    "    \n",
    "\n",
    "print 'total training time: %1.2f hours' %((time.time() - script_start) / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mod_test_sequences(model_dir, sequence_dir, sequences, sequences2):\n",
    "    \n",
    "    #loading previously trained model\n",
    "    RNN = behaviorRNN()\n",
    "    model_file = sequences[:sequences.find('.')] + '.npz' \n",
    "    load_model_parameters(model_dir + model_file, RNN)\n",
    "    #loading appropriate dataset\n",
    "    tmp_seq = sequences2[:sequences2.find('.')] + '.p'     \n",
    "    x_train, y_train, x_test, y_test = pickle.load(open(sequence_dir + tmp_seq, 'rb'))\n",
    "\n",
    "    \n",
    "    #checking accuracy\n",
    "    hits = 0\n",
    "    trials = 0\n",
    "    for test_seq in x_test:\n",
    "        out = evaluate_model(test_seq, 'choice_reward', RNN)\n",
    "        hits += out[0]\n",
    "        trials += out[1]\n",
    "            \n",
    "    return float(hits)/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: PSR - MPFC - choice_reward - split\n",
      "time elapsed: 0.32 minutes\n",
      "finished: DSR - FirstTraining - choice_reward - split\n",
      "time elapsed: 0.31 minutes\n",
      "finished: PSR - MidTraining - choice_reward - split\n",
      "time elapsed: 0.31 minutes\n",
      "finished: PSR - Ipsi - choice_reward - split\n",
      "time elapsed: 0.31 minutes\n",
      "finished: DSR - OFC - choice_reward - split\n",
      "time elapsed: 0.32 minutes\n",
      "finished: PSR - OFC - choice_reward - split\n",
      "time elapsed: 0.32 minutes\n",
      "finished: PSR - Saline - choice_reward - split\n",
      "time elapsed: 0.31 minutes\n",
      "finished: DSR - Ipsi - choice_reward - split\n",
      "time elapsed: 0.31 minutes\n",
      "finished: PSR - Contra - choice_reward - split\n",
      "time elapsed: 0.31 minutes\n",
      "finished: DSR - MPFC - choice_reward - split\n",
      "time elapsed: 0.33 minutes\n",
      "finished: DSR - Contra - choice_reward - split\n",
      "time elapsed: 0.34 minutes\n",
      "finished: DSR - MidTraining - choice_reward - split\n",
      "time elapsed: 0.33 minutes\n",
      "finished: DSR - Saline - choice_reward - split\n",
      "time elapsed: 0.32 minutes\n",
      "finished: PSR - FirstTraining - choice_reward - split\n",
      "time elapsed: 0.32 minutes\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAGJCAYAAAB/3c+9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106d71910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequence_dir = ROOT + '/DATA_structures/RNN_sequences/'\n",
    "model_dir = ROOT + '/DATA_structures/RNN_models2/'\n",
    "\n",
    "#creating dataframe\n",
    "idx = pd.IndexSlice\n",
    "iterables_row = [['DSR','PSR'], ['FirstTraining', 'MidTraining', 'Saline',\n",
    "                                 'MPFC', 'OFC', 'Ipsi', 'Contra']]\n",
    "row_index  = pd.MultiIndex.from_product(iterables_row, names=['task','regime'])\n",
    "df = pd.DataFrame(np.full([len(row_index),len(row_index)], np.NaN),\n",
    "                                                      index = row_index,\n",
    "                                                      columns=row_index)\n",
    "\n",
    "\n",
    "\n",
    "for sequences in os.listdir(sequence_dir):\n",
    "    \n",
    "    task, regime, seq_type, seq_split = sequence_to_labels(sequences)\n",
    "    \n",
    "    #only taking input sequences that have been split into training and test sets\n",
    "    if sequences.find('train') > 0\\\n",
    "    and seq_type == 'choice_reward'\\\n",
    "    and seq_split == 'split':\n",
    "        start = time.time()\n",
    "        for comparator in os.listdir(sequence_dir):\n",
    "            \n",
    "            task2, regime2, seq_type2, seq_split2  = sequence_to_labels(comparator)\n",
    "            \n",
    "            #only working within input sequence type\n",
    "            if comparator.find('train') > 0 \\\n",
    "            and seq_split2 == 'split' \\\n",
    "            and seq_type2 == 'choice_reward':\n",
    "                df.loc[idx[task, regime], idx[task2, regime2]] = \\\n",
    "                        mod_test_sequences(model_dir, sequence_dir, sequences, comparator)\n",
    "\n",
    "            \n",
    "            \n",
    "        print 'finished: %s - %s - %s - %s' %(task, regime, seq_type, seq_split)\n",
    "        print 'time elapsed: %1.2f minutes' %((time.time() - start) / 60)\n",
    "    \n",
    "\n",
    "labels = [df.index.levels[0][a] + df.index.levels[1][b] \\\n",
    "             for a,b in zip(df.index.labels[0], df.index.labels[1])]\n",
    "\n",
    "plot_models(df, labels, 'Recurrent Neural Network Decoding\\n with Greater Depth', [0.5, 0.85] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WTF. Double the hidden units and training epochs resulted in worse decoding. Barring an error ? Not sure what happened here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
